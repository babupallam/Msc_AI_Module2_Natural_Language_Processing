{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9uuitZmsh6RJzTT/LBRAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babupallam/Msc_AI_Module2_Natural_Language_Processing/blob/main/L06-Feed%20Forward%20Networks%20for%20Natural%20Language%20Processing/01_MLP_Input_Data_and_Tensor_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Introduction**\n",
        "\n",
        "- **Tensors in Neural Networks**:\n",
        "  - In PyTorch, data is represented using **tensors**. A tensor is essentially a multi-dimensional array (similar to NumPy arrays) but with added support for GPU acceleration.\n",
        "  - Neural networks process data in the form of tensors, which are passed through layers, transformed, and produce outputs.\n",
        "\n",
        "- **Dimensions in Neural Networks**:\n",
        "  - **Batch size**: Refers to the number of data samples processed simultaneously by the network. For instance, a batch size of 32 means the model processes 32 samples at once.\n",
        "  - **Input dimensions**: Refers to the number of features in each input sample. For example, in a dataset of images, the input dimension might be the number of pixels (height × width) per image.\n",
        "  - **Output dimensions**: Typically corresponds to the number of target classes or regression outputs the model predicts.\n",
        "\n",
        "  **Observation**:\n",
        "  - Tensors allow us to handle multi-dimensional data efficiently, which is crucial for large datasets and high-dimensional inputs like images or time series.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wcq3ml1-J13T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "fEjZeNfbJ18o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. **Generating Input Data**\n",
        "\n",
        "- **Creating Random Tensors**:\n",
        "  - To simulate data, we can generate random tensors using PyTorch’s `torch.rand()`. This function generates random numbers uniformly distributed between 0 and 1.\n",
        "\n",
        "  - **Shape of the Tensor**:\n",
        "    - The shape is critical in neural networks. In this case, the shape `(batch_size, input_dim)` means we have a batch of `batch_size` samples, where each sample has `input_dim` features.\n",
        "\n",
        "  **Code Explanation**:\n",
        "  - For a batch size of 2 and an input dimension of 3:\n",
        "  "
      ],
      "metadata": {
        "id": "NXZ40Up4J2Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Imports the PyTorch library. This line makes 'torch' available for use\n",
        "\n",
        "batch_size = 2  # Defines the number of samples (batch size) to be processed at once\n",
        "input_dim = 3  # Defines the number of features in each input sample\n",
        "x_input = torch.rand(batch_size, input_dim)  # Generates a random input tensor with shape (batch_size, input_dim)\n",
        "print(\"Random input tensor:\", x_input)  # Prints the generated random tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Q-IbZtkKsq",
        "outputId": "dd414aad-beb3-47dd-e17a-4f74de6d420c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random input tensor: tensor([[0.3881, 0.7579, 0.5920],\n",
            "        [0.0592, 0.7366, 0.1417]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  **Demonstration**:\n",
        "  - Generate the random tensor and print its shape and values:\n"
      ],
      "metadata": {
        "id": "UjGtIoGpJ2Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input tensor shape:\", x_input.shape)  # Prints the shape of the tensor, which is (batch_size, input_dim)\n",
        "print(\"Input tensor values:\\n\", x_input)  # Prints the actual values of the input tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIQaFJmBkZGA",
        "outputId": "6232fbc2-9474-4726-e90d-66a12d45ad25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tensor shape: torch.Size([2, 3])\n",
            "Input tensor values:\n",
            " tensor([[0.3881, 0.7579, 0.5920],\n",
            "        [0.0592, 0.7366, 0.1417]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Role of Batch Size and Input Dimensions**:\n",
        "  - **Batch size**: Controls how many data samples are processed at once. A larger batch size can speed up training, but it also requires more memory.\n",
        "  - **Input dimensions**: Define how much information is passed to the network per sample. For example, if each sample represents an image, the input dimension could be the number of pixels.\n",
        "\n",
        "  **Observation**:\n",
        "  - Batch size and input dimensions directly affect memory usage and computation time. It’s essential to choose appropriate values for batch size based on your dataset and hardware.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-1fgr4DGJ2Jb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3. **Understanding Tensor Shapes**\n",
        "\n",
        "- **`describe()` Function**:\n",
        "  - Understanding the **shape** and **type** of tensors is crucial when designing neural networks, as mismatched shapes can cause errors.\n",
        "  - The `describe()` function will print out key information about the tensor:\n",
        "    - **Type**: Type of tensor (e.g., `torch.FloatTensor`).\n",
        "    - **Shape**: Dimensions of the tensor (e.g., `(batch_size, input_dim)`).\n",
        "    - **Values**: The actual data contained within the tensor.\n",
        "\n",
        "  **Code**:\n"
      ],
      "metadata": {
        "id": "0qACGUIXJ2Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe(x):\n",
        "    # Prints the type of the tensor\n",
        "    print(\"Type: {}\".format(x.type()))\n",
        "\n",
        "    # Prints the shape of the tensor\n",
        "    print(\"Shape: {}\".format(x.shape))\n",
        "\n",
        "    # Prints the actual values of the tensor\n",
        "    print(\"Values: \\n{}\".format(x))\n"
      ],
      "metadata": {
        "id": "FZ3wSmGhknOf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  **Demonstration**:\n",
        "  - Use the `describe()` function to display details about the tensor created earlier:\n"
      ],
      "metadata": {
        "id": "oe0qgLVCJ3QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "describe(x_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D59Kb_YlkpTH",
        "outputId": "feaab2fc-4ab0-4574-ecf0-972be357248e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.3881, 0.7579, 0.5920],\n",
            "        [0.0592, 0.7366, 0.1417]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  **Observation**:\n",
        "  - Understanding the structure of your data is critical. In neural networks, tensors must have the correct shape for layers to process them properly (e.g., input and output shapes need to align with the layers’ expectations).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "_W91bPV7J3QM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4. **Exercise**\n",
        "\n",
        "- **Changing Batch Size and Input Dimensions**:\n",
        "  - Explore how modifying the batch size or input dimensions affects the tensor shape. Changing these values helps understand how different datasets with various sizes are handled by the network.\n",
        "  \n",
        "  **Task**:\n",
        "  - Change the batch size to 4 and input dimensions to 5, then print the new tensor shape and values:\n"
      ],
      "metadata": {
        "id": "tnzSDAL0J3QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "input_dim = 5\n",
        "x_input = torch.rand(batch_size, input_dim)  # Generate new random tensor\n",
        "describe(x_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PlE5eVglFL4",
        "outputId": "3f507736-5e0f-485c-bf31-ee09ef3d795a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape: torch.Size([4, 5])\n",
            "Values: \n",
            "tensor([[0.5139, 0.5055, 0.2539, 0.4155, 0.4862],\n",
            "        [0.9612, 0.8655, 0.6660, 0.2281, 0.9330],\n",
            "        [0.5295, 0.7268, 0.6760, 0.9847, 0.6083],\n",
            "        [0.5106, 0.7859, 0.8158, 0.4364, 0.4476]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  **Observation**:\n",
        "  - Increasing the batch size increases the number of samples being processed simultaneously. This change will also affect memory usage and how fast the network can train.\n",
        "\n",
        "- **Creating Additional Tensors with Different Shapes**:\n",
        "  - Experiment with creating tensors of different shapes, such as:\n",
        "    - 1D tensor (vector).\n",
        "    - 2D tensor (matrix).\n",
        "    - 3D tensor (cube-like data for image processing).\n",
        "\n",
        "  **Task**:\n",
        "  - Create and describe different tensors:\n"
      ],
      "metadata": {
        "id": "p2g8pnHqJ3QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1D tensor (vector)\n",
        "x_vector = torch.rand(10)  # Creates a 1D tensor with 10 random values (uniformly sampled between 0 and 1)\n",
        "describe(x_vector)  # Call the describe function to output type, shape, and values of the 1D tensor\n",
        "\n",
        "# 2D tensor (matrix)\n",
        "x_matrix = torch.rand(3, 4)  # Creates a 2D tensor with 3 rows and 4 columns (3x4 matrix) filled with random values\n",
        "describe(x_matrix)  # Call the describe function to output type, shape, and values of the 2D tensor\n",
        "\n",
        "# 3D tensor (for example, simulating images with RGB channels)\n",
        "x_3d = torch.rand(2, 3, 5)  # Creates a 3D tensor: 2 samples, 3 channels (RGB), and 5x5 pixels per channel\n",
        "describe(x_3d)  # Call the describe function to output type, shape, and values of the 3D tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlmvzmyulYAE",
        "outputId": "9a1725af-f6cf-4084-b756-76f146a04917"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape: torch.Size([10])\n",
            "Values: \n",
            "tensor([0.1835, 0.7427, 0.2901, 0.1761, 0.7132, 0.7392, 0.3549, 0.1595, 0.2869,\n",
            "        0.8143])\n",
            "Type: torch.FloatTensor\n",
            "Shape: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[0.8827, 0.8895, 0.8898, 0.1312],\n",
            "        [0.1597, 0.6499, 0.4837, 0.7159],\n",
            "        [0.6974, 0.1937, 0.9633, 0.6133]])\n",
            "Type: torch.FloatTensor\n",
            "Shape: torch.Size([2, 3, 5])\n",
            "Values: \n",
            "tensor([[[0.9016, 0.0044, 0.3400, 0.0975, 0.1876],\n",
            "         [0.8151, 0.5927, 0.7756, 0.2288, 0.9963],\n",
            "         [0.9532, 0.9311, 0.0167, 0.8669, 0.9576]],\n",
            "\n",
            "        [[0.1763, 0.2425, 0.9991, 0.3652, 0.1233],\n",
            "         [0.6588, 0.9498, 0.1700, 0.7415, 0.0975],\n",
            "         [0.7149, 0.1856, 0.2802, 0.3512, 0.6118]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  **Observation**:\n",
        "  - The shape of the tensor changes how data is represented. A 1D tensor might represent a simple list of numbers, while a 3D tensor could represent an image with multiple color channels.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "3qu6aSRSJ3QO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 5. **Conclusion**\n",
        "\n",
        "- **Recap**:\n",
        "  - Tensors are the foundation for data representation in neural networks. Understanding their shapes, sizes, and how they flow through the network is critical for successful model building.\n",
        "  - **Batch size** controls how many data samples are processed at once, while **input dimensions** define how much information each sample carries.\n",
        "\n",
        "- **Importance of Understanding Tensor Operations**:\n",
        "  - Tensor operations like reshaping, slicing, and broadcasting are key for feeding data into the model, passing data through layers, and adjusting for mismatches.\n",
        "  - Misaligned tensor shapes can cause errors, so it’s important to ensure that tensors are correctly sized before passing them through the network.\n",
        "\n",
        "  **Demonstration**:\n",
        "  - Show a final demonstration on reshaping a tensor, which is a common operation in neural networks:\n"
      ],
      "metadata": {
        "id": "eK9S4JFaJ3QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape a 3D tensor into a 2D tensor (flattening the last two dimensions)\n",
        "x_reshaped = x_3d.view(2, -1)  # Reshape to (2, 15), combining the last two dimensions\n",
        "describe(x_reshaped)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOXg0dEtld3q",
        "outputId": "3f4eac96-9499-47c2-c467-accf2e637e9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape: torch.Size([2, 15])\n",
            "Values: \n",
            "tensor([[0.9016, 0.0044, 0.3400, 0.0975, 0.1876, 0.8151, 0.5927, 0.7756, 0.2288,\n",
            "         0.9963, 0.9532, 0.9311, 0.0167, 0.8669, 0.9576],\n",
            "        [0.1763, 0.2425, 0.9991, 0.3652, 0.1233, 0.6588, 0.9498, 0.1700, 0.7415,\n",
            "         0.0975, 0.7149, 0.1856, 0.2802, 0.3512, 0.6118]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Takeaway**:\n",
        "  - Mastering tensor operations is a fundamental skill in deep learning with PyTorch. Ensuring that your tensors are correctly sized and shaped will save you time debugging errors and allow for smooth model training.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "90x1EVudJ3fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations"
      ],
      "metadata": {
        "id": "pWhX4tuMmR12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. **Observation: Random Tensor Generation Reproducibility**\n",
        "   - Every time you generate random tensors using `torch.rand()`, the output differs unless a random seed is set.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "72QaEgKYmNhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)  # Set random seed for reproducibility\n",
        "x_input = torch.rand(2, 3)  # Generate random tensor\n",
        "print(\"Random tensor with seed 42:\\n\", x_input)\n",
        "\n",
        "torch.manual_seed(42)  # Set the same seed again\n",
        "x_input_again = torch.rand(2, 3)\n",
        "print(\"Reproduced tensor with same seed:\\n\", x_input_again)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G94UsroGmwSB",
        "outputId": "63434a0a-c981-424b-abe3-a878ba2fddae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor with seed 42:\n",
            " tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n",
            "Reproduced tensor with same seed:\n",
            " tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. **Observation: Effect of Batch Size on Memory Usage**\n",
        "   - Larger batch sizes allow more data to be processed at once but increase memory usage.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "rCM9b7jimNdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with different batch sizes\n",
        "batch_size_small = 2\n",
        "batch_size_large = 64\n",
        "input_dim = 100\n",
        "\n",
        "x_input_small = torch.rand(batch_size_small, input_dim)\n",
        "x_input_large = torch.rand(batch_size_large, input_dim)\n",
        "\n",
        "print(f\"Small batch size memory: {x_input_small.element_size() * x_input_small.nelement()} bytes\")\n",
        "print(f\"Large batch size memory: {x_input_large.element_size() * x_input_large.nelement()} bytes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzq7eXPHm0lN",
        "outputId": "64f1ddc9-7448-4d42-dd72-dc4b0ec90c71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small batch size memory: 800 bytes\n",
            "Large batch size memory: 25600 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3. **Observation: Tensor Operations for Multi-Dimensional Data**\n",
        "   - Tensors can represent complex data (e.g., 3D tensors for RGB images, 2D matrices for grayscale images).\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "y1x3KQyRmNbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors to represent different data types\n",
        "rgb_image = torch.rand(1, 3, 32, 32)  # 1 image, 3 channels (RGB), 32x32 pixels\n",
        "grayscale_image = torch.rand(1, 1, 32, 32)  # 1 image, 1 channel (grayscale), 32x32 pixels\n",
        "\n",
        "print(\"RGB Image shape:\", rgb_image.shape)\n",
        "print(\"Grayscale Image shape:\", grayscale_image.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etKIEFUEm6YT",
        "outputId": "fc6b1339-728b-49ea-efbe-2eaf36cc47d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB Image shape: torch.Size([1, 3, 32, 32])\n",
            "Grayscale Image shape: torch.Size([1, 1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4. **Observation: Understanding Tensor Broadcasting**\n",
        "   - Broadcasting allows tensors of different shapes to be used in operations by expanding their dimensions.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "X3D4Wk36mNYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(3, 1)\n",
        "b = torch.rand(1, 4)\n",
        "broadcasted_result = a + b  # Broadcasting allows (3, 1) + (1, 4)\n",
        "print(\"Result after broadcasting:\\n\", broadcasted_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOsGe6aKm8uh",
        "outputId": "060a62e0-d61e-4f84-d447-74db95c91fc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result after broadcasting:\n",
            " tensor([[1.2550, 1.2105, 1.1784, 1.0308],\n",
            "        [1.1506, 1.1061, 1.0741, 0.9265],\n",
            "        [1.1320, 1.0875, 1.0554, 0.9079]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 5. **Observation: Reshaping Tensors with `view()`**\n",
        "   - Reshaping tensors without changing their data can be useful for adjusting input formats for layers in neural networks.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "ve9V-J8smNWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape 3D tensor into 2D tensor\n",
        "x_3d = torch.rand(2, 3, 5)  # Shape: (2, 3, 5)\n",
        "x_reshaped = x_3d.view(2, -1)  # Flatten last two dimensions\n",
        "print(\"Original 3D tensor shape:\", x_3d.shape)\n",
        "print(\"Reshaped 2D tensor shape:\", x_reshaped.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWpH4775m-Fz",
        "outputId": "1174c30a-cef5-45b8-b12a-24312e42451f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original 3D tensor shape: torch.Size([2, 3, 5])\n",
            "Reshaped 2D tensor shape: torch.Size([2, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6. **Observation: Effect of Input Dimension on Model Complexity**\n",
        "   - Increasing the input dimension increases the number of parameters in a neural network, making it more complex.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "_acGK1rimNUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input dimensions for two different networks\n",
        "input_dim_small = 2\n",
        "input_dim_large = 10\n",
        "hidden_dim = 15\n",
        "\n",
        "model_small = torch.nn.Linear(input_dim_small, hidden_dim)\n",
        "model_large = torch.nn.Linear(input_dim_large, hidden_dim)\n",
        "\n",
        "print(\"Number of parameters (small input):\", sum(p.numel() for p in model_small.parameters()))\n",
        "print(\"Number of parameters (large input):\", sum(p.numel() for p in model_large.parameters()))\n",
        "\n",
        "\n",
        "# In PyTorch, when you call .parameters() on a model (e.g., model_small.parameters()), it returns an iterator over all the learnable parameters (weights and biases) of the model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vYcOxaCm-b0",
        "outputId": "3c69a059-2deb-4970-d4e0-e517a15e9e4c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters (small input): 45\n",
            "Number of parameters (large input): 165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model structure\n",
        "print(\"Model structure:\\n\", model_small)\n",
        "\n",
        "# Access the model's parameters\n",
        "print(\"\\nModel parameters:\")\n",
        "for param in model_small.parameters():\n",
        "    print(param)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1xkHmacoObL",
        "outputId": "5b23e4af-ffb1-4c73-dd97-21fc983ac51b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure:\n",
            " Linear(in_features=2, out_features=15, bias=True)\n",
            "\n",
            "Model parameters:\n",
            "Parameter containing:\n",
            "tensor([[ 0.5803,  0.4982],\n",
            "        [ 0.3824,  0.5655],\n",
            "        [ 0.5694,  0.4177],\n",
            "        [ 0.5108, -0.0908],\n",
            "        [ 0.1842, -0.6078],\n",
            "        [-0.2534, -0.0661],\n",
            "        [-0.0345,  0.6974],\n",
            "        [ 0.5770,  0.2227],\n",
            "        [ 0.6593, -0.3605],\n",
            "        [ 0.1375, -0.5609],\n",
            "        [-0.6015,  0.3781],\n",
            "        [ 0.2270, -0.0381],\n",
            "        [-0.4575,  0.5097],\n",
            "        [-0.0542,  0.4827],\n",
            "        [-0.4885,  0.5434]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0334, -0.2210, -0.0584, -0.5454, -0.1293,  0.0414, -0.5235,  0.3819,\n",
            "         0.6680,  0.3646, -0.3473, -0.4394, -0.5604, -0.4359,  0.4221],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 7. **Observation: How Tensor Slicing Affects Data**\n",
        "   - Tensor slicing allows you to access specific elements or rows/columns in a tensor, useful for selecting parts of a dataset.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "gWeHa8QMmNRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and slice it\n",
        "x = torch.rand(4, 5)  # 4 samples, each with 5 features\n",
        "slice_1 = x[1, :]  # Access second row (second sample)\n",
        "slice_2 = x[:, 2]  # Access third column (third feature across all samples)\n",
        "\n",
        "print(\"Original tensor:\\n\", x)\n",
        "print(\"Second sample (row 1):\", slice_1)\n",
        "print(\"Third feature (column 2):\", slice_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUCIbDeIm-on",
        "outputId": "113d73e9-8238-4c77-ee5e-b0f3f01a867b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            " tensor([[0.2096, 0.9536, 0.7689, 0.5212, 0.2507],\n",
            "        [0.8813, 0.9706, 0.6002, 0.1777, 0.5172],\n",
            "        [0.7436, 0.6460, 0.9499, 0.9503, 0.7533],\n",
            "        [0.1522, 0.4730, 0.5968, 0.3332, 0.6496]])\n",
            "Second sample (row 1): tensor([0.8813, 0.9706, 0.6002, 0.1777, 0.5172])\n",
            "Third feature (column 2): tensor([0.7689, 0.6002, 0.9499, 0.5968])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 8. **Observation: Checking the Data Type of a Tensor**\n",
        "   - It's crucial to ensure that tensors have the correct data type, especially when switching between CPU and GPU.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "5PR4om4UmNMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_input = torch.rand(2, 3)\n",
        "print(\"Tensor type:\", x_input.type())  # Default is usually float32\n",
        "\n",
        "# Convert to another type (e.g., double)\n",
        "x_double = x_input.double()\n",
        "print(\"Converted to double type:\", x_double.type())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_44VhLgfm-0g",
        "outputId": "c786c09f-f9c3-4e6e-929a-d02ee2118e65"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor type: torch.FloatTensor\n",
            "Converted to double type: torch.DoubleTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 9. **Observation: Using `.unsqueeze()` to Add Dimensions**\n",
        "   - `.unsqueeze()` adds dimensions to a tensor, often necessary when batch sizes or channel dimensions need to be included in input data.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "tb5jnXfrmNIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor without a batch dimension\n",
        "x = torch.rand(5)  # Shape: (5)\n",
        "x_unsqueezed = x.unsqueeze(0)  # Add batch dimension\n",
        "print(\"Original shape:\", x.shape)\n",
        "print(\"After unsqueeze (with batch dimension):\", x_unsqueezed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH7txzYFm_BR",
        "outputId": "5e54fdc6-bed5-49b4-8235-3e141be6a563"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([5])\n",
            "After unsqueeze (with batch dimension): torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 11. **Observation: Tensor Concatenation**\n",
        "   - You can concatenate two tensors along a specified dimension to combine data from different sources.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "BnbFFagDmNB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two tensors\n",
        "tensor1 = torch.rand(2, 3)\n",
        "tensor2 = torch.rand(2, 3)\n",
        "\n",
        "# Concatenate along dimension 0 (rows) and dimension 1 (columns)\n",
        "concat_dim0 = torch.cat((tensor1, tensor2), dim=0)\n",
        "concat_dim1 = torch.cat((tensor1, tensor2), dim=1)\n",
        "\n",
        "print(\"Concatenated along rows (dim=0):\\n\", concat_dim0)\n",
        "print(\"Concatenated along columns (dim=1):\\n\", concat_dim1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlq6FIEwm_Y2",
        "outputId": "77a85d16-556c-413e-c2d4-3c95f6a0e712"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenated along rows (dim=0):\n",
            " tensor([[0.8429, 0.3490, 0.1078],\n",
            "        [0.4759, 0.8217, 0.7287],\n",
            "        [0.7685, 0.2914, 0.4680],\n",
            "        [0.0355, 0.6551, 0.5548]])\n",
            "Concatenated along columns (dim=1):\n",
            " tensor([[0.8429, 0.3490, 0.1078, 0.7685, 0.2914, 0.4680],\n",
            "        [0.4759, 0.8217, 0.7287, 0.0355, 0.6551, 0.5548]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 12. **Observation: Tensor Stacking**\n",
        "   - **Stacking** adds a new dimension to tensors by joining them along a new axis, often used when combining batch samples.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "Sl6HLtommM-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two tensors and stack them along a new dimension\n",
        "tensor1 = torch.rand(2, 3)\n",
        "tensor2 = torch.rand(2, 3)\n",
        "\n",
        "stacked = torch.stack((tensor1, tensor2), dim=0)  # Stack along a new axis\n",
        "print(\"Stacked tensor shape:\", stacked.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyZYCKWGm_lD",
        "outputId": "9df2697f-56fe-4f6e-d00e-d8047d6e6eef"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacked tensor shape: torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 13. **Observation: Tensor Transposition with `transpose()`**\n",
        "   - You can **transpose** tensors to swap dimensions, which is essential when working with different data formats.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "ZODkiK80mM7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2D tensor and transpose its dimensions\n",
        "tensor = torch.rand(3, 4)\n",
        "transposed = tensor.transpose(0, 1)  # Swap dimensions\n",
        "\n",
        "print(\"Original tensor shape:\", tensor.shape)\n",
        "print(\"Transposed tensor shape:\", transposed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSjJrSprm_vV",
        "outputId": "24510663-eecb-443d-81a1-9d36b84cd11f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor shape: torch.Size([3, 4])\n",
            "Transposed tensor shape: torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14. **Observation: Squeezing Out Extra Dimensions**\n",
        "   - The `.squeeze()` function removes dimensions of size 1 from a tensor, which is useful for reducing unnecessary dimensions.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "lO3bzhQ1mM25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with an extra dimension\n",
        "tensor = torch.rand(1, 3, 1, 4)\n",
        "\n",
        "squeezed = tensor.squeeze()  # Remove dimensions of size 1\n",
        "print(\"Original shape:\", tensor.shape)\n",
        "print(\"Squeezed shape:\", squeezed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5h5767qm_6b",
        "outputId": "3466c5e4-7b56-461c-d5b3-ecfbe44231bf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([1, 3, 1, 4])\n",
            "Squeezed shape: torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15. **Observation: Expanding Dimensions with `.expand()`**\n",
        "   - The `.expand()` function replicates data along a dimension, allowing the tensor to \"expand\" without copying data.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "Chx-w1yfmMy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 1D tensor\n",
        "tensor = torch.rand(3)\n",
        "\n",
        "# Expand along the first dimension\n",
        "expanded = tensor.unsqueeze(0).expand(5, 3)  # Replicate along new dimension\n",
        "print(\"Expanded tensor shape:\", expanded.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m08yUcB_nAFX",
        "outputId": "5fa8a949-367f-4ce5-8835-c35e67c50698"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanded tensor shape: torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16. **Observation: Calculating Basic Statistics on Tensors**\n",
        "   - PyTorch allows you to calculate basic statistics (mean, std, max, etc.) directly on tensors.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "YKG1wRMGmMv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(10)\n",
        "\n",
        "print(\"Mean:\", tensor.mean())\n",
        "print(\"Standard deviation:\", tensor.std())\n",
        "print(\"Max value:\", tensor.max())\n",
        "print(\"Min value:\", tensor.min())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFA7ZbdEnAQo",
        "outputId": "05ddb57d-78b3-4698-b68c-c48a1d41444c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor(0.5568)\n",
            "Standard deviation: tensor(0.3316)\n",
            "Max value: tensor(0.9480)\n",
            "Min value: tensor(0.0205)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 17. **Observation: Normalizing Tensors**\n",
        "   - Normalization ensures that the data is scaled to a specific range, often between 0 and 1 or with zero mean and unit variance.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "o_mx25DLmMsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize tensor to have values between 0 and 1\n",
        "tensor = torch.rand(5, 5)\n",
        "min_val = tensor.min()\n",
        "max_val = tensor.max()\n",
        "\n",
        "normalized_tensor = (tensor - min_val) / (max_val - min_val)\n",
        "print(\"Original tensor:\\n\", tensor)\n",
        "print(\"Normalized tensor:\\n\", normalized_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvM6Mt9ynAce",
        "outputId": "16fb7ba0-5403-44cd-8185-40020f5cf03c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            " tensor([[0.7233, 0.6234, 0.0753, 0.9029, 0.7256],\n",
            "        [0.1539, 0.4359, 0.1715, 0.9640, 0.0454],\n",
            "        [0.6139, 0.7571, 0.8677, 0.0027, 0.6088],\n",
            "        [0.3461, 0.4988, 0.0255, 0.4740, 0.4436],\n",
            "        [0.8906, 0.6684, 0.2413, 0.3218, 0.5840]])\n",
            "Normalized tensor:\n",
            " tensor([[0.7496, 0.6457, 0.0755, 0.9365, 0.7520],\n",
            "        [0.1573, 0.4506, 0.1756, 1.0000, 0.0444],\n",
            "        [0.6358, 0.7848, 0.8998, 0.0000, 0.6305],\n",
            "        [0.3572, 0.5160, 0.0237, 0.4902, 0.4586],\n",
            "        [0.9236, 0.6925, 0.2482, 0.3319, 0.6047]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 18. **Observation: Element-Wise Multiplication of Tensors**\n",
        "   - PyTorch supports element-wise operations such as multiplication, where corresponding elements in two tensors are multiplied.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "0GfbWzMqmMle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(3, 3)\n",
        "tensor2 = torch.rand(3, 3)\n",
        "\n",
        "elementwise_product = tensor1 * tensor2  # Element-wise multiplication\n",
        "print(\"Element-wise multiplication result:\\n\", elementwise_product)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBpXNeNwnAoN",
        "outputId": "a3c5d661-4532-47d0-e4f5-e44cf4ca92fa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element-wise multiplication result:\n",
            " tensor([[0.2287, 0.5928, 0.1999],\n",
            "        [0.1619, 0.1881, 0.0052],\n",
            "        [0.5981, 0.3062, 0.4026]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 19. **Observation: Cloning a Tensor**\n",
        "   - The `.clone()` function creates a copy of the tensor, which is independent of the original tensor.\n",
        "   - **Demonstration**:\n",
        "\n"
      ],
      "metadata": {
        "id": "Sa7DeQ-6mMcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(2, 3)\n",
        "\n",
        "tensor_clone = tensor.clone()  # Create a copy of the tensor\n",
        "tensor_clone[0, 0] = 999  # Modify the clone without affecting the original\n",
        "\n",
        "print(\"Original tensor:\\n\", tensor)\n",
        "print(\"Cloned and modified tensor:\\n\", tensor_clone)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC9W30YPnAzb",
        "outputId": "e5f104b2-808c-47f6-b0e3-8f1b04985636"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            " tensor([[0.7962, 0.7779, 0.0420],\n",
            "        [0.3859, 0.3467, 0.4566]])\n",
            "Cloned and modified tensor:\n",
            " tensor([[9.9900e+02, 7.7787e-01, 4.1979e-02],\n",
            "        [3.8589e-01, 3.4673e-01, 4.5663e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 20. **Observation: Moving Tensors Between Devices (CPU and GPU)**\n",
        "   - Tensors can be moved between the CPU and GPU using `.to()` to utilize GPU acceleration when available.\n",
        "   - **Demonstration**:\n"
      ],
      "metadata": {
        "id": "f14u57nWmqY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 3)\n",
        "\n",
        "# Check if a GPU is available and move the tensor to GPU\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = tensor.to('cuda')\n",
        "    print(\"Tensor moved to GPU:\\n\", tensor_gpu)\n",
        "else:\n",
        "    print(\"GPU not available, tensor remains on CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhIx3zUDnBAu",
        "outputId": "b74b845f-a660-4fb0-dd07-645a375bda06"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, tensor remains on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xK10uZPiowpj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}