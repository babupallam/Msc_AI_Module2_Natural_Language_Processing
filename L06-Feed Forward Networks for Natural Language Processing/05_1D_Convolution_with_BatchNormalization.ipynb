{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSpNavbo0Mw1A3jR85TiGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babupallam/Msc_AI_Module2_Natural_Language_Processing/blob/main/L06-Feed%20Forward%20Networks%20for%20Natural%20Language%20Processing/05_1D_Convolution_with_BatchNormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. **Introduction**\n",
        "\n",
        "- **What are 1D Convolutions?**\n",
        "  - **1D Convolutions** are applied to **sequential data** where the input is a sequence of vectors (like time series, text, or audio data).\n",
        "  - Each convolutional layer applies filters that slide across the sequence, capturing local dependencies between time steps or tokens.\n",
        "  \n",
        "- **Applications**:\n",
        "  - **Time-series data** (e.g., stock prices, sensor readings).\n",
        "  - **Natural Language Processing (NLP)** tasks (e.g., text classification, sentiment analysis).\n",
        "  - **Audio signal processing** (e.g., speech recognition).\n",
        "\n",
        "- **Why Batch Normalization?**\n",
        "  - **Batch Normalization** helps **stabilize learning** by normalizing the outputs of a layer, ensuring that activations are well-distributed across the network.\n",
        "  - It allows the model to use **higher learning rates** and accelerates training by reducing **internal covariate shift**.\n",
        "  - Additionally, it adds a slight regularization effect, making it less dependent on dropout.\n",
        "\n",
        "**Observation**:\n",
        "- Without normalization, neural networks may converge slowly, or the training may become unstable due to exploding or vanishing gradients.\n"
      ],
      "metadata": {
        "id": "Wcq3ml1-J13T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### 2. **Imports and Data Setup**\n",
        "\n",
        "- **Importing Required Libraries**:\n",
        "  - Import essential libraries like `torch` and `torch.nn` for building the convolutional neural network.\n",
        "  - PyTorch provides several modules, including `nn.Conv1d` for 1D convolutions and `nn.BatchNorm1d` for batch normalization.\n",
        "\n",
        "- **Creating Sample Input Data**:\n",
        "  - Create a random input tensor to simulate sequential data:\n",
        "    - **Batch size**: Number of independent sequences processed in parallel.\n",
        "    - **One-hot size**: Dimensionality of each input vector (e.g., size of one-hot encoded categories).\n",
        "    - **Sequence width**: Number of time steps in the sequence (e.g., words in a sentence, time steps in time series).\n",
        "\n",
        "**Code**:\n"
      ],
      "metadata": {
        "id": "fEjZeNfbJ18o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define parameters\n",
        "batch_size = 2\n",
        "one_hot_size = 10  # Represents the dimensionality of the one-hot encoding\n",
        "sequence_width = 7  # Represents the length of the sequence (e.g., time steps)\n",
        "\n",
        "# Create random input tensor\n",
        "data = torch.randn(batch_size, one_hot_size, sequence_width)\n",
        "print(\"Data shape:\", data.shape)  # Shape: (batch_size, one_hot_size, sequence_width)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IisYnub9lRO",
        "outputId": "e13fe9cb-25fb-476d-f834-448c555a3642"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: torch.Size([2, 10, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Explanation**:\n",
        "- **Batch size**: 2 sequences will be processed simultaneously.\n",
        "- **One-hot size**: The data has 10 features per time step.\n",
        "- **Sequence width**: The sequence is 7 time steps long.\n",
        "\n",
        "**Observation**:\n",
        "- Sequential data (e.g., text, time-series) can be modeled by using 1D convolutions, which slide across the time dimension.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Convolution Layers and Batch Normalization**\n",
        "\n",
        "- **Defining Convolutional Layers**:\n",
        "  - Use `nn.Conv1d` to define the convolutional layers. We define three layers in this case:\n",
        "    - **conv1**: Takes in `one_hot_size` input channels and produces 16 output channels (filters) with a kernel size of 3.\n",
        "    - **conv2**: Takes 16 input channels from `conv1` and produces 32 output channels.\n",
        "    - **conv3**: Takes 32 input channels from `conv2` and produces 64 output channels.\n",
        "\n",
        "**Code**:\n"
      ],
      "metadata": {
        "id": "NXZ40Up4J2Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=16, kernel_size=3)\n",
        "conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n"
      ],
      "metadata": {
        "id": "yO_g2-MQ9zGJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Applying Batch Normalization**:\n",
        "  - After each convolutional layer (except the last one), apply batch normalization to normalize the activations.\n",
        "  - ReLU activation is applied to add non-linearity between the layers.\n",
        "  - **conv1_bn** and **conv2_bn** normalize the activations of `conv1` and `conv2` respectively.\n",
        "\n",
        "**Code**:\n"
      ],
      "metadata": {
        "id": "UjGtIoGpJ2Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv1_bn = nn.BatchNorm1d(num_features=16)\n",
        "conv2_bn = nn.BatchNorm1d(num_features=32)\n",
        "\n",
        "# Forward pass with ReLU and batch normalization\n",
        "intermediate1 = conv1_bn(torch.relu(conv1(data)))\n",
        "intermediate2 = conv2_bn(torch.relu(conv2(intermediate1)))\n",
        "intermediate3 = conv3(intermediate2)  # No batch normalization on the last layer\n"
      ],
      "metadata": {
        "id": "jDA-TsDw92l2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Printing Intermediate Tensor Sizes**:\n",
        "  - Print the shapes of tensors after each layer to observe how the sequence width shrinks and the number of output channels increases.\n",
        "\n",
        "**Demonstration**:\n"
      ],
      "metadata": {
        "id": "-1fgr4DGJ2Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape after conv1 + batch norm + ReLU:\", intermediate1.shape)\n",
        "print(\"Shape after conv2 + batch norm + ReLU:\", intermediate2.shape)\n",
        "print(\"Shape after conv3:\", intermediate3.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEsrMSZT99Ip",
        "outputId": "ddf13dd3-047d-4ff5-dc59-c6aee5c207d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after conv1 + batch norm + ReLU: torch.Size([2, 16, 5])\n",
            "Shape after conv2 + batch norm + ReLU: torch.Size([2, 32, 3])\n",
            "Shape after conv3: torch.Size([2, 64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Observation**:\n",
        "- The sequence width shrinks as the convolutional layers apply filters across the time steps.\n",
        "- Batch normalization helps stabilize the values passed to the next layer, speeding up learning and improving the model's performance.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Exercise**\n",
        "\n",
        "- **Modifying the Kernel Size**:\n",
        "  - The **kernel size** defines the window size for each convolution operation.\n",
        "  - Change the kernel size in the convolutional layers and observe how it affects the output tensorâ€™s size.\n",
        "  \n",
        "**Task**:\n",
        "  - Modify the kernel size and print the resulting output shapes:\n"
      ],
      "metadata": {
        "id": "0qACGUIXJ2Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=16, kernel_size=2)  # Modify kernel size\n",
        "  conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=2)\n",
        "\n",
        "  intermediate1 = conv1_bn(torch.relu(conv1(data)))\n",
        "  intermediate2 = conv2_bn(torch.relu(conv2(intermediate1)))\n",
        "  print(\"Shape with kernel size 2:\", intermediate2.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLzWVne2-B4S",
        "outputId": "bdd55f5c-91b9-4c96-8d6d-eed5fb1d7945"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape with kernel size 2: torch.Size([2, 32, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  **Observation**:\n",
        "  - Smaller kernels may capture finer details in the sequence, but they may also lose long-range dependencies.\n",
        "\n",
        "- **Adding More Layers**:\n",
        "  - Add additional convolutional layers to make the architecture deeper.\n",
        "  - Observe how adding more layers increases the complexity of the model and can help it learn more abstract patterns.\n",
        "\n",
        "**Task**:\n",
        "  - Add more layers and apply ReLU activation:\n"
      ],
      "metadata": {
        "id": "oe0qgLVCJ3QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=1)\n",
        "intermediate4 = torch.relu(conv3(intermediate2))\n",
        "print(\"Shape after adding conv4:\", intermediate4.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gENdISF-E57",
        "outputId": "36c110b5-c9ff-4f76-fe32-e48d29f5ab88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after adding conv4: torch.Size([2, 64, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  **Observation**:\n",
        "  - Deeper architectures can model more complex dependencies in sequential data, but they require more computational power.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "_W91bPV7J3QM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Demonstration (using Code from the previous file)"
      ],
      "metadata": {
        "id": "2rifJGhe-gJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a more complex 1D CNN architecture with two convolutional layers, batch normalization, dropout, and two fully connected layers\n",
        "class Complex1DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Complex1DCNN, self).__init__()\n",
        "\n",
        "        # First 1D convolutional layer\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "\n",
        "        # Batch normalization after Conv1\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=16)  # Batch normalization for 16 channels (from Conv1)\n",
        "\n",
        "        # Second 1D convolutional layer\n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "\n",
        "        # Batch normalization after Conv2\n",
        "        self.bn2 = nn.BatchNorm1d(num_features=32)  # Batch normalization for 32 channels (from Conv2)\n",
        "\n",
        "        # Max pooling layer\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Dropout layer to reduce overfitting (p=0.5 means 50% chance of dropping a neuron)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32 * 5, 100)  # 32 channels with length reduced to 5 after pooling twice\n",
        "        self.fc2 = nn.Linear(100, 10)  # 10 output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial input dimensions\n",
        "        print(f\"Input Data:\\n{x}\")\n",
        "        print(f\" - Shape: {x.shape} (batch_size, channels, length)\")\n",
        "\n",
        "        # First convolution -> Batch Normalization -> ReLU -> Max Pooling\n",
        "        x = self.conv1(x)\n",
        "        print(f\"Values after Conv1:\\n{x}\")\n",
        "\n",
        "        # Apply batch normalization after Conv1\n",
        "        x = self.bn1(x)\n",
        "        print(f\"Values after BatchNorm1 (Conv1):\\n{x}\")\n",
        "\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        print(f\"Values after Max Pooling (Conv1):\\n{x}\")\n",
        "        print(f\" - Output shape after Max Pooling (Conv1): {x.shape} (batch_size, out_channels=16, length=10)\")\n",
        "\n",
        "        # Second convolution -> Batch Normalization -> ReLU -> Max Pooling\n",
        "        x = self.conv2(x)\n",
        "        print(f\"Values after Conv2:\\n{x}\")\n",
        "\n",
        "        # Apply batch normalization after Conv2\n",
        "        x = self.bn2(x)\n",
        "        print(f\"Values after BatchNorm2 (Conv2):\\n{x}\")\n",
        "\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        print(f\"Values after Max Pooling (Conv2):\\n{x}\")\n",
        "        print(f\" - Output shape after Max Pooling (Conv2): {x.shape} (batch_size, out_channels=32, length=5)\")\n",
        "\n",
        "        # Flatten the tensor before passing into fully connected layers\n",
        "        print(f\"\\nFlattening the tensor for Fully Connected layers\")\n",
        "        x = x.view(-1, 32 * 5)\n",
        "        print(f\"Values after Flattening:\\n{x}\")\n",
        "        print(f\" - Shape after flattening: {x.shape} (batch_size, flattened size)\")\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = self.fc1(x)\n",
        "        print(f\"Values after FC1:\\n{x}\")\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Apply dropout after the first fully connected layer\n",
        "        x = self.dropout(x)\n",
        "        print(f\"Values after Dropout:\\n{x} (note: some neurons will have values set to zero)\")\n",
        "\n",
        "        # Fully connected layer 2 (Output layer)\n",
        "        x = self.fc2(x)\n",
        "        print(f\"Values after FC2 (Output):\\n{x}\")\n",
        "        print(f\" - Output shape after FC2: {x.shape} (batch_size, neurons=10)\")\n",
        "\n",
        "        return x\n",
        "\n",
        "# Create an instance of the complex CNN model with batch normalization and dropout\n",
        "complex_model = Complex1DCNN()\n",
        "\n",
        "# Generate a random 1D input tensor\n",
        "input_data = torch.randn(1, 1, 20)\n",
        "print(f\"Input Data:\\n{input_data}\\n\")\n",
        "\n",
        "# Forward pass through the model\n",
        "output = complex_model(input_data)\n",
        "\n",
        "# Print the final output shape and values\n",
        "print(f\"\\nFinal Output Shape: {output.shape}\")\n",
        "print(f\"Final Output Values:\\n{output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kM6kvS2-oWC",
        "outputId": "c7bb511d-1cac-47c6-d45e-4c6c5e772a48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data:\n",
            "tensor([[[-1.2090, -0.5226,  0.6870,  0.2028,  1.3623, -1.5955,  1.1614,\n",
            "           1.6579, -0.0861, -2.3708,  0.3673, -0.0206,  0.1043,  1.5678,\n",
            "           1.3681, -1.1600,  0.5823, -0.3004,  0.2747,  1.0564]]])\n",
            "\n",
            "Input Data:\n",
            "tensor([[[-1.2090, -0.5226,  0.6870,  0.2028,  1.3623, -1.5955,  1.1614,\n",
            "           1.6579, -0.0861, -2.3708,  0.3673, -0.0206,  0.1043,  1.5678,\n",
            "           1.3681, -1.1600,  0.5823, -0.3004,  0.2747,  1.0564]]])\n",
            " - Shape: torch.Size([1, 1, 20]) (batch_size, channels, length)\n",
            "Values after Conv1:\n",
            "tensor([[[ 6.7277e-01,  1.4928e-01,  2.4794e-01,  2.7395e-01,  6.7104e-01,\n",
            "           6.1018e-01, -2.8030e-01,  5.0563e-01,  1.2253e+00,  5.9284e-01,\n",
            "           5.1939e-04,  4.9356e-01,  1.1820e-01,  3.6025e-02,  8.2193e-01,\n",
            "           6.8499e-01,  2.4799e-01,  5.2450e-01,  1.5545e-01,  3.9215e-01],\n",
            "         [-1.6731e-01, -4.8241e-04, -3.8558e-01, -3.2023e-01, -8.2194e-01,\n",
            "          -8.1485e-02, -1.6730e-01, -8.3561e-01, -8.2258e-01,  1.7423e-01,\n",
            "          -9.9927e-02, -3.7781e-01, -1.8219e-01, -5.0887e-01, -9.5667e-01,\n",
            "          -2.3413e-01, -3.3706e-01, -3.3230e-01, -2.3665e-01, -5.8851e-01],\n",
            "         [-6.4286e-01,  2.4205e-01,  1.3407e-02, -1.3823e-01, -6.9233e-01,\n",
            "          -6.7971e-01,  8.9458e-01, -5.4582e-01, -1.6375e+00, -5.0165e-01,\n",
            "           5.6550e-01, -4.2879e-01,  1.6310e-01,  2.5410e-01, -1.0501e+00,\n",
            "          -7.9637e-01,  7.7453e-02, -4.9224e-01,  1.3346e-01, -2.8309e-01],\n",
            "         [-9.5481e-01, -9.1485e-01, -2.3412e-01, -3.4015e-01,  3.0012e-01,\n",
            "          -1.0280e+00, -2.8430e-01,  4.8151e-01, -7.1942e-02, -1.5478e+00,\n",
            "          -6.4950e-01, -4.0662e-01, -5.0768e-01,  1.8083e-01,  4.8575e-01,\n",
            "          -7.9360e-01, -3.4669e-01, -5.0996e-01, -4.4091e-01,  6.8583e-02],\n",
            "         [ 3.1126e-01,  1.0007e+00,  5.4397e-01,  1.1807e+00, -6.0312e-01,\n",
            "           1.2257e+00,  1.3883e+00,  1.6094e-01, -9.7508e-01,  9.5472e-01,\n",
            "           5.7243e-01,  5.1027e-01,  1.3545e+00,  1.0675e+00, -4.4404e-01,\n",
            "           8.4636e-01,  3.1051e-01,  6.2498e-01,  1.0622e+00,  3.3525e-01],\n",
            "         [-6.0328e-02,  6.4065e-01, -1.3968e-02,  1.6172e-01, -1.0785e+00,\n",
            "           2.5092e-01,  7.8444e-01, -8.5262e-01, -1.5277e+00,  5.5522e-01,\n",
            "           5.4046e-01, -1.8027e-01,  4.8183e-01,  5.8845e-02, -1.3347e+00,\n",
            "          -6.6854e-02,  1.0727e-02, -1.2228e-01,  3.3463e-01, -4.1770e-01],\n",
            "         [-7.5711e-01, -2.2872e-01, -6.2226e-02, -2.9955e-01, -1.8206e-01,\n",
            "          -9.4260e-01,  4.0691e-01, -1.2203e-01, -9.2431e-01, -9.7778e-01,\n",
            "           1.5804e-01, -4.2918e-01, -1.7970e-01,  1.8660e-01, -3.8223e-01,\n",
            "          -8.7944e-01, -2.6945e-02, -5.2899e-01, -1.3260e-01, -1.2229e-01],\n",
            "         [-3.8021e-02,  1.8063e-01,  8.5220e-01, -2.7756e-01,  1.7842e+00,\n",
            "          -1.3859e+00,  8.0715e-01,  1.0091e+00,  8.8365e-01, -1.0379e+00,\n",
            "           1.3250e+00,  2.3772e-01, -2.0887e-01,  6.4801e-01,  1.1910e+00,\n",
            "          -8.9713e-01,  1.2022e+00, -5.4668e-02,  1.8966e-01,  9.0511e-01],\n",
            "         [-5.9550e-02, -3.0682e-01,  5.0844e-01,  2.2388e-01,  1.4343e+00,\n",
            "          -4.0728e-01,  1.2714e-01,  1.3626e+00,  1.2693e+00, -8.4013e-01,\n",
            "           5.2940e-02,  3.8974e-01, -1.6220e-02,  7.2763e-01,  1.5945e+00,\n",
            "          -5.5281e-02,  4.6612e-01,  2.6033e-01,  1.4021e-01,  8.8909e-01],\n",
            "         [ 7.9094e-01,  5.2953e-01,  3.8835e-02, -2.3146e-01, -5.9688e-03,\n",
            "           3.5418e-01, -2.1600e-01, -5.8868e-01,  4.1128e-01,  1.0721e+00,\n",
            "           5.5162e-01,  1.5485e-01, -1.0010e-01, -6.3450e-01, -3.5029e-01,\n",
            "           3.0104e-01,  2.9557e-01,  1.8640e-01, -1.2692e-02, -2.1168e-01],\n",
            "         [ 4.3830e-01,  6.1308e-01,  1.3414e-01,  3.8257e-01, -4.7218e-01,\n",
            "           7.5235e-01,  4.0141e-01, -3.3515e-01, -3.8207e-01,  9.3064e-01,\n",
            "           3.4447e-01,  2.1793e-01,  5.1529e-01,  7.8871e-02, -5.1254e-01,\n",
            "           5.2087e-01,  1.1953e-01,  3.0584e-01,  3.9359e-01, -7.7574e-02],\n",
            "         [-7.7340e-01, -5.1588e-01, -3.6187e-01,  5.0492e-01, -8.7318e-01,\n",
            "           3.9853e-01,  2.6136e-02,  1.7506e-01, -9.4800e-01, -5.3879e-01,\n",
            "          -1.1054e+00, -2.1050e-01,  3.5819e-01,  4.9495e-01, -2.2837e-01,\n",
            "           1.8820e-01, -8.1507e-01, -9.8001e-02,  5.2503e-02, -1.4990e-01],\n",
            "         [-1.1545e+00, -4.2880e-02,  3.4287e-01,  4.8437e-01, -2.1363e-01,\n",
            "          -7.2235e-01,  1.4350e+00,  5.7248e-01, -1.5828e+00, -1.3858e+00,\n",
            "           2.6039e-01, -2.1168e-01,  6.0620e-01,  1.3378e+00, -1.5532e-01,\n",
            "          -7.5045e-01,  1.1310e-01, -3.1511e-01,  4.9034e-01,  3.6798e-01],\n",
            "         [ 6.1761e-01,  1.5766e+00,  4.6947e-01,  7.3686e-01, -1.1585e+00,\n",
            "           1.0611e+00,  1.5887e+00, -9.0633e-01, -1.6733e+00,  1.6419e+00,\n",
            "           1.3655e+00,  2.8750e-01,  1.2309e+00,  4.4305e-01, -1.5732e+00,\n",
            "           5.5384e-01,  5.4015e-01,  3.9701e-01,  1.0098e+00, -1.8033e-01],\n",
            "         [ 3.6536e-01,  1.8921e-01,  7.0300e-01,  1.6599e-01,  1.4852e+00,\n",
            "          -3.1525e-01,  3.8160e-01,  1.0706e+00,  1.2882e+00, -2.7300e-01,\n",
            "           6.9981e-01,  5.1328e-01,  7.6947e-02,  5.7996e-01,  1.3301e+00,\n",
            "           4.5401e-03,  8.4275e-01,  3.7135e-01,  2.9810e-01,  8.7152e-01],\n",
            "         [-1.1975e+00, -6.9089e-01, -9.4343e-02,  8.3026e-01, -4.7848e-01,\n",
            "           1.3316e-01,  5.0514e-01,  9.1377e-01, -1.0048e+00, -1.2920e+00,\n",
            "          -1.1458e+00, -1.1890e-01,  6.0302e-01,  1.2475e+00,  3.3945e-01,\n",
            "           1.9330e-02, -6.9416e-01, -6.7992e-02,  2.8035e-01,  3.0232e-01]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "Values after BatchNorm1 (Conv1):\n",
            "tensor([[[ 7.9655e-01, -7.7356e-01, -4.7766e-01, -3.9966e-01,  7.9136e-01,\n",
            "           6.0881e-01, -2.0620e+00,  2.9525e-01,  2.4537e+00,  5.5679e-01,\n",
            "          -1.2197e+00,  2.5903e-01, -8.6678e-01, -1.1133e+00,  1.2439e+00,\n",
            "           8.3319e-01, -4.7752e-01,  3.5181e-01, -7.5507e-01, -4.5114e-02],\n",
            "         [ 6.5888e-01,  1.2174e+00, -7.1831e-02,  1.4692e-01, -1.5327e+00,\n",
            "           9.4621e-01,  6.5891e-01, -1.5785e+00, -1.5348e+00,  1.8023e+00,\n",
            "           8.8447e-01, -4.5839e-02,  6.0907e-01, -4.8459e-01, -1.9837e+00,\n",
            "           4.3518e-01,  9.0594e-02,  1.0654e-01,  4.2676e-01, -7.5121e-01],\n",
            "         [-6.3623e-01,  9.0369e-01,  5.0580e-01,  2.4192e-01, -7.2232e-01,\n",
            "          -7.0036e-01,  2.0392e+00, -4.6737e-01, -2.3670e+00, -3.9050e-01,\n",
            "           1.4665e+00, -2.6370e-01,  7.6629e-01,  9.2465e-01, -1.3449e+00,\n",
            "          -9.0336e-01,  6.1725e-01, -3.7413e-01,  7.1472e-01, -1.0158e-02],\n",
            "         [-1.1271e+00, -1.0494e+00,  2.7558e-01,  6.9217e-02,  1.3154e+00,\n",
            "          -1.2697e+00,  1.7791e-01,  1.6685e+00,  5.9124e-01, -2.2813e+00,\n",
            "          -5.3290e-01, -6.0172e-02, -2.5686e-01,  1.0832e+00,  1.6767e+00,\n",
            "          -8.1337e-01,  5.6478e-02, -2.6131e-01, -1.2691e-01,  8.6475e-01],\n",
            "         [-4.0768e-01,  6.7274e-01, -4.2986e-02,  9.5483e-01, -1.8406e+00,\n",
            "           1.0253e+00,  1.2802e+00, -6.4326e-01, -2.4236e+00,  6.0072e-01,\n",
            "           1.6260e-03, -9.5791e-02,  1.2273e+00,  7.7746e-01, -1.5913e+00,\n",
            "           4.3091e-01, -4.0886e-01,  8.3978e-02,  7.6914e-01, -3.7008e-01],\n",
            "         [ 4.9325e-02,  1.1487e+00,  1.2204e-01,  3.9758e-01, -1.5476e+00,\n",
            "           5.3748e-01,  1.3743e+00, -1.1933e+00, -2.2521e+00,  1.0147e+00,\n",
            "           9.9161e-01, -1.3879e-01,  8.9965e-01,  2.3623e-01, -1.9494e+00,\n",
            "           3.9090e-02,  1.6077e-01, -4.7842e-02,  6.6878e-01, -5.1118e-01],\n",
            "         [-1.1113e+00,  2.3609e-01,  6.6065e-01,  5.5490e-02,  3.5507e-01,\n",
            "          -1.5842e+00,  1.8569e+00,  5.0814e-01, -1.5376e+00, -1.6739e+00,\n",
            "           1.2223e+00, -2.7505e-01,  3.6109e-01,  1.2951e+00, -1.5534e-01,\n",
            "          -1.4232e+00,  7.5061e-01, -5.2956e-01,  4.8120e-01,  5.0749e-01],\n",
            "         [-4.8976e-01, -2.2457e-01,  5.8995e-01, -7.8029e-01,  1.7203e+00,\n",
            "          -2.1245e+00,  5.3531e-01,  7.8029e-01,  6.2809e-01, -1.7024e+00,\n",
            "           1.1634e+00, -1.5533e-01, -6.9698e-01,  3.4229e-01,  1.0009e+00,\n",
            "          -1.5317e+00,  1.0145e+00, -5.0995e-01, -2.1362e-01,  6.5412e-01],\n",
            "         [-7.0191e-01, -1.0897e+00,  1.8881e-01, -2.5745e-01,  1.6407e+00,\n",
            "          -1.2472e+00, -4.0915e-01,  1.5282e+00,  1.3819e+00, -1.9260e+00,\n",
            "          -5.2550e-01,  2.6554e-03, -6.3396e-01,  5.3252e-01,  1.8920e+00,\n",
            "          -6.9521e-01,  1.2244e-01, -2.0028e-01, -3.8864e-01,  7.8573e-01],\n",
            "         [ 1.5788e+00,  9.6665e-01, -1.8245e-01, -8.1542e-01, -2.8737e-01,\n",
            "           5.5602e-01, -7.7920e-01, -1.6519e+00,  6.8974e-01,  2.2371e+00,\n",
            "           1.0184e+00,  8.9220e-02, -5.0781e-01, -1.7592e+00, -1.0937e+00,\n",
            "           4.3158e-01,  4.1877e-01,  1.6311e-01, -3.0311e-01, -7.6910e-01],\n",
            "         [ 5.5899e-01,  1.0034e+00, -2.1443e-01,  4.1728e-01, -1.7562e+00,\n",
            "           1.3576e+00,  4.6518e-01, -1.4078e+00, -1.5271e+00,  1.8109e+00,\n",
            "           3.2041e-01, -1.3729e-03,  7.5477e-01, -3.5497e-01, -1.8588e+00,\n",
            "           7.6895e-01, -2.5159e-01,  2.2218e-01,  4.4531e-01, -7.5278e-01],\n",
            "         [-1.1228e+00, -5.9936e-01, -2.8633e-01,  1.4754e+00, -1.3256e+00,\n",
            "           1.2592e+00,  5.0229e-01,  8.0497e-01, -1.4776e+00, -6.4593e-01,\n",
            "          -1.7975e+00,  2.1328e-02,  1.1772e+00,  1.4552e+00, -1.5003e-02,\n",
            "           8.3167e-01, -1.2075e+00,  2.4998e-01,  5.5588e-01,  1.4451e-01],\n",
            "         [-1.4330e+00, -2.1188e-02,  4.6874e-01,  6.4846e-01, -2.3805e-01,\n",
            "          -8.8416e-01,  1.8559e+00,  7.6036e-01, -1.9770e+00, -1.7268e+00,\n",
            "           3.6399e-01, -2.3558e-01,  8.0318e-01,  1.7324e+00, -1.6399e-01,\n",
            "          -9.1985e-01,  1.7691e-01, -3.6694e-01,  6.5603e-01,  5.0063e-01],\n",
            "         [ 2.1807e-01,  1.1853e+00,  6.8651e-02,  3.3834e-01, -1.5734e+00,\n",
            "           6.6535e-01,  1.1976e+00, -1.3190e+00, -2.0926e+00,  1.2512e+00,\n",
            "           9.7240e-01, -1.1490e-01,  8.3663e-01,  4.2002e-02, -1.9917e+00,\n",
            "           1.5375e-01,  1.3993e-01, -4.4372e-03,  6.1361e-01, -5.8677e-01],\n",
            "         [-3.3715e-01, -6.9255e-01,  3.4408e-01, -7.3940e-01,  1.9223e+00,\n",
            "          -1.7104e+00, -3.0438e-01,  1.0858e+00,  1.5247e+00, -1.6251e+00,\n",
            "           3.3763e-01, -3.8701e-02, -9.1906e-01,  9.5835e-02,  1.6092e+00,\n",
            "          -1.0651e+00,  6.2604e-01, -3.2506e-01, -4.7285e-01,  6.8407e-01],\n",
            "         [-1.5405e+00, -8.4180e-01, -1.9055e-02,  1.2561e+00, -5.4884e-01,\n",
            "           2.9471e-01,  8.0773e-01,  1.3713e+00, -1.2747e+00, -1.6709e+00,\n",
            "          -1.4691e+00, -5.2917e-02,  9.4272e-01,  1.8316e+00,  5.7922e-01,\n",
            "           1.3772e-01, -8.4630e-01,  1.7288e-02,  4.9770e-01,  5.2800e-01]]],\n",
            "       grad_fn=<NativeBatchNormBackward0>)\n",
            "Values after Max Pooling (Conv1):\n",
            "tensor([[[7.9655e-01, 0.0000e+00, 7.9136e-01, 2.9525e-01, 2.4537e+00,\n",
            "          2.5903e-01, 0.0000e+00, 1.2439e+00, 3.5181e-01, 0.0000e+00],\n",
            "         [1.2174e+00, 1.4692e-01, 9.4621e-01, 6.5891e-01, 1.8023e+00,\n",
            "          8.8447e-01, 6.0907e-01, 4.3518e-01, 1.0654e-01, 4.2676e-01],\n",
            "         [9.0369e-01, 5.0580e-01, 0.0000e+00, 2.0392e+00, 0.0000e+00,\n",
            "          1.4665e+00, 9.2465e-01, 0.0000e+00, 6.1725e-01, 7.1472e-01],\n",
            "         [0.0000e+00, 2.7558e-01, 1.3154e+00, 1.6685e+00, 5.9124e-01,\n",
            "          0.0000e+00, 1.0832e+00, 1.6767e+00, 5.6478e-02, 8.6475e-01],\n",
            "         [6.7274e-01, 9.5483e-01, 1.0253e+00, 1.2802e+00, 6.0072e-01,\n",
            "          1.6260e-03, 1.2273e+00, 4.3091e-01, 8.3978e-02, 7.6914e-01],\n",
            "         [1.1487e+00, 3.9758e-01, 5.3748e-01, 1.3743e+00, 1.0147e+00,\n",
            "          9.9161e-01, 8.9965e-01, 3.9090e-02, 1.6077e-01, 6.6878e-01],\n",
            "         [2.3609e-01, 6.6065e-01, 3.5507e-01, 1.8569e+00, 0.0000e+00,\n",
            "          1.2223e+00, 1.2951e+00, 0.0000e+00, 7.5061e-01, 5.0749e-01],\n",
            "         [0.0000e+00, 5.8995e-01, 1.7203e+00, 7.8029e-01, 6.2809e-01,\n",
            "          1.1634e+00, 3.4229e-01, 1.0009e+00, 1.0145e+00, 6.5412e-01],\n",
            "         [0.0000e+00, 1.8881e-01, 1.6407e+00, 1.5282e+00, 1.3819e+00,\n",
            "          2.6554e-03, 5.3252e-01, 1.8920e+00, 1.2244e-01, 7.8573e-01],\n",
            "         [1.5788e+00, 0.0000e+00, 5.5602e-01, 0.0000e+00, 2.2371e+00,\n",
            "          1.0184e+00, 0.0000e+00, 4.3158e-01, 4.1877e-01, 0.0000e+00],\n",
            "         [1.0034e+00, 4.1728e-01, 1.3576e+00, 4.6518e-01, 1.8109e+00,\n",
            "          3.2041e-01, 7.5477e-01, 7.6895e-01, 2.2218e-01, 4.4531e-01],\n",
            "         [0.0000e+00, 1.4754e+00, 1.2592e+00, 8.0497e-01, 0.0000e+00,\n",
            "          2.1328e-02, 1.4552e+00, 8.3167e-01, 2.4998e-01, 5.5588e-01],\n",
            "         [0.0000e+00, 6.4846e-01, 0.0000e+00, 1.8559e+00, 0.0000e+00,\n",
            "          3.6399e-01, 1.7324e+00, 0.0000e+00, 1.7691e-01, 6.5603e-01],\n",
            "         [1.1853e+00, 3.3834e-01, 6.6535e-01, 1.1976e+00, 1.2512e+00,\n",
            "          9.7240e-01, 8.3663e-01, 1.5375e-01, 1.3993e-01, 6.1361e-01],\n",
            "         [0.0000e+00, 3.4408e-01, 1.9223e+00, 1.0858e+00, 1.5247e+00,\n",
            "          3.3763e-01, 9.5835e-02, 1.6092e+00, 6.2604e-01, 6.8407e-01],\n",
            "         [0.0000e+00, 1.2561e+00, 2.9471e-01, 1.3713e+00, 0.0000e+00,\n",
            "          0.0000e+00, 1.8316e+00, 5.7922e-01, 1.7288e-02, 5.2800e-01]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            " - Output shape after Max Pooling (Conv1): torch.Size([1, 16, 10]) (batch_size, out_channels=16, length=10)\n",
            "Values after Conv2:\n",
            "tensor([[[-2.9549e-01,  4.5526e-02, -2.4075e-01, -6.7399e-02,  5.4297e-01,\n",
            "          -1.3473e-01, -9.3207e-03,  3.2200e-01, -6.0451e-02, -2.4665e-01],\n",
            "         [-2.4617e-02,  2.8669e-02,  6.3477e-01,  6.0860e-01,  4.4234e-01,\n",
            "           4.1062e-02,  1.3511e-01,  6.0030e-01,  3.8127e-01,  3.6677e-01],\n",
            "         [-3.8567e-01, -1.4050e-01,  1.7374e-01,  1.2120e+00,  2.6441e-01,\n",
            "           2.1957e-01, -1.0275e-01,  3.6796e-01,  7.1146e-01,  3.4798e-01],\n",
            "         [-3.1889e-01,  4.0702e-01, -1.2458e-01,  2.0942e-01, -3.5871e-01,\n",
            "           2.0026e-01,  3.5038e-01,  2.2137e-01,  4.8303e-02, -4.2483e-02],\n",
            "         [ 3.4211e-01,  4.0611e-01,  1.3835e+00,  1.0215e+00,  1.3786e+00,\n",
            "           1.9106e-01,  3.8003e-01,  8.6043e-01,  2.7543e-01,  5.2428e-01],\n",
            "         [-7.4266e-02, -7.5701e-02, -7.4112e-01, -3.8746e-02, -7.2776e-01,\n",
            "           5.7665e-01, -1.7868e-01, -4.9037e-01,  5.5424e-02,  2.2087e-02],\n",
            "         [ 2.8631e-01, -3.1047e-01,  9.4803e-01,  7.4026e-01,  6.8016e-01,\n",
            "           3.3278e-01, -8.5871e-02,  5.6192e-01,  5.8421e-02,  4.2867e-01],\n",
            "         [ 9.8480e-03, -2.2813e-01,  4.6654e-02,  3.3692e-01,  5.8668e-01,\n",
            "          -5.0715e-03, -6.8542e-02,  6.9477e-01, -8.5705e-02,  1.5104e-01],\n",
            "         [ 1.0940e-03,  1.1112e-02,  5.0267e-01, -1.7809e-01,  7.0169e-02,\n",
            "          -6.6739e-02,  9.3882e-02,  7.1876e-01,  2.2195e-01,  6.0868e-02],\n",
            "         [ 2.4608e-01, -4.6254e-01, -1.7170e-01,  8.2869e-02,  1.0695e+00,\n",
            "           5.0630e-02, -3.1419e-01,  3.1365e-01,  3.5001e-01,  2.0252e-01],\n",
            "         [ 4.7092e-01,  1.9207e-01,  1.0068e+00,  5.4804e-01,  8.8278e-01,\n",
            "           4.7960e-01,  7.6240e-01,  8.3004e-01, -1.6989e-01,  5.4246e-01],\n",
            "         [-4.1819e-01, -1.7117e-01, -1.3974e-01, -2.6668e-01,  1.9295e-01,\n",
            "          -8.6244e-02, -1.0547e-01,  2.3588e-01, -1.0425e-01,  2.0923e-01],\n",
            "         [ 3.0604e-02,  3.2977e-02, -5.7586e-01,  3.6516e-01, -1.8880e-01,\n",
            "           1.1913e-02,  2.1503e-01, -1.2012e-01,  3.0041e-01, -1.9690e-03],\n",
            "         [-1.5584e-01,  3.7755e-01,  1.1923e-01, -7.9912e-02, -1.8698e-02,\n",
            "           4.1614e-01,  3.2022e-01,  1.2743e-01,  2.9654e-02, -1.6734e-02],\n",
            "         [ 7.1372e-01, -6.6826e-02,  1.6003e-01,  2.9992e-01,  9.3543e-01,\n",
            "           1.3693e-01, -1.5042e-01,  4.2107e-01, -2.1642e-01,  1.8668e-01],\n",
            "         [ 8.7558e-01,  1.4173e+00,  9.6420e-01,  1.3995e+00,  8.5736e-01,\n",
            "           1.5653e+00,  8.6287e-01,  9.0493e-01,  6.7898e-01,  3.1085e-01],\n",
            "         [ 5.9523e-01, -6.3053e-01,  5.7153e-01, -7.7810e-02,  4.9753e-01,\n",
            "          -1.6701e-01, -3.2695e-01,  3.0222e-01,  2.5008e-01,  3.4000e-01],\n",
            "         [ 3.2160e-01, -6.5943e-02,  6.7757e-01,  2.7080e-01, -5.1292e-02,\n",
            "          -5.3109e-01,  3.1249e-02,  7.2999e-01, -2.1964e-01,  1.2100e-01],\n",
            "         [-3.0128e-01, -2.9538e-01, -5.4471e-01, -1.1096e+00, -2.9361e-01,\n",
            "          -8.8502e-01, -4.8231e-01, -9.9374e-02, -5.0971e-01, -3.0367e-01],\n",
            "         [-4.3259e-01, -3.3747e-01, -1.1339e+00, -1.6421e-01, -8.0866e-01,\n",
            "          -3.1420e-01, -1.3636e-01, -8.0415e-01, -2.8810e-01, -2.6962e-01],\n",
            "         [ 2.3651e-01,  2.1932e-01,  1.5535e-01, -2.8383e-01,  3.0981e-02,\n",
            "          -2.3393e-01, -8.7158e-02, -1.5823e-01,  6.5070e-02, -3.9820e-01],\n",
            "         [-3.9405e-01, -1.7846e-01, -3.1869e-01,  3.1387e-01, -4.1244e-01,\n",
            "           4.7794e-03, -1.6554e-01, -1.3890e-01,  1.0982e-01,  5.7711e-02],\n",
            "         [ 1.8365e-01,  1.6307e-01,  4.1332e-02,  8.0520e-02,  5.0867e-01,\n",
            "           5.2166e-01,  3.7391e-01,  2.1111e-01,  2.4211e-01,  1.3353e-01],\n",
            "         [ 2.6411e-01,  3.7723e-01,  2.2440e-01, -6.2626e-01,  1.7770e-01,\n",
            "           6.7235e-01, -2.1197e-01,  7.5466e-02, -1.4770e-02, -2.1756e-01],\n",
            "         [-1.5972e-01,  2.6199e-01,  3.3376e-01,  2.6948e-03, -5.1401e-01,\n",
            "           5.4568e-01,  2.5969e-01, -6.4368e-02,  2.1459e-01,  3.5139e-01],\n",
            "         [ 3.9430e-01,  6.3960e-01,  9.2510e-01,  1.3569e+00,  8.3331e-01,\n",
            "           1.0793e+00,  4.5936e-01,  8.1842e-01,  6.5614e-01,  3.2579e-01],\n",
            "         [ 7.9225e-01, -5.0679e-01,  5.8618e-01, -7.5622e-01, -1.3198e-01,\n",
            "           7.8256e-01, -8.2888e-01, -3.6719e-01,  2.3057e-01, -2.0175e-01],\n",
            "         [-7.7183e-02, -1.7329e-01,  1.6621e-01, -2.7861e-01,  3.0441e-01,\n",
            "          -8.5681e-02,  8.2177e-02,  6.5781e-01, -1.8127e-01,  1.6616e-02],\n",
            "         [-7.2856e-02, -5.1951e-01, -4.4091e-01, -8.0571e-01, -9.8891e-01,\n",
            "          -2.1766e-01, -4.3462e-01, -1.0727e+00, -4.3095e-01, -1.5381e-01],\n",
            "         [-9.8442e-01, -5.5235e-01, -4.6613e-01, -9.3709e-01, -3.3874e-01,\n",
            "          -9.3235e-01, -6.3950e-01,  1.1566e-01, -3.1770e-01, -2.4900e-01],\n",
            "         [-2.3371e-01, -1.3562e-01,  2.2125e-01,  4.2857e-01,  7.5498e-02,\n",
            "          -3.8800e-02, -4.4528e-01,  4.7437e-01,  7.9089e-02, -3.7568e-02],\n",
            "         [-3.4673e-02, -1.8533e-01, -9.2261e-02, -3.2248e-01,  1.6791e-01,\n",
            "          -5.8590e-01, -3.7142e-01,  2.1194e-01, -6.8643e-02,  2.0437e-01]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "Values after BatchNorm2 (Conv2):\n",
            "tensor([[[-1.1188e+00,  2.3865e-01, -9.0085e-01, -2.1085e-01,  2.2187e+00,\n",
            "          -4.7886e-01,  2.0334e-02,  1.3392e+00, -1.8319e-01, -9.2435e-01],\n",
            "         [-1.4156e+00, -1.1976e+00,  1.2818e+00,  1.1748e+00,  4.9463e-01,\n",
            "          -1.1469e+00, -7.6218e-01,  1.1408e+00,  2.4481e-01,  1.8550e-01],\n",
            "         [-1.5182e+00, -9.4774e-01, -2.1658e-01,  2.1992e+00, -5.6045e-03,\n",
            "          -1.0995e-01, -8.5989e-01,  2.3531e-01,  1.0345e+00,  1.8883e-01],\n",
            "         [-1.4987e+00,  1.3787e+00, -7.2850e-01,  5.9542e-01, -1.6566e+00,\n",
            "           5.5910e-01,  1.1541e+00,  6.4277e-01, -4.3233e-02, -4.0309e-01],\n",
            "         [-7.7948e-01, -6.3019e-01,  1.6494e+00,  8.0517e-01,  1.6380e+00,\n",
            "          -1.1318e+00, -6.9103e-01,  4.2942e-01, -9.3498e-01, -3.5459e-01],\n",
            "         [ 2.4670e-01,  2.4290e-01, -1.5226e+00,  3.4095e-01, -1.4872e+00,\n",
            "           1.9738e+00, -3.0324e-02, -8.5732e-01,  5.9080e-01,  5.0235e-01],\n",
            "         [-2.0890e-01, -1.8132e+00,  1.5700e+00,  1.0114e+00,  8.4986e-01,\n",
            "          -8.3975e-02, -1.2094e+00,  5.3200e-01, -8.2153e-01,  1.7380e-01],\n",
            "         [-4.6715e-01, -1.2968e+00, -3.3883e-01,  6.7310e-01,  1.5438e+00,\n",
            "          -5.1916e-01, -7.4043e-01,  1.9206e+00, -8.0027e-01,  2.5080e-02],\n",
            "         [-5.5196e-01, -5.1315e-01,  1.3912e+00, -1.2461e+00, -2.8435e-01,\n",
            "          -8.1475e-01, -1.9249e-01,  2.2284e+00,  3.0365e-01, -3.2039e-01],\n",
            "         [ 2.7088e-01, -1.4837e+00, -7.6357e-01, -1.3324e-01,  2.3096e+00,\n",
            "          -2.1306e-01, -1.1164e+00,  4.3819e-01,  5.2823e-01,  1.6303e-01],\n",
            "         [-2.5202e-01, -1.0926e+00,  1.3634e+00, -1.9533e-02,  9.8953e-01,\n",
            "          -2.2585e-01,  6.2664e-01,  8.3054e-01, -2.1837e+00, -3.6361e-02],\n",
            "         [-1.7252e+00, -5.1731e-01, -3.6365e-01, -9.8433e-01,  1.2631e+00,\n",
            "          -1.0206e-01, -1.9608e-01,  1.4730e+00, -1.9008e-01,  1.3427e+00],\n",
            "         [ 9.2602e-02,  1.0189e-01, -2.2801e+00,  1.4015e+00, -7.6580e-01,\n",
            "           1.9474e-02,  8.1416e-01, -4.9707e-01,  1.1482e+00, -3.4837e-02],\n",
            "         [-1.4195e+00,  1.4084e+00,  3.8819e-02, -1.0170e+00, -6.9242e-01,\n",
            "           1.6130e+00,  1.1045e+00,  8.2295e-02, -4.3606e-01, -6.8200e-01],\n",
            "         [ 1.3509e+00, -8.8448e-01, -2.3479e-01,  1.6584e-01,  1.9859e+00,\n",
            "          -3.0095e-01, -1.1239e+00,  5.1281e-01, -1.3129e+00, -1.5847e-01],\n",
            "         [-3.0058e-01,  1.2055e+00, -5.4163e-02,  1.1560e+00, -3.5122e-01,\n",
            "           1.6171e+00, -3.3589e-01, -2.1896e-01, -8.4718e-01, -1.8707e+00],\n",
            "         [ 1.1667e+00, -1.9436e+00,  1.1066e+00, -5.4109e-01,  9.1883e-01,\n",
            "          -7.6742e-01, -1.1733e+00,  4.2323e-01,  2.9093e-01,  5.1911e-01],\n",
            "         [ 5.2444e-01, -5.2767e-01,  1.4908e+00,  3.8652e-01, -4.8789e-01,\n",
            "          -1.7905e+00, -2.6381e-01,  1.6331e+00, -9.4493e-01, -2.0153e-02],\n",
            "         [ 6.2430e-01,  6.4462e-01, -2.1444e-01, -2.1609e+00,  6.5072e-01,\n",
            "          -1.3870e+00,  5.6243e-04,  1.3200e+00, -9.3853e-02,  6.1605e-01],\n",
            "         [ 1.1556e-01,  4.1811e-01, -2.1151e+00,  9.6919e-01, -1.0805e+00,\n",
            "           4.9211e-01,  1.0578e+00, -1.0662e+00,  5.7514e-01,  6.3392e-01],\n",
            "         [ 1.3450e+00,  1.2630e+00,  9.5783e-01, -1.1375e+00,  3.6447e-01,\n",
            "          -8.9942e-01, -1.9917e-01, -5.3826e-01,  5.2711e-01, -1.6831e+00],\n",
            "         [-1.2686e+00, -2.9827e-01, -9.2941e-01,  1.9176e+00, -1.3514e+00,\n",
            "           5.2645e-01, -2.4011e-01, -1.2022e-01,  9.9923e-01,  7.6469e-01],\n",
            "         [-3.8989e-01, -5.1866e-01, -1.2805e+00, -1.0353e+00,  1.6440e+00,\n",
            "           1.7253e+00,  8.0067e-01, -2.1806e-01, -2.4059e-02, -7.0355e-01],\n",
            "         [ 5.5796e-01,  8.8664e-01,  4.4259e-01, -2.0290e+00,  3.0690e-01,\n",
            "           1.7441e+00, -8.2527e-01,  9.8664e-03, -2.5231e-01, -8.4153e-01],\n",
            "         [-9.6631e-01,  4.7420e-01,  7.1935e-01, -4.1153e-01, -2.1765e+00,\n",
            "           1.4433e+00,  4.6633e-01, -6.4061e-01,  3.1228e-01,  7.7956e-01],\n",
            "         [-1.1618e+00, -3.5794e-01,  5.7767e-01,  1.9928e+00,  2.7687e-01,\n",
            "           1.0831e+00, -9.4864e-01,  2.2807e-01, -3.0375e-01, -1.3864e+00],\n",
            "         [ 1.4425e+00, -8.0875e-01,  1.0854e+00, -1.2410e+00, -1.5919e-01,\n",
            "           1.4258e+00, -1.3669e+00, -5.6682e-01,  4.6912e-01, -2.8010e-01],\n",
            "         [-4.5622e-01, -8.2069e-01,  4.6678e-01, -1.2201e+00,  9.9089e-01,\n",
            "          -4.8845e-01,  1.4811e-01,  2.3311e+00, -8.5093e-01, -1.0051e-01],\n",
            "         [ 1.3583e+00, -1.7690e-02,  2.2446e-01, -8.9937e-01, -1.4638e+00,\n",
            "           9.1223e-01,  2.4382e-01, -1.7220e+00,  2.5514e-01,  1.1089e+00],\n",
            "         [-1.3524e+00, -6.6058e-02,  1.9064e-01, -1.2115e+00,  5.6990e-01,\n",
            "          -1.1974e+00, -3.2552e-01,  1.9227e+00,  6.3252e-01,  8.3706e-01],\n",
            "         [-1.0093e+00, -6.4598e-01,  6.7588e-01,  1.4438e+00,  1.3600e-01,\n",
            "          -2.8736e-01, -1.7930e+00,  1.6134e+00,  1.4931e-01, -2.8279e-01],\n",
            "         [ 2.9003e-01, -3.0873e-01,  6.1160e-02, -8.5382e-01,  1.0952e+00,\n",
            "          -1.9007e+00, -1.0483e+00,  1.2702e+00,  1.5503e-01,  1.2401e+00]]],\n",
            "       grad_fn=<NativeBatchNormBackward0>)\n",
            "Values after Max Pooling (Conv2):\n",
            "tensor([[[0.2387, 0.0000, 2.2187, 1.3392, 0.0000],\n",
            "         [0.0000, 1.2818, 0.4946, 1.1408, 0.2448],\n",
            "         [0.0000, 2.1992, 0.0000, 0.2353, 1.0345],\n",
            "         [1.3787, 0.5954, 0.5591, 1.1541, 0.0000],\n",
            "         [0.0000, 1.6494, 1.6380, 0.4294, 0.0000],\n",
            "         [0.2467, 0.3409, 1.9738, 0.0000, 0.5908],\n",
            "         [0.0000, 1.5700, 0.8499, 0.5320, 0.1738],\n",
            "         [0.0000, 0.6731, 1.5438, 1.9206, 0.0251],\n",
            "         [0.0000, 1.3912, 0.0000, 2.2284, 0.3036],\n",
            "         [0.2709, 0.0000, 2.3096, 0.4382, 0.5282],\n",
            "         [0.0000, 1.3634, 0.9895, 0.8305, 0.0000],\n",
            "         [0.0000, 0.0000, 1.2631, 1.4730, 1.3427],\n",
            "         [0.1019, 1.4015, 0.0195, 0.8142, 1.1482],\n",
            "         [1.4084, 0.0388, 1.6130, 1.1045, 0.0000],\n",
            "         [1.3509, 0.1658, 1.9859, 0.5128, 0.0000],\n",
            "         [1.2055, 1.1560, 1.6171, 0.0000, 0.0000],\n",
            "         [1.1667, 1.1066, 0.9188, 0.4232, 0.5191],\n",
            "         [0.5244, 1.4908, 0.0000, 1.6331, 0.0000],\n",
            "         [0.6446, 0.0000, 0.6507, 1.3200, 0.6161],\n",
            "         [0.4181, 0.9692, 0.4921, 1.0578, 0.6339],\n",
            "         [1.3450, 0.9578, 0.3645, 0.0000, 0.5271],\n",
            "         [0.0000, 1.9176, 0.5265, 0.0000, 0.9992],\n",
            "         [0.0000, 0.0000, 1.7253, 0.8007, 0.0000],\n",
            "         [0.8866, 0.4426, 1.7441, 0.0099, 0.0000],\n",
            "         [0.4742, 0.7193, 1.4433, 0.4663, 0.7796],\n",
            "         [0.0000, 1.9928, 1.0831, 0.2281, 0.0000],\n",
            "         [1.4425, 1.0854, 1.4258, 0.0000, 0.4691],\n",
            "         [0.0000, 0.4668, 0.9909, 2.3311, 0.0000],\n",
            "         [1.3583, 0.2245, 0.9122, 0.2438, 1.1089],\n",
            "         [0.0000, 0.1906, 0.5699, 1.9227, 0.8371],\n",
            "         [0.0000, 1.4438, 0.1360, 1.6134, 0.1493],\n",
            "         [0.2900, 0.0612, 1.0952, 1.2702, 1.2401]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            " - Output shape after Max Pooling (Conv2): torch.Size([1, 32, 5]) (batch_size, out_channels=32, length=5)\n",
            "\n",
            "Flattening the tensor for Fully Connected layers\n",
            "Values after Flattening:\n",
            "tensor([[0.2387, 0.0000, 2.2187, 1.3392, 0.0000, 0.0000, 1.2818, 0.4946, 1.1408,\n",
            "         0.2448, 0.0000, 2.1992, 0.0000, 0.2353, 1.0345, 1.3787, 0.5954, 0.5591,\n",
            "         1.1541, 0.0000, 0.0000, 1.6494, 1.6380, 0.4294, 0.0000, 0.2467, 0.3409,\n",
            "         1.9738, 0.0000, 0.5908, 0.0000, 1.5700, 0.8499, 0.5320, 0.1738, 0.0000,\n",
            "         0.6731, 1.5438, 1.9206, 0.0251, 0.0000, 1.3912, 0.0000, 2.2284, 0.3036,\n",
            "         0.2709, 0.0000, 2.3096, 0.4382, 0.5282, 0.0000, 1.3634, 0.9895, 0.8305,\n",
            "         0.0000, 0.0000, 0.0000, 1.2631, 1.4730, 1.3427, 0.1019, 1.4015, 0.0195,\n",
            "         0.8142, 1.1482, 1.4084, 0.0388, 1.6130, 1.1045, 0.0000, 1.3509, 0.1658,\n",
            "         1.9859, 0.5128, 0.0000, 1.2055, 1.1560, 1.6171, 0.0000, 0.0000, 1.1667,\n",
            "         1.1066, 0.9188, 0.4232, 0.5191, 0.5244, 1.4908, 0.0000, 1.6331, 0.0000,\n",
            "         0.6446, 0.0000, 0.6507, 1.3200, 0.6161, 0.4181, 0.9692, 0.4921, 1.0578,\n",
            "         0.6339, 1.3450, 0.9578, 0.3645, 0.0000, 0.5271, 0.0000, 1.9176, 0.5265,\n",
            "         0.0000, 0.9992, 0.0000, 0.0000, 1.7253, 0.8007, 0.0000, 0.8866, 0.4426,\n",
            "         1.7441, 0.0099, 0.0000, 0.4742, 0.7193, 1.4433, 0.4663, 0.7796, 0.0000,\n",
            "         1.9928, 1.0831, 0.2281, 0.0000, 1.4425, 1.0854, 1.4258, 0.0000, 0.4691,\n",
            "         0.0000, 0.4668, 0.9909, 2.3311, 0.0000, 1.3583, 0.2245, 0.9122, 0.2438,\n",
            "         1.1089, 0.0000, 0.1906, 0.5699, 1.9227, 0.8371, 0.0000, 1.4438, 0.1360,\n",
            "         1.6134, 0.1493, 0.2900, 0.0612, 1.0952, 1.2702, 1.2401]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            " - Shape after flattening: torch.Size([1, 160]) (batch_size, flattened size)\n",
            "Values after FC1:\n",
            "tensor([[-0.1228, -0.5976, -0.4792,  0.3632,  0.3199, -0.3551,  1.5115, -0.3007,\n",
            "          0.1045, -0.2295,  0.7837, -0.1220, -0.0603, -1.3283, -1.0179,  0.5626,\n",
            "          0.0924,  0.7541,  0.3299,  0.4273, -0.5523,  0.2285,  1.0216,  0.6592,\n",
            "          0.2520, -1.1187, -0.4438, -0.1980,  0.0587,  0.3603, -0.8938,  0.1822,\n",
            "         -0.4598,  0.0596,  0.2794,  0.5080,  0.6606,  0.5053, -0.1209, -0.1705,\n",
            "         -0.8802,  0.5832,  0.4581,  0.1052,  0.3873, -0.0818, -0.1214,  0.2186,\n",
            "          0.6542, -0.1471,  0.3569,  0.0636, -0.0175,  0.0712, -0.5434,  0.4016,\n",
            "         -0.2042, -0.1385, -0.8051,  0.5850,  1.0833,  0.0111, -0.6531,  0.2424,\n",
            "         -1.0783, -0.8283, -0.7114,  0.7223, -0.7103,  0.3928, -0.0644,  1.7387,\n",
            "         -0.8347, -0.2682,  0.5136,  0.6401, -0.6527,  0.8781, -1.4194,  0.5545,\n",
            "          0.1213, -0.0109,  0.2359, -0.1063,  0.2924,  0.0073, -0.2389,  0.9176,\n",
            "          0.7796, -0.2594, -0.8979,  0.9731, -0.9376, -0.3316, -0.0789,  1.1763,\n",
            "          0.5411, -0.1209,  0.5461, -0.0801]], grad_fn=<AddmmBackward0>)\n",
            "Values after Dropout:\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.7263, 0.0000, 0.0000, 0.0000, 0.0000, 0.2090,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1848, 1.5083,\n",
            "         0.6598, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5040, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.3645, 0.0000, 0.1193, 0.5588, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1665, 0.0000, 0.2104, 0.7746,\n",
            "         0.0000, 0.0000, 0.0000, 1.3084, 0.0000, 0.0000, 0.1273, 0.0000, 0.1423,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1701, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 1.2802, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.5849, 0.0146, 0.0000, 0.0000, 1.5593, 0.0000,\n",
            "         0.0000, 1.9462, 0.0000, 0.0000, 0.0000, 0.0000, 1.0821, 0.0000, 0.0000,\n",
            "         0.0000]], grad_fn=<MulBackward0>) (note: some neurons will have values set to zero)\n",
            "Values after FC2 (Output):\n",
            "tensor([[-0.1372, -0.2046,  0.4987,  0.1784, -0.4317, -0.2090,  0.4788, -0.4048,\n",
            "          0.1171, -0.2425]], grad_fn=<AddmmBackward0>)\n",
            " - Output shape after FC2: torch.Size([1, 10]) (batch_size, neurons=10)\n",
            "\n",
            "Final Output Shape: torch.Size([1, 10])\n",
            "Final Output Values:\n",
            "tensor([[-0.1372, -0.2046,  0.4987,  0.1784, -0.4317, -0.2090,  0.4788, -0.4048,\n",
            "          0.1171, -0.2425]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To extend the current `Complex1DCNN` model with **batch normalization**, we need to add batch normalization layers after the convolutional layers. Batch normalization normalizes the output of the previous layers by adjusting and scaling the activations, which helps improve the stability and convergence of the network, especially for deeper networks.\n",
        "\n",
        "\n",
        "##### Key Modifications:\n",
        "\n",
        "1. **Batch Normalization Layers**:\n",
        "   - **`self.bn1 = nn.BatchNorm1d(num_features=16)`**: This layer normalizes the output of `conv1` across the batch. It helps the network stabilize learning by ensuring that the activations have zero mean and unit variance.\n",
        "   - **`self.bn2 = nn.BatchNorm1d(num_features=32)`**: Similarly, this normalizes the output of `conv2` before the ReLU activation.\n",
        "   \n",
        "2. **Where Batch Normalization is Applied**:\n",
        "   - Batch normalization is applied **after the convolutional layers** but **before the ReLU activation**. This allows the activations to be scaled and shifted appropriately.\n",
        "   - For instance, after the first convolution (`conv1`), batch normalization is applied to normalize the feature maps before passing them through ReLU:\n",
        "     ```python\n",
        "     x = self.conv1(x)\n",
        "     x = self.bn1(x)\n",
        "     x = F.relu(x)\n",
        "     ```\n",
        "\n",
        "3. **Impact of Batch Normalization**:\n",
        "   - **Faster convergence**: Batch normalization helps the network converge faster by preventing the internal covariate shift (where layer outputs change distribution during training).\n",
        "   - **Reduced overfitting**: By stabilizing the learning process, batch normalization can also act as a regularizer, sometimes even reducing the need for dropout (though we keep both in this model).\n",
        "\n",
        "4. **Forward Pass**:\n",
        "   - The model performs a forward pass with batch normalization added after each convolutional layer.\n",
        "   - The values after each step, including convolution, batch normalization, ReLU activation, max pooling, and dropout, are printed for detailed inspection.\n",
        "\n",
        "##### Example Output (Simplified):\n",
        "```plaintext\n",
        "Input Data:\n",
        "tensor([[ ... ]])\n",
        " - Shape: torch.Size([1, 1, 20]) (batch_size, channels, length)\n",
        "\n",
        "Values after Conv1:\n",
        "tensor([[ ... ]])\n",
        "Values after BatchNorm1 (Conv1):\n",
        "tensor([[ ... ]])\n",
        "Values after Max Pooling (Conv1):\n",
        "tensor([[ ... ]])\n",
        " - Output shape after Max Pooling (Conv1): torch.Size([1, 16, 10])\n",
        "\n",
        "Values after Conv2:\n",
        "tensor([[ ... ]])\n",
        "Values after BatchNorm2 (Conv2):\n",
        "tensor([[ ... ]])\n",
        "Values after Max Pooling (Conv2):\n",
        "tensor([[ ... ]])\n",
        " - Output shape after Max Pooling (Conv2): torch.Size([1, 32, 5])\n",
        "\n",
        "Flattening the tensor for Fully Connected layers\n",
        "Values after Flattening:\n",
        "tensor([[ ... ]])\n",
        " - Shape after flattening: torch.Size([1, 160])\n",
        "\n",
        "Values after FC1:\n",
        "tensor([[ ... ]])\n",
        "Values after Dropout:\n",
        "tensor([[ ... ]]) (note: some neurons will have values set to zero)\n",
        "\n",
        "Values after FC2 (Output):\n",
        "tensor([[ ... ]])\n",
        " - Output shape after FC2: torch.Size([1, 10])\n",
        "\n",
        "Final Output Shape: torch.Size([1, 10])\n",
        "Final Output Values:\n",
        "tensor([[ ... ]])\n",
        "```\n"
      ],
      "metadata": {
        "id": "GaGaHUFB-rA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6. **Conclusion**\n",
        "\n",
        "- **Recap**:\n",
        "  - **1D Convolutions** are essential for sequential data, allowing the network to capture relationships between neighboring time steps or tokens.\n",
        "  - **Batch Normalization** improves the training process by normalizing activations, allowing higher learning rates, and stabilizing gradients.\n",
        "\n",
        "- **Importance of Batch Normalization**:\n",
        "  - Batch normalization helps prevent overfitting, speeds up convergence, and allows deeper networks to be trained more effectively.\n",
        "\n",
        "**Quiz**:\n",
        "  - Why is batch normalization typically applied before the activation function in many architectures?\n",
        "  - What is the impact of changing the kernel size in a 1D convolution layer?\n",
        "  \n",
        "  **Observation**:\n",
        "  - Batch normalization regularizes the activations, enabling the model to converge faster and generalize better on new data.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "NTkVOkiw-fg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LdTxj73K00Lv"
      }
    }
  ]
}