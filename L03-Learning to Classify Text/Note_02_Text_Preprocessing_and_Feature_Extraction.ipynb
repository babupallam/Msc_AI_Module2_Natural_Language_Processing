{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjQst7dFCWdag2X9JgkM3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d33d63613fc84d8ebbe43471d25db589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69554570a4794d3cb611fcc2deb7085c",
              "IPY_MODEL_2546222166fb40cc942b020c3bc69192",
              "IPY_MODEL_113d21aeaedd4ef9a94cdabaa555cc73"
            ],
            "layout": "IPY_MODEL_8327844223cf47dc944a95708ee29ddc"
          }
        },
        "69554570a4794d3cb611fcc2deb7085c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf3f2f01e8f4cfc91ba4a18ff2f06db",
            "placeholder": "​",
            "style": "IPY_MODEL_6747da07850e4cf8a8295f9cff908c78",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2546222166fb40cc942b020c3bc69192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca03917edb0440a591936f22eea4daca",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_671a71b6b552435c8dfc2ee669f957c6",
            "value": 48
          }
        },
        "113d21aeaedd4ef9a94cdabaa555cc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_000a611ea8f249bc9189e4e756b0dd22",
            "placeholder": "​",
            "style": "IPY_MODEL_aa6543f377ab4652ae8803afbb867067",
            "value": " 48.0/48.0 [00:00&lt;00:00, 813B/s]"
          }
        },
        "8327844223cf47dc944a95708ee29ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf3f2f01e8f4cfc91ba4a18ff2f06db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6747da07850e4cf8a8295f9cff908c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca03917edb0440a591936f22eea4daca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "671a71b6b552435c8dfc2ee669f957c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "000a611ea8f249bc9189e4e756b0dd22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6543f377ab4652ae8803afbb867067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab43fcc0d194c88ba70342a20815d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d5d3fdfa7134737a9e42d29a17d9517",
              "IPY_MODEL_983056ad6f3b46cbb6f119a91ffb4145",
              "IPY_MODEL_54137b7ef1c540c1955cd0e3c4a33780"
            ],
            "layout": "IPY_MODEL_f52cbb6f56ee4a3793e5ca740c0ecb65"
          }
        },
        "6d5d3fdfa7134737a9e42d29a17d9517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_451b3bd957154e51aa79933967d692be",
            "placeholder": "​",
            "style": "IPY_MODEL_808c552eee32452184afa2735749354c",
            "value": "vocab.txt: 100%"
          }
        },
        "983056ad6f3b46cbb6f119a91ffb4145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c36e1f430044ba981928a894b44c58",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e615505a0cdf4a69a637050699d035aa",
            "value": 231508
          }
        },
        "54137b7ef1c540c1955cd0e3c4a33780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf0e3c1f725477eab55450e7fb43296",
            "placeholder": "​",
            "style": "IPY_MODEL_20489da5cdff4875ace2cc89c65c7781",
            "value": " 232k/232k [00:00&lt;00:00, 1.94MB/s]"
          }
        },
        "f52cbb6f56ee4a3793e5ca740c0ecb65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "451b3bd957154e51aa79933967d692be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808c552eee32452184afa2735749354c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c36e1f430044ba981928a894b44c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e615505a0cdf4a69a637050699d035aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebf0e3c1f725477eab55450e7fb43296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20489da5cdff4875ace2cc89c65c7781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "771f0c16754747f08b5533b23fd08f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb1cadb175ec40a5a69ff675d1daa454",
              "IPY_MODEL_57755fb143c44e299d37468f9ad56c6b",
              "IPY_MODEL_99f2db6a48a44b78a55b426179be2534"
            ],
            "layout": "IPY_MODEL_4b11c5b69088457eac9c4eec36447444"
          }
        },
        "fb1cadb175ec40a5a69ff675d1daa454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58cb681cd7c646ad9d640eea4604bd5b",
            "placeholder": "​",
            "style": "IPY_MODEL_d2c3631cbdbd4cbc86b8d6fecc57e443",
            "value": "tokenizer.json: 100%"
          }
        },
        "57755fb143c44e299d37468f9ad56c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37407fe4cb534b56b120618148a56198",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0c8d69409b048bca0dc12fdfb5a76ae",
            "value": 466062
          }
        },
        "99f2db6a48a44b78a55b426179be2534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ca8439badb4e7988be7fdaaad32ec5",
            "placeholder": "​",
            "style": "IPY_MODEL_7ad3e783f7ab4e0082c56728ac471a7f",
            "value": " 466k/466k [00:00&lt;00:00, 2.87MB/s]"
          }
        },
        "4b11c5b69088457eac9c4eec36447444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58cb681cd7c646ad9d640eea4604bd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c3631cbdbd4cbc86b8d6fecc57e443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37407fe4cb534b56b120618148a56198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c8d69409b048bca0dc12fdfb5a76ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5ca8439badb4e7988be7fdaaad32ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad3e783f7ab4e0082c56728ac471a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e492e60ccf804e0588727edd21ad1ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9907001a3d4b4f14ae321103c0fb9f38",
              "IPY_MODEL_3428c247828741e38e399ba40e5043ac",
              "IPY_MODEL_088dbfdb0fdd471c9b43a8e16bba1e12"
            ],
            "layout": "IPY_MODEL_4e39dcd6b1624a0e89e039b3a7158008"
          }
        },
        "9907001a3d4b4f14ae321103c0fb9f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e4287d9db64c57aad79f7ee36d241a",
            "placeholder": "​",
            "style": "IPY_MODEL_832f96463579449995320dd2a52566a2",
            "value": "config.json: 100%"
          }
        },
        "3428c247828741e38e399ba40e5043ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd9199dc88ba4e78a9d19edd57444561",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_842fd48fd6404a5797934752451daf56",
            "value": 570
          }
        },
        "088dbfdb0fdd471c9b43a8e16bba1e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5640df0d539048ef974a28aa2d13a08f",
            "placeholder": "​",
            "style": "IPY_MODEL_c1f6cf03382a4feeb6bf8c78bb90b764",
            "value": " 570/570 [00:00&lt;00:00, 7.94kB/s]"
          }
        },
        "4e39dcd6b1624a0e89e039b3a7158008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e4287d9db64c57aad79f7ee36d241a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832f96463579449995320dd2a52566a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd9199dc88ba4e78a9d19edd57444561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "842fd48fd6404a5797934752451daf56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5640df0d539048ef974a28aa2d13a08f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f6cf03382a4feeb6bf8c78bb90b764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57f44fc4118d4b7f8e767a3a1e25550c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56aba3f8b94247939915053e810d156b",
              "IPY_MODEL_b1ca345ab8fa4385b38e27bfb53d6492",
              "IPY_MODEL_73dcc320f17c4f8b88f86f70a5ba097c"
            ],
            "layout": "IPY_MODEL_9d36c49ac159474ea6fb6fe219511943"
          }
        },
        "56aba3f8b94247939915053e810d156b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c26f2db8fa846fba433a37d9a8e1362",
            "placeholder": "​",
            "style": "IPY_MODEL_b614c8e99f524550ab33eea1c41d4a29",
            "value": "model.safetensors: 100%"
          }
        },
        "b1ca345ab8fa4385b38e27bfb53d6492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eee561816eca4440adc7e2ed1ab8d602",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b11ac3dbe8a4b5b83a6e54dcfae8555",
            "value": 440449768
          }
        },
        "73dcc320f17c4f8b88f86f70a5ba097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887ebb73afc34d638025b97b13beab22",
            "placeholder": "​",
            "style": "IPY_MODEL_953f4781e16d43d68e112130f38aafaf",
            "value": " 440M/440M [00:04&lt;00:00, 157MB/s]"
          }
        },
        "9d36c49ac159474ea6fb6fe219511943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c26f2db8fa846fba433a37d9a8e1362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b614c8e99f524550ab33eea1c41d4a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eee561816eca4440adc7e2ed1ab8d602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b11ac3dbe8a4b5b83a6e54dcfae8555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "887ebb73afc34d638025b97b13beab22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953f4781e16d43d68e112130f38aafaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babupallam/Msc_AI_Module2_Natural_Language_Processing/blob/main/L03-Learning%20to%20Classify%20Text/Note_02_Text_Preprocessing_and_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This section focuses on preparing raw text data for text classification tasks by cleaning, normalizing, and extracting features that can be used as input for machine learning and deep learning models.\n",
        "- Text preprocessing is a crucial step that ensures the quality and relevance of the data fed into classification algorithms, directly impacting model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZutFAY_El50s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 **Text Cleaning and Normalization**\n"
      ],
      "metadata": {
        "id": "JbSxkww4l5xQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Tokenization**:\n",
        "  - Split the text into individual units, such as words (word tokenization) or sentences (sentence tokenization).\n",
        "  - Use NLTK's `word_tokenize` or `sent_tokenize` methods for tokenization.\n"
      ],
      "metadata": {
        "id": "Pnsgzq2u0Bii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
        "\n",
        "# Example text\n",
        "text = \"Hello there! How are you doing today? Let's learn some NLP.\"\n",
        "\n",
        "# Word tokenization\n",
        "word_tokens = nltk.word_tokenize(text)\n",
        "print(\"Word Tokenization:\", word_tokens)\n",
        "\n",
        "# Sentence tokenization\n",
        "sentence_tokens = nltk.sent_tokenize(text)\n",
        "print(\"Sentence Tokenization:\", sentence_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU3IIC_r0Knj",
        "outputId": "cf2f6853-af3e-494b-c421-856f98bab6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokenization: ['Hello', 'there', '!', 'How', 'are', 'you', 'doing', 'today', '?', 'Let', \"'s\", 'learn', 'some', 'NLP', '.']\n",
            "Sentence Tokenization: ['Hello there!', 'How are you doing today?', \"Let's learn some NLP.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Lowercasing**:\n",
        "  - Convert all text to lowercase to ensure consistency, as most models treat \"Word\" and \"word\" differently.\n"
      ],
      "metadata": {
        "id": "jLXJ3zkW0Be4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercasing\n",
        "lowercase_text = text.lower()\n",
        "print(\"Lowercased Text:\", lowercase_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19NT2IDF0LDd",
        "outputId": "2372516f-701b-457e-fd7f-6dbd7e1cf748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased Text: hello there! how are you doing today? let's learn some nlp.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Removing Special Characters and Punctuation**:\n",
        "  - Eliminate non-alphanumeric characters to reduce noise (e.g., special symbols, hashtags, or emojis, if not relevant to the task).\n",
        "  - Keep punctuation if it carries meaning for the task (e.g., sentence segmentation).\n"
      ],
      "metadata": {
        "id": "FZsDIeSK0BcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Removing special characters and punctuation\n",
        "cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "print(\"Text without Special Characters:\", cleaned_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEfxTWvS0Lq7",
        "outputId": "75d639b8-5500-47ba-c599-cd309dacfcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text without Special Characters: Hello there How are you doing today Lets learn some NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Stop Word Removal**:\n",
        "  - Remove common words like \"the,\" \"is,\" \"and,\" which may not add meaningful information.\n",
        "  - Use NLTK's built-in list of stop words or customize your own list based on the task.\n"
      ],
      "metadata": {
        "id": "d5TGg7dc0BZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# List of English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(\"Stop Words:\", stop_words)\n",
        "\n",
        "# Removing stop words from word tokens\n",
        "filtered_tokens = [word for word in word_tokens if word.lower() not in stop_words]\n",
        "print(\"Tokens after Stop Word Removal:\", filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45G4RxB60MHi",
        "outputId": "4c82e8e2-a681-48ee-9ae1-032d493c2497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop Words: {'as', 'there', 'most', 'those', 'she', 'some', \"you'll\", 'them', 'by', \"doesn't\", 'didn', 'yourselves', 'while', \"you're\", \"isn't\", 'do', 'their', 'wouldn', 'does', 'yours', 'being', 'of', 'own', 'into', 'until', 'other', 'or', 'ours', \"weren't\", 'any', 'm', 'needn', 'hasn', 'just', 'been', 'll', 'which', 'over', 'have', 'isn', 'you', 'below', \"you've\", 'on', 'haven', 'the', 'down', 'doesn', \"you'd\", 'above', 'having', 'where', 'should', 'he', 'now', 'same', 'was', 'has', \"shouldn't\", 's', 'these', 'out', 'so', 'ourselves', 'hadn', 'myself', 'y', 'each', 'but', 'am', 'were', 'after', 'at', 'nor', 'aren', 'if', 'an', 'can', 'yourself', 'such', \"shan't\", 'only', 'o', \"aren't\", \"needn't\", \"mustn't\", 'here', 'him', 'itself', 'we', 'not', 'under', 'then', 'with', 'both', 'herself', 'mightn', \"wasn't\", 'for', 'its', 'again', \"it's\", 'your', 'few', \"wouldn't\", 'against', 'between', 'will', \"that'll\", 'theirs', 'before', 't', 'hers', 'to', 'during', 'a', 'that', 'than', 'in', \"she's\", 'and', 'off', 'mustn', 'couldn', \"haven't\", 'all', 'won', 'be', 'himself', \"hadn't\", \"should've\", 'ain', 'no', 'i', \"don't\", 'who', 'too', 'this', 'me', 've', 'how', 'when', 'shan', \"couldn't\", 'up', \"hasn't\", 'because', 'about', 'had', 'his', 'weren', 'once', 'is', 'it', 'why', \"won't\", 'what', 'whom', 're', 'are', \"didn't\", 'through', 'very', 'my', 'ma', 'our', 'her', 'shouldn', 'wasn', 'doing', 'more', \"mightn't\", 'from', 'they', 'further', 'themselves', 'd', 'did', 'don'}\n",
            "Tokens after Stop Word Removal: ['Hello', '!', 'today', '?', 'Let', \"'s\", 'learn', 'NLP', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Spelling Correction**:\n",
        "  - Correct misspelled words to improve text quality.\n",
        "  - Tools like `autocorrect` or `pyspellchecker` can help with spelling correction.\n"
      ],
      "metadata": {
        "id": "ZJGkINDZ0BWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GncOf4NF1AEU",
        "outputId": "017ee8e6-993d-4c44-b1b7-bb48d0d8eb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/622.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/622.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m583.7/622.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622364 sha256=d04ccbd5bb63c5f9f52d104fc885c60bf8c789c1ddff1294b2bcae4c8e0da037\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autocorrect import Speller\n",
        "\n",
        "# Initialize spell checker\n",
        "spell = Speller()\n",
        "\n",
        "# Correct spelling in each word\n",
        "corrected_text = \" \".join([spell(word) for word in word_tokens])\n",
        "print(\"Corrected Text:\", corrected_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrkjqQe20MjK",
        "outputId": "8930d0c0-067c-40c7-b332-e6bdfbea3133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Text: Hello there ! How are you doing today ? Let 's learn some LP .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Handling Abbreviations and Contractions**:\n",
        "  - Expand abbreviations (e.g., \"etc.\" → \"etcetera\") and contractions (e.g., \"don't\" → \"do not\") for consistency.\n",
        "\n"
      ],
      "metadata": {
        "id": "GFzx9P900BTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShckT3P21OE5",
        "outputId": "38e05a87-f6ed-4e04-d2c8-e975425a1e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from contractions import contractions_dict  # A dictionary of contractions and their expansions\n",
        "\n",
        "# Example function to expand contractions\n",
        "def expand_contractions(text, contractions_dict):\n",
        "    pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b')\n",
        "    expanded_text = pattern.sub(lambda x: contractions_dict[x.group()], text)\n",
        "    return expanded_text\n",
        "\n",
        "# Expanding contractions\n",
        "expanded_text = expand_contractions(text, contractions_dict)\n",
        "print(\"Expanded Text:\", expanded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3RsGMoQ0M78",
        "outputId": "69965f30-e83f-4478-9392-db42c130a85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanded Text: Hello there! How are you doing today? Let's learn some NLP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 **Text Normalization**\n"
      ],
      "metadata": {
        "id": "EoMByjKMl5uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Stemming**:\n",
        "  - Reduce words to their root form by removing suffixes (e.g., \"running\" → \"run\").\n",
        "  - Use algorithms like Porter Stemmer or Snowball Stemmer in NLTK.\n"
      ],
      "metadata": {
        "id": "-BZW3hZ30Pko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Initialize the Porter Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Stemming each word\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"Stemmed Words:\", stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fICeU2A0Sym",
        "outputId": "0a0912e1-b61f-4cce-c521-8efa7e22cab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['hello', '!', 'today', '?', 'let', \"'s\", 'learn', 'nlp', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Lemmatization**:\n",
        "  - More sophisticated than stemming, it converts words to their base or dictionary form (e.g., \"better\" → \"good\").\n",
        "  - Use NLTK's `WordNetLemmatizer` for lemmatization.\n"
      ],
      "metadata": {
        "id": "l09Lmahb0PhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # For WordNet lemmatizer dependencies\n",
        "\n",
        "# Initialize the WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatizing each word\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DffuuyL0TLG",
        "outputId": "d44521f7-fd30-4d94-9e19-b654ef93b409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words: ['Hello', '!', 'today', '?', 'Let', \"'s\", 'learn', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Handling Accents and Diacritics**:\n",
        "  - Normalize text by removing accents (e.g., \"café\" → \"cafe\").\n",
        "  - Use libraries like `unidecode` for accent removal.\n"
      ],
      "metadata": {
        "id": "VT6Da5_T0PeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode # Install the unidecode module\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr58xXXD1doB",
        "outputId": "09509992-b52e-41ad-f2e3-e365d18cf5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unidecode\n",
        "\n",
        "# Example text with accented characters\n",
        "accented_text = \"Café and résumé are common words with accents.\"\n",
        "\n",
        "# Removing accents\n",
        "normalized_text = unidecode.unidecode(accented_text)\n",
        "print(\"Normalized Text:\", normalized_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32YpIN3Z0TkK",
        "outputId": "51f619bd-ec14-4ccc-c43a-6b1ff5596888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Text: Cafe and resume are common words with accents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 **Feature Extraction Techniques**\n"
      ],
      "metadata": {
        "id": "dNlCBZkql5rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Bag-of-Words (BoW)**:\n",
        "  - Represent the text as a set of words, disregarding grammar and word order.\n",
        "  - Create a matrix where each row represents a document and each column represents a word, with cell values indicating word frequency.\n"
      ],
      "metadata": {
        "id": "3pMZHVxz1oOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example corpus (a list of documents)\n",
        "corpus = [\n",
        "    \"This is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Is this the first document?\"\n",
        "]\n",
        "\n",
        "# Create a CountVectorizer instance\n",
        "# This will convert the text data into a matrix of token counts\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the corpus and transform the corpus to a BoW representation\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Get the feature names (i.e., the vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the BoW matrix to an array for better readability\n",
        "bow_array = bow_matrix.toarray()\n",
        "\n",
        "print(\"Feature Names (Vocabulary):\", feature_names)  # Displays the vocabulary\n",
        "print(\"Bag-of-Words Matrix:\\n\", bow_array)  # Displays the BoW matrix where rows represent documents and columns represent word counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hd5nPic1tWQ",
        "outputId": "2da796d0-20ab-4340-d54b-6d750010c6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names (Vocabulary): ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "Bag-of-Words Matrix:\n",
            " [[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Term Frequency-Inverse Document Frequency (TF-IDF)**:\n",
        "  - Weigh word occurrences by their importance, giving higher weights to words that appear frequently in a document but not across all documents.\n",
        "  - Use `TfidfVectorizer` from `scikit-learn` to implement TF-IDF.\n"
      ],
      "metadata": {
        "id": "kRGMNISw1oLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create a TfidfVectorizer instance\n",
        "# This will convert the text data into a matrix of TF-IDF features\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the corpus and transform the corpus to a TF-IDF representation\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Get the feature names (i.e., the vocabulary)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the TF-IDF matrix to an array for better readability\n",
        "tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "print(\"TF-IDF Feature Names (Vocabulary):\", tfidf_feature_names)  # Displays the vocabulary\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf_array)  # Displays the TF-IDF matrix where rows represent documents and columns represent TF-IDF scores\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHPN8Qea1tzi",
        "outputId": "9c8035b2-becc-4b9f-ecba-65439fc73045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Feature Names (Vocabulary): ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]\n",
            " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
            "  0.28108867 0.         0.28108867]\n",
            " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
            "  0.26710379 0.51184851 0.26710379]\n",
            " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Word Embeddings**:\n",
        "  - Represent words in a continuous vector space, capturing semantic relationships.\n",
        "  - Use pre-trained embeddings like **Word2Vec**, **GloVe**, or **FastText** for capturing word similarities.\n",
        "  - Fine-tune embeddings on your dataset using deep learning frameworks like PyTorch.\n"
      ],
      "metadata": {
        "id": "4FEoppgV1oIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Example sentences to train Word2Vec\n",
        "sentences = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"Here we have another sentence.\",\n",
        "    \"Word embeddings capture word meanings.\",\n",
        "    \"This is a different sentence.\"\n",
        "]\n",
        "\n",
        "# Tokenize each sentence into words\n",
        "# Convert all text to lowercase to avoid case sensitivity issues\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Train a Word2Vec model on the tokenized sentences\n",
        "# vector_size: size of the embedding vectors, window: max distance between current and predicted word, min_count: ignore words with total frequency below this, workers: number of threads for training\n",
        "word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get the vector representation for the word 'sentence'\n",
        "# This vector represents the word's meaning in a numerical form\n",
        "word_vector = word2vec_model.wv['sentence']\n",
        "\n",
        "print(\"Vector for the word 'sentence':\\n\", word_vector)  # Displays the embedding vector for the word 'sentence'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7q2l5EH1uMz",
        "outputId": "00251e50-c7f6-4a17-86d5-2a379c6ec39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for the word 'sentence':\n",
            " [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Sentence Embeddings**:\n",
        "  - Encode entire sentences into vectors, preserving context.\n",
        "  - Use models like **BERT**, **RoBERTa**, or **Sentence-BERT** for better contextual representations.\n"
      ],
      "metadata": {
        "id": "-_HjbD9o1oFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Load a pre-trained BERT model and its corresponding tokenizer\n",
        "# 'bert-base-uncased' is a commonly used variant of BERT where all text is lowercased\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example sentence to encode\n",
        "sentence = \"Text classification with BERT embeddings.\"\n",
        "\n",
        "# Tokenize the input sentence and convert it into token IDs\n",
        "# return_tensors='pt' returns PyTorch tensors\n",
        "inputs = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "# Pass the tokenized inputs to the BERT model to obtain outputs\n",
        "# with torch.no_grad() ensures no gradients are computed, saving memory\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Get the sentence embedding by averaging the last hidden states of all tokens\n",
        "# outputs.last_hidden_state contains the hidden states of each token in the input sentence\n",
        "sentence_embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "\n",
        "print(\"Sentence Embedding for the example sentence:\\n\", sentence_embedding)  # Displays the vector representation for the entire sentence\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d33d63613fc84d8ebbe43471d25db589",
            "69554570a4794d3cb611fcc2deb7085c",
            "2546222166fb40cc942b020c3bc69192",
            "113d21aeaedd4ef9a94cdabaa555cc73",
            "8327844223cf47dc944a95708ee29ddc",
            "fbf3f2f01e8f4cfc91ba4a18ff2f06db",
            "6747da07850e4cf8a8295f9cff908c78",
            "ca03917edb0440a591936f22eea4daca",
            "671a71b6b552435c8dfc2ee669f957c6",
            "000a611ea8f249bc9189e4e756b0dd22",
            "aa6543f377ab4652ae8803afbb867067",
            "bab43fcc0d194c88ba70342a20815d6b",
            "6d5d3fdfa7134737a9e42d29a17d9517",
            "983056ad6f3b46cbb6f119a91ffb4145",
            "54137b7ef1c540c1955cd0e3c4a33780",
            "f52cbb6f56ee4a3793e5ca740c0ecb65",
            "451b3bd957154e51aa79933967d692be",
            "808c552eee32452184afa2735749354c",
            "f2c36e1f430044ba981928a894b44c58",
            "e615505a0cdf4a69a637050699d035aa",
            "ebf0e3c1f725477eab55450e7fb43296",
            "20489da5cdff4875ace2cc89c65c7781",
            "771f0c16754747f08b5533b23fd08f95",
            "fb1cadb175ec40a5a69ff675d1daa454",
            "57755fb143c44e299d37468f9ad56c6b",
            "99f2db6a48a44b78a55b426179be2534",
            "4b11c5b69088457eac9c4eec36447444",
            "58cb681cd7c646ad9d640eea4604bd5b",
            "d2c3631cbdbd4cbc86b8d6fecc57e443",
            "37407fe4cb534b56b120618148a56198",
            "b0c8d69409b048bca0dc12fdfb5a76ae",
            "b5ca8439badb4e7988be7fdaaad32ec5",
            "7ad3e783f7ab4e0082c56728ac471a7f",
            "e492e60ccf804e0588727edd21ad1ba4",
            "9907001a3d4b4f14ae321103c0fb9f38",
            "3428c247828741e38e399ba40e5043ac",
            "088dbfdb0fdd471c9b43a8e16bba1e12",
            "4e39dcd6b1624a0e89e039b3a7158008",
            "92e4287d9db64c57aad79f7ee36d241a",
            "832f96463579449995320dd2a52566a2",
            "cd9199dc88ba4e78a9d19edd57444561",
            "842fd48fd6404a5797934752451daf56",
            "5640df0d539048ef974a28aa2d13a08f",
            "c1f6cf03382a4feeb6bf8c78bb90b764",
            "57f44fc4118d4b7f8e767a3a1e25550c",
            "56aba3f8b94247939915053e810d156b",
            "b1ca345ab8fa4385b38e27bfb53d6492",
            "73dcc320f17c4f8b88f86f70a5ba097c",
            "9d36c49ac159474ea6fb6fe219511943",
            "4c26f2db8fa846fba433a37d9a8e1362",
            "b614c8e99f524550ab33eea1c41d4a29",
            "eee561816eca4440adc7e2ed1ab8d602",
            "0b11ac3dbe8a4b5b83a6e54dcfae8555",
            "887ebb73afc34d638025b97b13beab22",
            "953f4781e16d43d68e112130f38aafaf"
          ]
        },
        "id": "LU3FDB0z1uq1",
        "outputId": "45f36bcc-7d85-48cc-f9e4-66bd227f0dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d33d63613fc84d8ebbe43471d25db589"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bab43fcc0d194c88ba70342a20815d6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "771f0c16754747f08b5533b23fd08f95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e492e60ccf804e0588727edd21ad1ba4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57f44fc4118d4b7f8e767a3a1e25550c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Embedding for the example sentence:\n",
            " tensor([-4.9895e-01, -3.5024e-02, -3.5461e-01, -2.8169e-02,  1.0095e-01,\n",
            "         2.0884e-02, -2.5413e-01,  2.7742e-01, -4.6405e-02,  4.4192e-02,\n",
            "        -2.8290e-01,  1.9983e-01, -2.5800e-01, -2.4812e-01,  1.5008e-02,\n",
            "         2.6797e-01, -1.7945e-01,  2.4348e-01, -2.2559e-01,  6.5268e-02,\n",
            "         2.4007e-01, -1.1787e-01, -4.0681e-01,  9.2509e-02,  2.6697e-01,\n",
            "        -1.2055e-01, -2.9749e-02, -1.4366e-01, -4.2196e-01, -2.2909e-01,\n",
            "         1.8353e-01,  4.2590e-01,  2.1517e-01, -3.6770e-01, -4.9305e-01,\n",
            "        -1.7630e-01,  3.1828e-02, -8.9287e-02, -3.1037e-01,  4.3864e-01,\n",
            "        -7.9540e-01, -1.2213e-01,  7.0302e-02, -1.8723e-01,  1.7915e-01,\n",
            "        -2.4740e-01, -4.3649e-01, -7.1884e-02, -3.6788e-01, -3.8521e-01,\n",
            "        -8.9820e-01,  3.1086e-01,  5.0078e-02, -3.1777e-02,  3.0968e-01,\n",
            "         5.5267e-01,  3.5910e-02, -7.9101e-01,  6.3835e-01,  2.8195e-01,\n",
            "        -2.6005e-02, -2.4286e-01, -3.6507e-01, -5.7928e-01,  3.6649e-01,\n",
            "         1.2046e-01, -2.8694e-01,  4.4687e-01, -1.0222e+00,  9.4876e-02,\n",
            "        -4.6404e-01, -1.2905e-01, -7.7264e-02, -1.0479e-01, -9.6815e-02,\n",
            "         9.1759e-02, -4.4732e-01,  9.0219e-02, -6.5074e-02, -4.2484e-01,\n",
            "        -5.0715e-01,  4.4853e-01,  2.1351e-01,  4.3364e-01,  6.2942e-01,\n",
            "         1.4794e-02, -2.4686e-01,  3.0175e-01, -1.8136e-01,  3.4490e-01,\n",
            "        -1.7055e-01, -4.4650e-01, -1.7992e-01,  2.1165e-01,  6.6288e-01,\n",
            "         2.9675e-01, -1.7574e-01,  1.8674e-01,  8.3240e-02,  5.8376e-01,\n",
            "        -7.6449e-02, -2.4862e-01,  2.4882e-01,  2.6278e-01, -2.9005e-01,\n",
            "         2.5542e-03, -9.7323e-02,  4.2329e-01, -1.7689e-01, -1.3068e-01,\n",
            "        -1.1091e-01, -3.8716e-01,  3.0610e-01, -4.8400e-01, -2.6184e-01,\n",
            "        -9.1029e-02, -1.3920e-01,  4.1028e-01,  2.0390e-01, -6.0002e-01,\n",
            "        -1.2912e-03,  4.5607e-01,  2.9033e-01,  1.1290e+00, -2.8999e-01,\n",
            "         3.9941e-01, -2.3095e-01,  5.2168e-01,  3.8289e-01,  9.4552e-02,\n",
            "         3.0023e-02,  3.3310e-01,  5.0497e-01, -2.3090e-01, -3.1272e-01,\n",
            "         3.8444e-01, -1.2978e-01, -3.8561e-01, -1.8137e-01, -3.8010e-02,\n",
            "        -3.2800e-01,  1.5909e-01,  1.3560e-01, -2.4905e-02,  6.8898e-01,\n",
            "         3.6639e-01, -1.8838e-01, -3.2544e-01,  1.2963e-01,  4.9428e-01,\n",
            "         2.8840e-01, -1.0603e-02, -4.4503e-01, -1.2698e-01, -5.1578e-01,\n",
            "         6.9228e-01,  2.8024e-01,  1.9891e-02, -5.7201e-02,  1.0807e-02,\n",
            "         6.1107e-01,  2.3479e-01, -4.2437e-01, -7.6649e-02,  3.3644e-02,\n",
            "        -2.1849e-01, -3.3295e-01,  5.6296e-01,  1.2479e-01,  2.6981e-01,\n",
            "        -2.3346e-01, -4.8781e-02,  4.3929e-01, -8.3773e-02,  2.6031e-02,\n",
            "        -1.2541e-01,  3.2362e-01,  1.8252e-01,  1.5895e-01,  2.3490e-01,\n",
            "        -1.3002e+00,  1.8825e-01, -1.1748e-01, -1.4973e-01,  2.7753e-02,\n",
            "         9.8738e-02,  9.8346e-02, -6.4900e-01, -1.9685e-01, -1.7385e-01,\n",
            "        -3.7227e-01, -1.0523e-02, -4.9986e-01, -2.4113e-01,  4.8348e-01,\n",
            "        -2.7734e-01,  1.9029e-02, -6.2864e-02, -7.6218e-02,  6.8201e-02,\n",
            "        -8.4771e-02, -1.3015e-01, -4.0092e-02,  2.7623e-01,  1.6708e-01,\n",
            "        -8.3391e-02, -1.8164e-01, -1.9122e-01, -5.6559e-01,  1.2846e-01,\n",
            "        -2.4959e-01,  7.2672e-01,  8.6286e-02, -3.1727e-02,  3.3156e-01,\n",
            "        -3.4658e-01,  5.3211e-02, -1.6484e-01, -2.2112e-01,  2.2358e-02,\n",
            "         2.8883e-01, -1.2364e-01, -5.7335e-01,  2.4580e-01, -6.1641e-01,\n",
            "         8.4867e-01,  1.4197e-01,  7.2835e-02,  6.4509e-01,  1.2238e-01,\n",
            "         1.7214e-01, -2.3286e-01,  3.8122e-01, -2.1020e-01,  5.7202e-02,\n",
            "         1.8858e-01, -7.8535e-02,  2.6148e-01,  1.5050e-01,  9.6226e-02,\n",
            "        -2.6634e-02,  3.2563e-01,  4.8754e-01, -1.6435e-01,  1.9300e-02,\n",
            "        -3.2496e-01, -1.2566e-01,  2.9314e-01,  4.2644e-02, -5.8199e-01,\n",
            "         1.3784e-01, -2.7404e-01, -2.4678e-01, -9.6823e-01, -3.3029e-01,\n",
            "        -5.9110e-02, -4.6350e-01, -1.3648e-01, -7.2109e-02,  5.7734e-01,\n",
            "         2.0827e-01, -1.2738e-02,  1.1109e-01,  8.5646e-02, -2.2398e-01,\n",
            "        -5.7529e-01, -1.2658e-01,  3.0563e-01,  8.0221e-01,  1.2269e-01,\n",
            "        -2.7494e-01, -4.6217e-01, -1.8338e-01, -1.9929e-02, -9.0215e-01,\n",
            "        -1.8345e-01,  1.8218e-01, -1.5034e-01, -1.4840e-01, -1.8050e-01,\n",
            "         2.2593e-01,  2.7080e-01, -1.6482e-01,  2.7322e-01, -6.6858e-01,\n",
            "         6.0296e-02, -1.3948e-01, -3.8401e-02, -5.4413e-02, -4.5279e-01,\n",
            "        -3.9490e-02,  4.9666e-01, -2.8026e-01,  2.5611e-01,  8.6974e-02,\n",
            "         6.2801e-01,  3.1917e-01,  2.2692e-01,  7.8193e-02, -6.4649e-01,\n",
            "        -8.8375e-02, -4.4842e-01, -1.7936e-01,  7.9094e-02, -7.1803e-01,\n",
            "         3.8952e-01, -3.2507e-01, -2.5099e-01, -3.2541e+00,  4.8454e-02,\n",
            "        -1.2577e-02, -1.0382e-01,  7.7909e-02, -3.1999e-01, -3.2696e-01,\n",
            "        -3.5582e-01, -3.2409e-01,  2.7894e-01, -1.6075e-01, -4.1995e-02,\n",
            "        -2.9691e-01,  5.7892e-01,  3.1982e-01,  1.6023e-01, -3.5286e-01,\n",
            "        -1.4544e-01,  7.0374e-02,  9.5524e-02,  1.2182e-01, -6.7443e-01,\n",
            "        -8.5029e-02,  6.6813e-02, -3.3270e-02, -1.0101e-01, -3.5962e-01,\n",
            "         5.7030e-01, -4.8790e-01, -5.7155e-01,  9.4448e-02, -2.4665e-01,\n",
            "         3.8850e-01,  4.0471e-01,  5.1155e-03,  1.1548e-01,  2.8631e-01,\n",
            "         1.4607e-01,  3.9590e-01, -5.5785e-01,  1.7706e-01,  3.8527e-01,\n",
            "        -7.7994e-02, -7.1803e-02,  3.8817e-01, -1.2292e-01,  3.1329e-01,\n",
            "        -3.3908e-01,  2.8043e-01,  2.9885e-01, -4.1730e-01, -3.2132e-01,\n",
            "        -1.7526e-01, -5.9410e-02,  1.4902e-01, -3.5104e-01,  3.6597e-01,\n",
            "         4.0262e-02, -4.3679e-01,  1.8556e-01,  4.4418e-01, -3.5688e-01,\n",
            "        -2.5974e-01, -2.5815e-01, -6.1368e-02, -2.3362e-01, -9.2529e-01,\n",
            "        -2.5337e-01, -1.4164e-01,  9.0907e-02, -5.4284e-01,  2.8800e-02,\n",
            "        -4.1215e-01, -9.7387e-01,  1.9930e-01, -4.7633e-01,  1.2218e-01,\n",
            "        -4.9350e-01,  1.7114e-01, -1.0623e-01, -2.2992e-01, -4.7677e-01,\n",
            "         4.4484e-01, -2.6939e-02,  2.8516e-02,  3.6444e-01,  2.9602e-02,\n",
            "        -4.4153e-01,  2.4953e-02, -4.1025e-01,  6.6611e-02,  1.6117e-01,\n",
            "         2.8548e-02,  4.0633e-01,  2.5154e-01,  1.2859e-01,  7.9783e-01,\n",
            "        -1.9629e-01,  5.1618e-01, -1.5414e-01,  3.1620e-01, -3.5033e-01,\n",
            "         1.3914e-01, -1.0960e-01, -3.5853e-01,  5.8728e-01, -8.5440e-01,\n",
            "        -2.6591e-01,  1.4741e-01, -2.1494e-02,  6.8272e-02,  2.0931e-02,\n",
            "         4.3642e-01, -5.9132e-01, -4.6595e-01,  6.2370e-01,  2.0429e-02,\n",
            "         5.3083e-01,  4.4317e-01,  1.2623e-02,  2.4465e-03,  5.7006e-01,\n",
            "        -1.0668e-01,  1.8523e-02,  2.9715e-02, -3.1208e-01, -6.6544e-02,\n",
            "         1.9659e-01, -1.9922e-01, -2.0558e-01,  1.1119e-01, -3.5458e-01,\n",
            "        -8.6609e-03,  8.5958e-02,  4.8167e-01, -4.2337e-01, -1.3348e-01,\n",
            "         5.3100e-01,  1.3176e-01,  1.7358e-01,  3.4185e-01,  2.4537e-01,\n",
            "         2.1767e-01, -3.0344e-01,  1.1839e-01,  1.5357e-01, -9.2918e-02,\n",
            "         1.2248e-01,  3.4707e-01,  8.7132e-02, -3.9244e-01, -3.2175e-02,\n",
            "        -2.0606e-01, -1.4020e-01,  3.1379e-02, -2.1462e-01,  2.3186e-01,\n",
            "        -2.7943e-01, -8.1559e-02, -5.4998e-01,  3.1207e-01,  5.0255e-01,\n",
            "         7.0052e-01,  2.8659e-03, -4.9776e-02,  3.1753e-01, -2.5879e-01,\n",
            "         1.3226e-01, -3.7360e-01,  1.6328e-01, -5.5102e-01, -5.2317e-01,\n",
            "         5.0030e-01,  1.0150e-01,  2.7388e-01,  3.9954e-01,  1.6331e-01,\n",
            "         3.7255e-02,  3.3607e-01,  8.0799e-01,  3.3217e-01,  9.7780e-03,\n",
            "        -2.2149e-01,  4.2481e-01,  3.6231e-01,  5.0781e-01, -5.0104e-01,\n",
            "        -6.8542e-02, -4.8553e-03,  6.6590e-02, -4.2429e-01,  1.9753e-01,\n",
            "        -2.2302e-03, -4.5086e-01, -6.2383e-01, -1.5757e-01,  2.7607e-01,\n",
            "        -3.3331e-01,  2.6774e-01, -3.6277e-01,  6.4963e-02, -2.3096e-01,\n",
            "        -2.3050e-01, -6.7088e-02, -1.9461e-01, -3.2289e-01,  4.5550e-01,\n",
            "        -7.4047e-02, -2.0036e-01, -5.7677e-03,  1.3390e-01, -4.2200e-01,\n",
            "        -5.6091e-01, -6.2486e-01,  5.0172e-01, -5.6926e-02,  2.5690e-01,\n",
            "         4.8878e-02, -1.7307e-01, -1.6676e-01, -2.5523e-01, -4.1463e-02,\n",
            "         3.9173e-01,  5.0078e-01, -3.3490e-01, -1.9234e-01, -5.6679e-03,\n",
            "        -2.7547e-01, -8.6166e-01,  3.2725e-01,  2.3391e-01, -5.4146e-01,\n",
            "         3.3747e-01,  2.2071e-01,  3.4855e-01, -2.8882e-01, -8.1995e-01,\n",
            "        -2.8591e-01,  1.8723e-01, -4.5677e-01, -1.2101e-02, -1.1470e-01,\n",
            "         6.3633e-02, -2.9917e-01,  6.2271e-02, -1.2862e-01, -9.3552e-02,\n",
            "         2.3579e-01, -1.9673e-01,  4.5051e-01, -4.1659e-01, -2.3627e-01,\n",
            "        -3.4846e-01, -2.1120e-01,  1.9741e-01, -7.5273e-02, -3.6395e-01,\n",
            "        -1.7311e-01, -5.5046e-01,  2.9512e-01,  2.4506e-01, -2.8507e-01,\n",
            "        -3.2027e-01,  4.8395e-01,  4.4176e-01,  4.6035e-01,  1.4748e-01,\n",
            "        -3.0240e-02,  1.1622e-01, -6.4986e-02, -3.0658e-01, -5.9170e-01,\n",
            "         8.5366e-03, -1.5929e-01, -1.7499e-01, -5.1072e-01,  1.1458e-01,\n",
            "        -2.7294e-01,  3.4267e-01, -1.8810e-01,  1.5537e-02,  2.9386e-01,\n",
            "         1.2379e-01,  4.1344e-02,  4.6741e-01, -3.2803e-01, -2.7013e-01,\n",
            "         1.1554e-02,  1.1177e-01, -4.9330e-02,  2.6005e-01,  5.0349e-01,\n",
            "        -2.7984e-01, -2.5391e-02, -2.2400e-01,  3.0340e-01,  4.2989e-01,\n",
            "         2.7445e-01,  1.2035e-01, -2.2093e-02,  3.9756e-03,  9.0668e-01,\n",
            "         3.0462e-01,  3.1456e-02, -3.1365e-01, -2.0918e-01,  1.8491e-01,\n",
            "        -4.6200e-01, -1.2812e-01,  1.7352e-01, -1.2904e-01, -9.4852e-02,\n",
            "         6.2536e-01,  5.4139e-01, -5.9663e-01, -5.1223e-02,  2.5154e-01,\n",
            "        -1.6230e-01,  6.9358e-01,  1.7208e-01, -8.4789e-02, -1.8104e-01,\n",
            "         7.4637e-01, -1.7296e-02, -5.0799e-01,  6.5535e-01, -3.4123e-01,\n",
            "        -1.9944e-01, -1.6996e-01,  2.5113e-01,  1.7285e-01,  6.6511e-01,\n",
            "         1.1587e-01,  2.2431e-01, -1.5435e-01, -4.1032e-01,  3.6484e-02,\n",
            "         1.9693e-01,  3.1767e-01, -1.4384e-01,  3.0443e-01,  4.2711e-01,\n",
            "         2.5118e-01,  2.0746e-01,  9.0650e-02,  2.3387e-01, -1.0681e-01,\n",
            "         1.8373e-01,  4.3400e-01,  7.1643e-01,  4.2648e-01,  2.4327e-02,\n",
            "         2.3865e-01, -3.4872e-02,  1.7284e-01, -1.6652e-01,  5.2364e-01,\n",
            "         4.1170e-01,  3.1283e-01,  3.6574e-01,  1.0323e-01, -2.8030e-03,\n",
            "         2.0808e-01, -5.1984e-01,  5.3441e-02,  1.5388e-01,  5.7386e-01,\n",
            "        -8.1774e-02,  2.3391e-01, -3.9294e-02, -2.1559e-01,  5.6097e-01,\n",
            "         1.5744e-01,  1.2936e-01, -8.6905e-02,  2.5423e-02,  7.1574e-02,\n",
            "        -2.2564e-01, -6.3951e-01,  1.6088e-01, -1.6269e-01, -9.2741e-02,\n",
            "        -1.1703e-01, -3.0531e-01, -4.4492e-01, -3.2317e-01, -5.8066e-02,\n",
            "         2.4860e-01,  9.9389e-02, -1.9821e-01, -2.1239e-01, -2.4085e-01,\n",
            "         6.4790e-01, -7.4655e-01,  3.7981e-01, -6.5110e-02, -3.4183e-01,\n",
            "         3.4822e-01,  3.1774e-01, -2.0274e-01,  4.0467e-01,  6.6802e-02,\n",
            "         1.3807e-01, -1.5670e-03, -2.9354e-02,  6.5869e-02,  8.2961e-02,\n",
            "         2.3329e-01, -4.3338e-01, -2.0409e-01,  4.3774e-01,  6.5084e-01,\n",
            "        -7.9360e-01, -1.8654e-01, -2.5353e-01,  1.0320e-01, -2.0279e-01,\n",
            "        -1.1740e-01, -7.7969e-02,  1.6558e-01, -4.8021e-01, -1.5142e-01,\n",
            "         7.3437e-01,  1.1199e-02,  8.7553e-04,  2.8466e-01,  3.4770e-02,\n",
            "         4.1813e-01, -8.9079e-02,  3.5462e-02,  4.8644e-01,  8.5643e-02,\n",
            "        -1.5074e-01,  4.3372e-01,  2.2612e-01,  2.5478e-02, -6.9971e-01,\n",
            "         4.1687e-01, -7.0231e-02,  8.7503e-02, -5.0120e-01, -1.5709e-01,\n",
            "         3.4079e-01,  2.4226e-01, -6.9528e-01, -2.7760e-02, -1.1228e-01,\n",
            "        -4.1769e-01, -4.5634e-01, -5.0146e-01,  3.2412e-01, -1.9772e-01,\n",
            "        -1.3048e-01, -2.5367e-01,  3.1018e-01,  3.8568e-01,  2.5967e-01,\n",
            "        -1.2221e-01, -5.3193e-01,  4.3707e-02])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **N-grams**:\n",
        "  - Use sequences of n consecutive words to capture local word dependencies (e.g., bi-grams, tri-grams).\n",
        "  - Combine n-grams with BoW or TF-IDF for richer feature sets.\n"
      ],
      "metadata": {
        "id": "jXwgZs0x1oDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example text for demonstration\n",
        "text = [\"This is a simple example to demonstrate n-grams feature extraction.\"]\n",
        "\n",
        "# Create a CountVectorizer with n-gram range (1, 2)\n",
        "# This will generate both unigrams (single words) and bigrams (pairs of consecutive words)\n",
        "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "# Fit the vectorizer to the text and transform it into an n-gram matrix\n",
        "ngram_matrix = ngram_vectorizer.fit_transform(text)\n",
        "\n",
        "# Get the feature names (i.e., the generated n-grams)\n",
        "ngram_feature_names = ngram_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the n-gram matrix to an array for better readability\n",
        "ngram_array = ngram_matrix.toarray()\n",
        "\n",
        "print(\"N-gram Feature Names:\\n\", ngram_feature_names)  # Displays the generated n-grams\n",
        "print(\"N-gram Matrix:\\n\", ngram_array)  # Displays the matrix where rows represent documents and columns represent n-gram counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5nzAaIF1vTZ",
        "outputId": "957a5ba1-1e0a-4324-ab4e-d3fa8f7ccf55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-gram Feature Names:\n",
            " ['demonstrate' 'demonstrate grams' 'example' 'example to' 'extraction'\n",
            " 'feature' 'feature extraction' 'grams' 'grams feature' 'is' 'is simple'\n",
            " 'simple' 'simple example' 'this' 'this is' 'to' 'to demonstrate']\n",
            "N-gram Matrix:\n",
            " [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 2.4 **Advanced Feature Engineering**\n"
      ],
      "metadata": {
        "id": "PUw8FsZHl5os"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Domain-Specific Features**:\n",
        "\n",
        "  - Extract features based on domain knowledge (e.g., presence of URLs in spam detection, special symbols in technical documents).\n",
        "  - For some tasks, certain features may be highly relevant depending on the domain (e.g., the presence of URLs in spam detection or special symbols in financial documents). Below is an example to detect URLs in a text.\n",
        "\n"
      ],
      "metadata": {
        "id": "gOsFit_M2wA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sample text containing a URL\n",
        "text_with_url = \"Visit our website at https://www.example.com for more information.\"\n",
        "\n",
        "# Regular expression pattern to detect URLs\n",
        "url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "\n",
        "# Extract URLs from the text\n",
        "urls = re.findall(url_pattern, text_with_url)\n",
        "print(\"Detected URLs:\", urls)\n",
        "\n",
        "# Feature: Count the number of URLs in the text\n",
        "num_urls = len(urls)\n",
        "print(\"Number of URLs in the text:\", num_urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTnnCSi621kd",
        "outputId": "4c95c0f8-2706-419f-a6b8-f31e99a8874c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected URLs: ['https://www.example.com']\n",
            "Number of URLs in the text: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Part-of-Speech (POS) Tagging**:\n",
        "  - Use POS tags as features to incorporate syntactic information.\n",
        "  - Leverage NLTK's `pos_tag` function for POS tagging.\n"
      ],
      "metadata": {
        "id": "bkKHfOtu2vwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')  # Download the POS tagger models\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(\"POS Tags:\", pos_tags)\n",
        "\n",
        "# Extracting only the POS tags as features\n",
        "pos_features = [tag for word, tag in pos_tags]\n",
        "print(\"POS Features:\", pos_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jihk1mRk216w",
        "outputId": "51673087-2d09-48b8-ac99-22b9ba14fefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
            "POS Features: ['DT', 'JJ', 'NN', 'NN', 'VBZ', 'IN', 'DT', 'JJ', 'NN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Named Entity Recognition (NER)**:\n",
        "  - Identify named entities (e.g., person names, locations) and use them as features.\n",
        "  - Implement NER using NLTK or pre-trained models like spaCy.\n"
      ],
      "metadata": {
        "id": "cV99olJ82vsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')  # Download the NER chunker\n",
        "nltk.download('words')  # Download word corpus needed for NER\n",
        "\n",
        "# Example text\n",
        "text = \"Barack Obama was born in Hawaii and was the president of the United States.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging before NER\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Perform named entity recognition\n",
        "named_entities = nltk.ne_chunk(pos_tags)\n",
        "print(\"Named Entities:\", named_entities)\n",
        "\n",
        "# Extracting named entity chunks\n",
        "entities = []\n",
        "for chunk in named_entities:\n",
        "    if hasattr(chunk, 'label'):  # Checking if it's a named entity chunk\n",
        "        entity_name = \" \".join(c[0] for c in chunk)\n",
        "        entity_type = chunk.label()  # The entity type (e.g., PERSON, GPE)\n",
        "        entities.append((entity_name, entity_type))\n",
        "\n",
        "print(\"Extracted Named Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbDqZUU122OM",
        "outputId": "3dbf8a5c-d2f5-4547-ceb3-578342b23016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities: (S\n",
            "  (PERSON Barack/NNP)\n",
            "  (PERSON Obama/NNP)\n",
            "  was/VBD\n",
            "  born/VBN\n",
            "  in/IN\n",
            "  (GPE Hawaii/NNP)\n",
            "  and/CC\n",
            "  was/VBD\n",
            "  the/DT\n",
            "  president/NN\n",
            "  of/IN\n",
            "  the/DT\n",
            "  (GPE United/NNP States/NNPS)\n",
            "  ./.)\n",
            "Extracted Named Entities: [('Barack', 'PERSON'), ('Obama', 'PERSON'), ('Hawaii', 'GPE'), ('United States', 'GPE')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Syntactic Parsing**:\n",
        "  - Extract syntactic features from parse trees (e.g., noun phrases, verb phrases).\n"
      ],
      "metadata": {
        "id": "CxLGOK5T2vqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import CFG\n",
        "from nltk.parse.generate import generate\n",
        "\n",
        "# Example CFG (Context-Free Grammar)\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> DT NN | DT NNS\n",
        "  VP -> VBZ NP\n",
        "  DT -> 'the'\n",
        "  NN -> 'cat' | 'dog'\n",
        "  NNS -> 'cats'\n",
        "  VBZ -> 'chases'\n",
        "\"\"\")\n",
        "\n",
        "# Generate all sentences from the grammar\n",
        "for sentence in generate(grammar, n=10):\n",
        "    print(' '.join(sentence))\n",
        "\n",
        "# Parse a sentence using the CFG\n",
        "from nltk.parse import RecursiveDescentParser\n",
        "parser = RecursiveDescentParser(grammar)\n",
        "\n",
        "sentence = \"the cat chases the dog\".split()\n",
        "print(\"\\nParsing Sentence:\")\n",
        "for tree in parser.parse(sentence):\n",
        "    print(tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syB4OBmA22ip",
        "outputId": "f0703006-4313-4406-8101-7629074f383b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the cat chases the cat\n",
            "the cat chases the dog\n",
            "the cat chases the cats\n",
            "the dog chases the cat\n",
            "the dog chases the dog\n",
            "the dog chases the cats\n",
            "the cats chases the cat\n",
            "the cats chases the dog\n",
            "the cats chases the cats\n",
            "\n",
            "Parsing Sentence:\n",
            "(S (NP (DT the) (NN cat)) (VP (VBZ chases) (NP (DT the) (NN dog))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Sentiment Scores**:\n",
        "  - Use sentiment analysis tools (e.g., VADER) to add sentiment-related features.\n"
      ],
      "metadata": {
        "id": "1LeSHSG92vnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')  # Download the VADER lexicon for sentiment analysis\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Example text\n",
        "text = \"I love this product! It works amazingly well and is the best thing I've bought.\"\n",
        "\n",
        "# Get the sentiment scores\n",
        "sentiment_scores = sid.polarity_scores(text)\n",
        "print(\"Sentiment Scores:\", sentiment_scores)\n",
        "\n",
        "# Extract specific features from the sentiment scores\n",
        "positive_score = sentiment_scores['pos']\n",
        "neutral_score = sentiment_scores['neu']\n",
        "negative_score = sentiment_scores['neg']\n",
        "compound_score = sentiment_scores['compound']\n",
        "\n",
        "print(\"Positive Score:\", positive_score)\n",
        "print(\"Neutral Score:\", neutral_score)\n",
        "print(\"Negative Score:\", negative_score)\n",
        "print(\"Compound Score:\", compound_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5QPK2ti2293",
        "outputId": "4c911744-cc96-440d-aaf8-0eae88a35ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Scores: {'neg': 0.0, 'neu': 0.498, 'pos': 0.502, 'compound': 0.9019}\n",
            "Positive Score: 0.502\n",
            "Neutral Score: 0.498\n",
            "Negative Score: 0.0\n",
            "Compound Score: 0.9019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Topic Modeling**:\n",
        "  - Use techniques like **Latent Dirichlet Allocation (LDA)** to capture underlying topics as features.\n",
        "\n"
      ],
      "metadata": {
        "id": "6-Kc2LU82vJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Example corpus\n",
        "documents = [\n",
        "    \"I love to play football.\",\n",
        "    \"The game of football is exciting.\",\n",
        "    \"Artificial intelligence is a rapidly growing field.\",\n",
        "    \"Machine learning is a subset of artificial intelligence.\"\n",
        "]\n",
        "\n",
        "# Convert documents to a matrix of token counts\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "document_term_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Perform Latent Dirichlet Allocation (LDA) for topic modeling\n",
        "lda_model = LatentDirichletAllocation(n_components=2, random_state=0)\n",
        "lda_model.fit(document_term_matrix)\n",
        "\n",
        "# Display the topics and top words in each topic\n",
        "words = vectorizer.get_feature_names_out()\n",
        "for idx, topic in enumerate(lda_model.components_):\n",
        "    print(f\"Topic {idx+1}:\")\n",
        "    print(\" \".join([words[i] for i in topic.argsort()[-5:]]))  # Top 5 words per topic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW2hD-w-23bF",
        "outputId": "df60e120-d8c1-4c00-fc88-32ed62508100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1:\n",
            "subset learning machine artificial intelligence\n",
            "Topic 2:\n",
            "play love game exciting football\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5 **Practical Implementations Using NLTK and PyTorch**\n"
      ],
      "metadata": {
        "id": "6UnADtRcl5mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. **Basic Preprocessing Pipeline with NLTK**:\n",
        "  - Implement tokenization, stop word removal, stemming/lemmatization, and feature extraction using NLTK.\n"
      ],
      "metadata": {
        "id": "AJaTY9rl3kb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Sample text data\n",
        "text = \"Natural Language Processing (NLP) is an exciting area of machine learning and artificial intelligence.\"\n",
        "\n",
        "# 1. Tokenization\n",
        "# Split the text into individual words\n",
        "word_tokens = nltk.word_tokenize(text)\n",
        "print(\"Word Tokens:\", word_tokens)\n",
        "\n",
        "# 2. Lowercasing\n",
        "# Convert all tokens to lowercase\n",
        "lowercase_tokens = [word.lower() for word in word_tokens]\n",
        "print(\"Lowercased Tokens:\", lowercase_tokens)\n",
        "\n",
        "# 3. Removing Special Characters and Punctuation\n",
        "# Filter out non-alphanumeric characters\n",
        "cleaned_tokens = [re.sub(r'[^a-zA-Z0-9]', '', token) for token in lowercase_tokens if re.sub(r'[^a-zA-Z0-9]', '', token)]\n",
        "print(\"Cleaned Tokens:\", cleaned_tokens)\n",
        "\n",
        "# 4. Stop Word Removal\n",
        "# Remove common stop words like \"is\", \"an\", \"of\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in cleaned_tokens if word not in stop_words]\n",
        "print(\"Tokens after Stop Word Removal:\", filtered_tokens)\n",
        "\n",
        "# 5. Stemming\n",
        "# Reduce words to their root form\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
        "\n",
        "# 6. Lemmatization\n",
        "# Convert words to their base form\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMEJTycg3wXR",
        "outputId": "ee81ab73-380d-4051-fc62-840e440c76dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokens: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'an', 'exciting', 'area', 'of', 'machine', 'learning', 'and', 'artificial', 'intelligence', '.']\n",
            "Lowercased Tokens: ['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'an', 'exciting', 'area', 'of', 'machine', 'learning', 'and', 'artificial', 'intelligence', '.']\n",
            "Cleaned Tokens: ['natural', 'language', 'processing', 'nlp', 'is', 'an', 'exciting', 'area', 'of', 'machine', 'learning', 'and', 'artificial', 'intelligence']\n",
            "Tokens after Stop Word Removal: ['natural', 'language', 'processing', 'nlp', 'exciting', 'area', 'machine', 'learning', 'artificial', 'intelligence']\n",
            "Stemmed Tokens: ['natur', 'languag', 'process', 'nlp', 'excit', 'area', 'machin', 'learn', 'artifici', 'intellig']\n",
            "Lemmatized Tokens: ['natural', 'language', 'processing', 'nlp', 'exciting', 'area', 'machine', 'learning', 'artificial', 'intelligence']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. **Combining NLTK with Scikit-learn for BoW and TF-IDF**:\n",
        "  - Use NLTK for text cleaning and scikit-learn's vectorizers for feature extraction.\n"
      ],
      "metadata": {
        "id": "T-OGVXmg3kYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Sample text data for multiple documents\n",
        "documents = [\n",
        "    \"Natural Language Processing is fun!\",\n",
        "    \"Machine learning makes NLP more interesting.\",\n",
        "    \"Python is a great language for text processing.\",\n",
        "]\n",
        "\n",
        "# Preprocess each document using NLTK\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Lowercasing\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    # Removing special characters\n",
        "    tokens = [re.sub(r'[^a-zA-Z0-9]', '', word) for word in tokens if re.sub(r'[^a-zA-Z0-9]', '', word)]\n",
        "    # Stop word removal\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Join tokens back to a single string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to each document\n",
        "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
        "print(\"Preprocessed Documents:\", preprocessed_documents)\n",
        "\n",
        "# 1. Bag-of-Words Representation\n",
        "# Create a CountVectorizer instance\n",
        "bow_vectorizer = CountVectorizer()\n",
        "# Fit and transform the documents\n",
        "bow_features = bow_vectorizer.fit_transform(preprocessed_documents)\n",
        "print(\"Bag-of-Words Feature Array:\\n\", bow_features.toarray())\n",
        "print(\"Feature Names (BoW):\", bow_vectorizer.get_feature_names_out())\n",
        "\n",
        "# 2. TF-IDF Representation\n",
        "# Create a TfidfVectorizer instance\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "# Fit and transform the documents\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(preprocessed_documents)\n",
        "print(\"TF-IDF Feature Array:\\n\", tfidf_features.toarray())\n",
        "print(\"Feature Names (TF-IDF):\", tfidf_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM1cysOY30Q7",
        "outputId": "7ba0c923-6318-4dab-8477-03139934a27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Documents: ['natural language processing fun', 'machine learning make nlp interesting', 'python great language text processing']\n",
            "Bag-of-Words Feature Array:\n",
            " [[1 0 0 1 0 0 0 1 0 1 0 0]\n",
            " [0 0 1 0 1 1 1 0 1 0 0 0]\n",
            " [0 1 0 1 0 0 0 0 0 1 1 1]]\n",
            "Feature Names (BoW): ['fun' 'great' 'interesting' 'language' 'learning' 'machine' 'make'\n",
            " 'natural' 'nlp' 'processing' 'python' 'text']\n",
            "TF-IDF Feature Array:\n",
            " [[0.5628291  0.         0.         0.42804604 0.         0.\n",
            "  0.         0.5628291  0.         0.42804604 0.         0.        ]\n",
            " [0.         0.         0.4472136  0.         0.4472136  0.4472136\n",
            "  0.4472136  0.         0.4472136  0.         0.         0.        ]\n",
            " [0.         0.49047908 0.         0.37302199 0.         0.\n",
            "  0.         0.         0.         0.37302199 0.49047908 0.49047908]]\n",
            "Feature Names (TF-IDF): ['fun' 'great' 'interesting' 'language' 'learning' 'machine' 'make'\n",
            " 'natural' 'nlp' 'processing' 'python' 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. **Building Word Embeddings with PyTorch**:\n",
        "  - Use pre-trained embeddings (e.g., GloVe) with PyTorch's `torchtext` library.\n"
      ],
      "metadata": {
        "id": "XEb2afmt3kV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we will preprocess text using NLTK and create custom word embeddings using PyTorch. We will initialize the embeddings randomly and then demonstrate how to convert the preprocessed tokens into embedding vectors.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZQ5xT_8u4NQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Preprocess text using NLTK (reusing the preprocess_text function from above)\n",
        "text_for_embeddings = \"Deep learning models require high-quality embeddings.\"\n",
        "processed_text = preprocess_text(text_for_embeddings)  # Assuming preprocess_text returns a list\n",
        "print(\"Preprocessed Text for Embeddings:\", processed_text)\n",
        "\n",
        "# Tokenize the processed text into words (No need to split if it's already a list)\n",
        "# tokens = processed_text.split()  # Remove this line\n",
        "tokens = processed_text  # Use the processed_text directly as tokens\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Create a vocabulary of the words\n",
        "vocab = {word: i for i, word in enumerate(set(tokens))}\n",
        "print(\"Vocabulary:\", vocab)\n",
        "\n",
        "# Create an embedding layer with the size of the vocabulary\n",
        "# Define embedding dimension (e.g., 10)\n",
        "embedding_dim = 10\n",
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embedding_dim)\n",
        "\n",
        "# Convert tokens into indices based on the vocabulary\n",
        "indices = torch.tensor([vocab[token] for token in tokens], dtype=torch.long)\n",
        "print(\"Indices:\", indices)\n",
        "\n",
        "# Pass the indices through the embedding layer to get word embeddings\n",
        "embedded_tokens = embedding_layer(indices)\n",
        "print(\"Embedded Tokens:\\n\", embedded_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC93rD_Y33es",
        "outputId": "e976880a-133a-4553-d4b3-3df8de94ca99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Text for Embeddings: ['deep', 'learning', 'model', 'require', 'highquality', 'embeddings']\n",
            "Tokens: ['deep', 'learning', 'model', 'require', 'highquality', 'embeddings']\n",
            "Vocabulary: {'deep': 0, 'learning': 1, 'require': 2, 'embeddings': 3, 'model': 4, 'highquality': 5}\n",
            "Indices: tensor([0, 1, 4, 2, 5, 3])\n",
            "Embedded Tokens:\n",
            " tensor([[-0.6018, -0.6115,  0.6035,  0.0116, -0.0642,  0.1093,  1.5187,  1.8751,\n",
            "         -0.6289, -0.1515],\n",
            "        [-0.4774,  1.2844, -0.9774,  0.6586,  0.2338,  1.3237,  1.1129, -0.7060,\n",
            "          1.6030, -0.8359],\n",
            "        [-1.1107, -0.5906,  0.2105, -1.1151, -0.4692, -0.1182, -0.4299, -0.5282,\n",
            "         -1.8053, -0.6475],\n",
            "        [ 0.6377,  1.6067, -1.4270,  1.0003, -0.1413, -0.4395, -0.1992, -0.9898,\n",
            "          2.4948, -1.2688],\n",
            "        [ 0.9818,  1.9060, -0.1517,  1.5721,  0.9548,  1.5889,  0.3732, -0.2467,\n",
            "          1.5822,  0.2485],\n",
            "        [ 0.9142,  0.2455,  0.4955,  0.4970,  0.1109,  0.0704,  0.1963,  0.1257,\n",
            "          0.4097, -0.0279]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. **Integrating BERT for Feature Extraction in PyTorch**:\n",
        "  - Use Hugging Face's `transformers` library to extract contextual embeddings for each text.\n",
        "\n"
      ],
      "metadata": {
        "id": "g_-hmiFb3kTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Preprocess text using NLTK\n",
        "text_for_bert = \"Text classification tasks can benefit from pre-trained models like BERT.\"\n",
        "processed_text = preprocess_text_for_embeddings(text_for_bert)\n",
        "processed_text = ' '.join(processed_text)  # Join tokens for BERT processing\n",
        "print(\"Processed Text for BERT:\", processed_text)\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the processed text\n",
        "input_ids = tokenizer.encode(processed_text, return_tensors='pt')\n",
        "print(\"Tokenized Input IDs:\", input_ids)\n",
        "\n",
        "# Extract embeddings using BERT\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "print(\"BERT Embeddings:\\n\", last_hidden_states)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w-j-lSu3-DU",
        "outputId": "e1efa903-754e-4be4-bca0-bed35508efd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Text for BERT: text classification task benefit pretrained model like bert\n",
            "Tokenized Input IDs: tensor([[  101,  3793,  5579,  4708,  5770,  3653, 23654,  2098,  2944,  2066,\n",
            "         14324,   102]])\n",
            "BERT Embeddings:\n",
            " tensor([[[-0.4142, -0.1928, -0.0709,  ..., -0.5888, -0.0326,  0.4164],\n",
            "         [-0.4245,  0.1284,  0.1029,  ..., -0.0319,  0.4030,  0.0015],\n",
            "         [-0.2798,  0.0493,  0.0273,  ..., -0.7371, -0.1523,  0.1787],\n",
            "         ...,\n",
            "         [-0.4364, -0.1351,  0.3804,  ..., -0.6504,  0.2804, -0.1594],\n",
            "         [-0.4033, -0.7611,  0.0645,  ...,  0.2308,  0.0244,  0.0938],\n",
            "         [ 0.8104,  0.0061, -0.5499,  ...,  0.3899, -0.5547, -0.1938]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.6 **Challenges in Text Preprocessing and Feature Extraction**\n"
      ],
      "metadata": {
        "id": "fhUzS85Al5jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. **Handling Noisy Data**:\n",
        "  - Develop strategies to clean and normalize text while preserving useful information.\n"
      ],
      "metadata": {
        "id": "XEgUXF-E5Ksv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example text with noise (misspellings, special characters, repeated characters)\n",
        "noisy_text = \"Thisss is an examplle of noooiiisy texttt!! #NLP @OpenAI :)\"\n",
        "\n",
        "# Step 1: Remove special characters (e.g., hashtags, mentions, emojis)\n",
        "cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', noisy_text)\n",
        "print(\"Text after removing special characters:\", cleaned_text)\n",
        "\n",
        "# Step 2: Handle repeated characters (e.g., 'ss' in 'Thisss')\n",
        "def remove_repeated_characters(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1\\1', text)  # Replace sequences of characters with two occurrences\n",
        "\n",
        "cleaned_text = remove_repeated_characters(cleaned_text)\n",
        "print(\"Text after handling repeated characters:\", cleaned_text)\n",
        "\n",
        "# Step 3: Tokenize and remove stop words\n",
        "word_tokens = nltk.word_tokenize(cleaned_text)\n",
        "filtered_tokens = [word for word in word_tokens if word.lower() not in stopwords.words('english')]\n",
        "print(\"Tokens after stop word removal:\", filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "167Zde5q5TnQ",
        "outputId": "719396e2-bad7-4487-dd8f-f87a0a80ab00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text after removing special characters: Thisss is an examplle of noooiiisy texttt NLP OpenAI \n",
            "Text after handling repeated characters: Thiss is an examplle of nooiisy textt NLP OpenAI \n",
            "Tokens after stop word removal: ['Thiss', 'examplle', 'nooiisy', 'textt', 'NLP', 'OpenAI']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. **Overfitting in Feature-rich Representations**:\n",
        "  - Use dimensionality reduction or regularization techniques to prevent overfitting when using high-dimensional features.\n",
        "  - When using a large number of features (e.g., n-grams), there is a risk of overfitting, where the model performs well on training data but poorly on unseen data. Techniques like dimensionality reduction can help mitigate this.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XcyNwkYa5KpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Example corpus with feature-rich text\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Never jump over the lazy dog quickly.\",\n",
        "    \"A fast, brown fox leaps over a sleepy dog.\",\n",
        "]\n",
        "\n",
        "# Step 1: Convert the text into TF-IDF features\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3))  # Using unigrams, bigrams, and trigrams\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "print(\"Original TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
        "\n",
        "# Step 2: Perform dimensionality reduction using TruncatedSVD\n",
        "# Reducing the number of features from original dimension to 2 components\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "print(\"Reduced TF-IDF Matrix Shape:\", reduced_matrix.shape)\n",
        "\n",
        "# The original TF-IDF matrix had a high dimensionality, but we reduced it to 2 components\n",
        "# to avoid overfitting by keeping only the most important information.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sISIR2Q5T-E",
        "outputId": "de5fd65f-5879-4d5b-cac9-ae013af42feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original TF-IDF Matrix Shape: (3, 45)\n",
            "Reduced TF-IDF Matrix Shape: (3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. **Choosing the Right Features**:\n",
        "  - Perform error analysis to refine the feature set based on task requirements.\n"
      ],
      "metadata": {
        "id": "y5ggUb3E5Kkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Sample data for classification\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Never jump over the lazy dog quickly.\",\n",
        "    \"A fast, brown fox leaps over a sleepy dog.\",\n",
        "    \"I love NLP and machine learning.\",\n",
        "    \"NLP is fascinating and fun!\",\n",
        "    \"I dislike boring tasks.\",\n",
        "    \"Tasks like these are very interesting.\",\n",
        "]\n",
        "labels = [0, 0, 0, 1, 1, 2, 2]  # Three classes: 0, 1, 2\n",
        "\n",
        "# Step 1: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(documents, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "# Step 2: Convert the text data into TF-IDF features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 3: Train a Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 4: Make predictions and evaluate the model\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 5: Error Analysis using Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# If there are many misclassifications in certain classes, we can perform feature selection\n",
        "# or add domain-specific features (e.g., specific keywords for each class) to improve the model.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc-v8sYN5UTx",
        "outputId": "affc7e26-6ca4-4cad-dde8-e57d0cba70e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.33      0.17      0.22         3\n",
            "weighted avg       0.67      0.33      0.44         3\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. **Computational Efficiency**:\n",
        "  - Balance the complexity of feature extraction techniques with the computational resources available.\n",
        "\n"
      ],
      "metadata": {
        "id": "_CXcr2r25Khq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example large text corpus\n",
        "large_corpus = [\n",
        "    \"Natural language processing is a fascinating field.\",\n",
        "    \"Machine learning is revolutionizing many industries.\",\n",
        "    \"Deep learning and neural networks are advancing rapidly.\",\n",
        "    \"There are numerous applications of artificial intelligence.\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "] * 1000  # Simulate a larger corpus by repeating entries\n",
        "\n",
        "# Step 1: Use CountVectorizer with a limited vocabulary size for computational efficiency\n",
        "vectorizer = CountVectorizer(max_features=100)  # Limit to the top 100 most frequent words\n",
        "vectorized_data = vectorizer.fit_transform(large_corpus)\n",
        "\n",
        "print(\"Shape of Vectorized Data with Limited Vocabulary:\", vectorized_data.shape)\n",
        "\n",
        "# Step 2: Tokenizing using NLTK's RegexpTokenizer for efficiency\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Initialize the RegexpTokenizer with a pattern for word characters only\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# Tokenize one of the sample texts\n",
        "sample_text = \"Natural language processing and machine learning are closely related fields.\"\n",
        "tokens = tokenizer.tokenize(sample_text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Limiting the vocabulary size and using efficient tokenizers can significantly reduce\n",
        "# processing time and memory usage when dealing with large datasets.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qHq5ecq5UpH",
        "outputId": "17de8836-6e03-40d2-fd69-b8380331f9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Vectorized Data with Limited Vocabulary: (5000, 32)\n",
            "Tokens: ['Natural', 'language', 'processing', 'and', 'machine', 'learning', 'are', 'closely', 'related', 'fields']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.7 **Transition to the Next Section**\n",
        "   - This section has covered various techniques for preparing text data and extracting meaningful features. These steps are crucial for ensuring the input to machine learning and deep learning models is both relevant and well-structured.\n",
        "   - In the next section, we will explore \"Classical Machine Learning Approaches,\" where the processed text data will be used to train traditional models like Naive Bayes, Decision Trees, and Logistic Regression. The concepts learned in this section will lay the groundwork for implementing these algorithms effectively."
      ],
      "metadata": {
        "id": "O7UX_r_Rl5g0"
      }
    }
  ]
}