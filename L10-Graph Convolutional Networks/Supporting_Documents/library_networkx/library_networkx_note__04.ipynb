{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/qL4ySEB8MegEwymBMTc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babupallam/Msc_AI_Module2_Natural_Language_Processing/blob/main/L10-Graph%20Convolutional%20Networks/Supporting_Documents/library_networkx/library_networkx_note__04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSAGE and Graph Isomorphism Network (GIN), which are designed for scalable and expressive graph learning tasks."
      ],
      "metadata": {
        "id": "lYafEEdt5jrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 61: GraphSAGE Layer (Sample and Aggregate)\n",
        "\n",
        "\n",
        "### GraphSAGE (Graph Sample and Aggregate)\n",
        "\n",
        "GraphSAGE (Graph Sample and Aggregate) is a framework designed to generate node embeddings in a scalable way. Unlike many traditional graph neural networks that require all nodes' features and structure for each batch, GraphSAGE works by **sampling a fixed number of neighbors** for each node, which makes it more suitable for large graphs.\n",
        "\n",
        "#### Key Concepts\n",
        "\n",
        "1. **Sampling-Based Aggregation**:\n",
        "   - Instead of aggregating all neighbors, GraphSAGE samples a fixed number of neighbors for each node.\n",
        "   - This makes GraphSAGE more scalable, as it doesn’t require loading the entire graph at once.\n",
        "\n",
        "2. **Neighbor Aggregation**:\n",
        "   - GraphSAGE uses different types of aggregation functions, such as:\n",
        "     - **Mean Aggregation**: Takes the average of the features of the sampled neighbors.\n",
        "     - **LSTM Aggregation**: Uses an LSTM network to aggregate neighbor features, which can capture more complex patterns.\n",
        "     - **Pooling Aggregation**: Applies a neural network layer followed by a pooling function (like max or mean pooling) to summarize neighbor features.\n",
        "\n",
        "3. **Inductive Learning**:\n",
        "   - GraphSAGE is designed for inductive tasks, where it can generalize to unseen nodes or graphs by learning functions for sampling and aggregating neighbors.\n",
        "\n",
        "#### Workflow of GraphSAGE\n",
        "\n",
        "1. **Sampling**: For each node, sample a fixed number of neighbors at each layer.\n",
        "2. **Aggregation**: Use an aggregation function to combine the features of the sampled neighbors.\n",
        "3. **Update**: Concatenate the node’s current representation with the aggregated features, then apply a neural network layer to produce the new node embedding.\n",
        "4. **Stacking Layers**: Repeat the process for a fixed number of layers, effectively allowing each node to capture information from neighbors up to `k` hops away.\n",
        "\n",
        "#### Applications of GraphSAGE\n",
        "\n",
        "- **Social Networks**: Friend recommendation by embedding users based on their connections.\n",
        "- **Biological Networks**: Predicting protein-protein interactions or classifying proteins based on neighborhood structures.\n",
        "- **Knowledge Graphs**: Learning embeddings for entities that capture relational information.\n",
        "\n",
        "### Graph Isomorphism Network (GIN)\n",
        "\n",
        "The Graph Isomorphism Network (GIN) is a powerful type of graph neural network designed to **capture structural information** in a way that is as powerful as the Weisfeiler-Lehman (WL) graph isomorphism test. This is achieved by making GIN highly expressive, enabling it to distinguish between different graph structures more effectively than other GNNs.\n",
        "\n",
        "#### Key Concepts\n",
        "\n",
        "1. **Expressive Power**:\n",
        "   - GIN is designed to be as expressive as the WL graph isomorphism test, which is a method for determining if two graphs are structurally identical.\n",
        "   - GIN achieves this by using a unique aggregation and update function that captures subtle structural differences.\n",
        "\n",
        "2. **Sum Aggregation**:\n",
        "   - Unlike other GNNs that use mean or max pooling, GIN uses **sum aggregation** to combine features from neighbors.\n",
        "   - Sum aggregation ensures that the network does not lose information by averaging out differences, which can be crucial for distinguishing nodes with similar neighborhoods.\n",
        "\n",
        "3. **MLP Update**:\n",
        "   - After aggregation, GIN applies a **multilayer perceptron (MLP)** to the combined features, which gives it more flexibility to learn complex transformations.\n",
        "   - The MLP updates the node’s representation based on both its own features and the aggregated neighbor features.\n",
        "\n",
        "4. **Injective Aggregation**:\n",
        "   - The design of GIN makes it possible to represent different neighborhoods uniquely, which helps it distinguish between nodes that might look identical to other GNNs.\n",
        "\n",
        "#### Workflow of GIN\n",
        "\n",
        "1. **Sum Aggregation**: Aggregate neighbor features using sum rather than mean or max.\n",
        "2. **Update with MLP**: Apply an MLP to the aggregated features plus the node’s own features.\n",
        "3. **Stacking Layers**: Stack multiple GIN layers to allow each node to capture information from multiple hops.\n",
        "\n",
        "#### Applications of GIN\n",
        "\n",
        "- **Molecular Graphs**: Useful in predicting molecular properties, as it captures structural information in molecules very effectively.\n",
        "- **Graph Classification**: Suitable for tasks where the goal is to classify entire graphs rather than individual nodes, such as classifying chemical compounds or proteins.\n",
        "- **Structural Pattern Detection**: GIN’s expressive power makes it ideal for detecting structural patterns in complex graphs.\n",
        "\n",
        "### Comparison of GraphSAGE and GIN\n",
        "\n",
        "| Aspect                     | GraphSAGE                                           | GIN                                      |\n",
        "|----------------------------|-----------------------------------------------------|------------------------------------------|\n",
        "| **Aggregation Method**     | Mean, LSTM, Pooling (sampling-based)                | Sum                                      |\n",
        "| **Expressive Power**       | Less expressive, designed for scalability           | Highly expressive, can capture graph isomorphisms |\n",
        "| **Scalability**            | High (samples neighbors, avoids entire graph loading) | Lower scalability (needs full neighborhood aggregation) |\n",
        "| **Inductive Learning**     | Yes (can generalize to unseen nodes)                | No (trained on a fixed graph)            |\n",
        "| **Typical Use Cases**      | Large, dynamic graphs (social networks, knowledge graphs) | Small, structured graphs (molecular graphs, chemistry) |\n",
        "| **Update Mechanism**       | Aggregation followed by concatenation               | Sum aggregation followed by MLP update   |\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **GraphSAGE** is best suited for large, dynamic graphs where scalability is crucial, and it achieves this by sampling neighbors and using various aggregation methods.\n",
        "- **GIN** is highly expressive, capable of distinguishing different graph structures, and is ideal for tasks that require precise structural understanding, such as molecular property prediction."
      ],
      "metadata": {
        "id": "oof4Hnst5e69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4krgRU45dBb",
        "outputId": "3c410ff6-7eca-4653-bbd2-f6714feb65b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphSAGE Layer created.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class GraphSAGELayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, aggregator=\"mean\"):\n",
        "        super(GraphSAGELayer, self).__init__()\n",
        "        # The in_features for the linear layer should be the sum of\n",
        "        # original in_features and the out_features (due to concatenation)\n",
        "        self.linear = nn.Linear(in_features + in_features, out_features)\n",
        "        self.aggregator = aggregator\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # Aggregate features from neighbors\n",
        "        if self.aggregator == \"mean\":\n",
        "            neighbor_features = torch.matmul(adj, x) / adj.sum(1, keepdim=True)\n",
        "        elif self.aggregator == \"max\":\n",
        "            neighbor_features, _ = torch.max(torch.matmul(adj, x), dim=1)\n",
        "\n",
        "        # Concatenate self and neighbor features\n",
        "        out = torch.cat([x, neighbor_features], dim=1)\n",
        "        return torch.relu(self.linear(out))\n",
        "\n",
        "# Initialize a GraphSAGE layer with mean aggregation\n",
        "graphsage_layer = GraphSAGELayer(in_features=2, out_features=4, aggregator=\"mean\")\n",
        "print(\"GraphSAGE Layer created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 62: Forward Pass through GraphSAGE Layer\n",
        " Perform a forward pass through the GraphSAGE layer.\n"
      ],
      "metadata": {
        "id": "gsP7168_5fob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPMYn_445fod",
        "outputId": "cfebefc0-965d-46c3-dced-f7b48059db60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output after GraphSAGE layer:\n",
            " tensor([[4.3317, 0.3054, 0.0000, 2.8851],\n",
            "        [2.3624, 0.0000, 0.0000, 0.6322],\n",
            "        [2.8036, 0.0000, 0.0000, 0.4942]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Assuming node_features_tensor should be a 2D tensor\n",
        "node_features_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], dtype=torch.float32)\n",
        "\n",
        "# Assuming adj_matrix_tensor should be a 2D tensor representing adjacency matrix\n",
        "adj_matrix_tensor = torch.tensor([[0, 1, 1], [1, 0, 0], [1, 0, 0]], dtype=torch.float32)\n",
        "\n",
        "output_graphsage = graphsage_layer(node_features_tensor, adj_matrix_tensor)\n",
        "print(\"Output after GraphSAGE layer:\\n\", output_graphsage)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 63: Building a Two-Layer GraphSAGE Model\n",
        " We stack two GraphSAGE layers to create a more expressive model for graph representation learning.\n"
      ],
      "metadata": {
        "id": "RcfOETjr5fsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaI8GBUv5fsw",
        "outputId": "35c81b4d-2f5d-462b-a8f4-d92c64583378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two-Layer GraphSAGE model created.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class TwoLayerGraphSAGE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwoLayerGraphSAGE, self).__init__()\n",
        "        self.sage1 = GraphSAGELayer(in_features=2, out_features=4, aggregator=\"mean\")\n",
        "        self.sage2 = GraphSAGELayer(in_features=4, out_features=2, aggregator=\"mean\")\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.sage1(x, adj)\n",
        "        x = torch.relu(x)\n",
        "        x = self.sage2(x, adj)\n",
        "        return x\n",
        "\n",
        "# Initialize the two-layer GraphSAGE model\n",
        "two_layer_graphsage = TwoLayerGraphSAGE()\n",
        "print(\"Two-Layer GraphSAGE model created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 64: Graph Isomorphism Network (GIN) Layer\n",
        " GIN is designed to capture graph structure more effectively, using sum aggregation and injective functions.\n"
      ],
      "metadata": {
        "id": "YSa-c2ca5f0p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkjy4sUM5f0r",
        "outputId": "0d4f8d51-be0c-4648-e301-98b7377eb668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Isomorphism Network Layer created.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class GINLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GINLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # Sum aggregation over neighbors\n",
        "        aggregated = torch.matmul(adj, x) + x  # Add self-connections (self-loop)\n",
        "        return torch.relu(self.linear(aggregated))\n",
        "\n",
        "# Initialize a GIN layer\n",
        "gin_layer = GINLayer(in_features=2, out_features=4)\n",
        "print(\"Graph Isomorphism Network Layer created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 65: Forward Pass through GIN Layer\n",
        " Perform a forward pass through the GIN layer.\n"
      ],
      "metadata": {
        "id": "t97V46mN5f32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd8xR7GK5f33",
        "outputId": "d7d922d5-4e2b-439f-b8d3-789e22a12c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output after GIN layer:\n",
            " tensor([[1.4928, 4.2979, 0.3393, 3.2505],\n",
            "        [0.4514, 2.3641, 0.0498, 1.3902],\n",
            "        [0.9207, 2.9143, 0.3038, 2.1200]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "output_gin = gin_layer(node_features_tensor, adj_matrix_tensor)\n",
        "print(\"Output after GIN layer:\\n\", output_gin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 66: Building a Two-Layer GIN Model\n",
        " We can stack multiple GIN layers for a deeper model that captures complex structural information.\n"
      ],
      "metadata": {
        "id": "iN56Qkgs5f6F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9RU9yZU5f6G",
        "outputId": "693d7c68-6d5d-4b50-859b-75450a7d1031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two-Layer GIN model created.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class TwoLayerGIN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwoLayerGIN, self).__init__()\n",
        "        self.gin1 = GINLayer(in_features=2, out_features=4)\n",
        "        self.gin2 = GINLayer(in_features=4, out_features=2)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.gin1(x, adj)\n",
        "        x = torch.relu(x)\n",
        "        x = self.gin2(x, adj)\n",
        "        return x\n",
        "\n",
        "# Initialize the two-layer GIN model\n",
        "two_layer_gin = TwoLayerGIN()\n",
        "print(\"Two-Layer GIN model created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 67: Graph Pooling with GraphSAGE and GIN\n",
        " Pooling can be applied to GraphSAGE or GIN models to generate graph-level representations.\n"
      ],
      "metadata": {
        "id": "bFageLfu5f7Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Hq8ZZk5f7R",
        "outputId": "dcf93bcd-36ba-457c-8885-2b6964aa68de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph-level Representation (GraphSAGE with Sum Pooling): tensor([0.1770, 1.2386], grad_fn=<SumBackward1>)\n",
            "Graph-level Representation (GIN with Mean Pooling): tensor([7.5310, 0.0000], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example of sum pooling after a GraphSAGE model forward pass\n",
        "output_graphsage = two_layer_graphsage(node_features_tensor, adj_matrix_tensor)\n",
        "graph_representation_graphsage = output_graphsage.sum(dim=0)\n",
        "print(\"Graph-level Representation (GraphSAGE with Sum Pooling):\", graph_representation_graphsage)\n",
        "\n",
        "# Example of mean pooling after a GIN model forward pass\n",
        "output_gin = two_layer_gin(node_features_tensor, adj_matrix_tensor)\n",
        "graph_representation_gin = output_gin.mean(dim=0)\n",
        "print(\"Graph-level Representation (GIN with Mean Pooling):\", graph_representation_gin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 68: Graph Classification with GIN Model\n",
        " We can use the GIN model for graph classification tasks by applying pooling and fully connected layers.\n"
      ],
      "metadata": {
        "id": "tJkNXds95f8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhasHQym5f8V",
        "outputId": "0eee97d5-fc1d-4c09-ea4b-acf8932a2057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIN Graph Classifier model created.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class GINGraphClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GINGraphClassifier, self).__init__()\n",
        "        self.gin1 = GINLayer(in_features=2, out_features=4)\n",
        "        self.gin2 = GINLayer(in_features=4, out_features=2)\n",
        "        self.fc = nn.Linear(2, 1)  # Final layer for binary classification\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.gin1(x, adj)\n",
        "        x = torch.relu(x)\n",
        "        x = self.gin2(x, adj)\n",
        "        x = x.mean(dim=0)  # Mean pooling for graph-level representation\n",
        "        return self.fc(x)\n",
        "\n",
        "# Initialize the GIN graph classifier model\n",
        "gin_classifier = GINGraphClassifier()\n",
        "print(\"GIN Graph Classifier model created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 69: Training GIN Graph Classifier Model\n",
        " Train the GIN graph classifier on a simple binary classification task.\n"
      ],
      "metadata": {
        "id": "FU9GK0gZ5f9a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rsZMDFbZ5f9a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define label for the graph (e.g., 1 for \"positive class\")\n",
        "graph_label = torch.tensor([1.0])\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def trainModel(model, node_features, adj_matrix, graph_label, epochs, lr=0.01):\n",
        "    \"\"\"\n",
        "    Trains a graph classification model.\n",
        "\n",
        "    Args:\n",
        "        model: The graph classification model (e.g., GINGraphClassifier).\n",
        "        node_features: Tensor representing node features.\n",
        "        adj_matrix: Tensor representing the adjacency matrix.\n",
        "        graph_label: Tensor representing the graph label.\n",
        "        epochs: Number of training epochs (default: 20).\n",
        "        lr: Learning rate (default: 0.01).\n",
        "\n",
        "    Returns:\n",
        "        Trained model.\n",
        "    \"\"\"\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        output = model(node_features, adj_matrix)\n",
        "        loss = loss_fn(output, graph_label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration 70: Evaluating the GIN Model Predictions\n",
        " Evaluate predictions of the GIN model on the graph classification task.\n"
      ],
      "metadata": {
        "id": "t4J9S3MQ5f-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "trained_model = trainModel(gin_classifier, node_features_tensor, adj_matrix_tensor, graph_label,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0CMVvx7CR6w",
        "outputId": "7251c2d1-9069-4700-ae9e-fdadb18940c9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.376694917678833\n",
            "Epoch 2, Loss: 0.3735669255256653\n",
            "Epoch 3, Loss: 0.37046098709106445\n",
            "Epoch 4, Loss: 0.3673773407936096\n",
            "Epoch 5, Loss: 0.36431628465652466\n",
            "Epoch 6, Loss: 0.36127805709838867\n",
            "Epoch 7, Loss: 0.35826295614242554\n",
            "Epoch 8, Loss: 0.35527122020721436\n",
            "Epoch 9, Loss: 0.35230299830436707\n",
            "Epoch 10, Loss: 0.34935858845710754\n",
            "Epoch 11, Loss: 0.34643813967704773\n",
            "Epoch 12, Loss: 0.34354180097579956\n",
            "Epoch 13, Loss: 0.34066975116729736\n",
            "Epoch 14, Loss: 0.33782216906547546\n",
            "Epoch 15, Loss: 0.334999144077301\n",
            "Epoch 16, Loss: 0.3322007954120636\n",
            "Epoch 17, Loss: 0.32942721247673035\n",
            "Epoch 18, Loss: 0.32667848467826843\n",
            "Epoch 19, Loss: 0.32395467162132263\n",
            "Epoch 20, Loss: 0.32125580310821533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1X2Bx6q5f-8",
        "outputId": "36332511-f6b6-49e4-eb43-72abf9878d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: tensor(1, dtype=torch.int32)\n",
            "Actual Label: tensor([1], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get predictions\n",
        "output = gin_classifier(node_features_tensor, adj_matrix_tensor).squeeze()\n",
        "prediction = (torch.sigmoid(output) > 0.5).int()\n",
        "print(\"Prediction:\", prediction)\n",
        "print(\"Actual Label:\", graph_label.int())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "trained_model = trainModel(gin_classifier, node_features_tensor, adj_matrix_tensor, graph_label,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0079eb-f996-4962-8596-ae7f5f29574e",
        "id": "mgfP5mFNCZHr"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2923385500907898\n",
            "Epoch 2, Loss: 0.28981316089630127\n",
            "Epoch 3, Loss: 0.28730711340904236\n",
            "Epoch 4, Loss: 0.2848205864429474\n",
            "Epoch 5, Loss: 0.2823539078235626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d32868-fcff-425f-dba3-6d618445a3f6",
        "id": "A0gM_1k3CZHs"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: tensor(1, dtype=torch.int32)\n",
            "Actual Label: tensor([1], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get predictions\n",
        "output = gin_classifier(node_features_tensor, adj_matrix_tensor).squeeze()\n",
        "prediction = (torch.sigmoid(output) > 0.5).int()\n",
        "print(\"Prediction:\", prediction)\n",
        "print(\"Actual Label:\", graph_label.int())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XhrEY6nl5gA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2zpa7P75gA1"
      },
      "outputs": [],
      "source": []
    }
  ]
}