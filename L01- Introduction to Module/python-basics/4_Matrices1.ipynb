{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matrices.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYQE37rOc539"
      },
      "source": [
        "# Matrices in pytorch\n",
        "\n",
        "\n",
        "-Professor: M.Sc.Saul Calderon.\n",
        "\n",
        "- Authors: \n",
        "    - M. Sc. Saúl Calderón, Dr. Juan Esquivel. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGl4eEBfJXGl",
        "colab_type": "text"
      },
      "source": [
        "# Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmUdHykmJXGm",
        "colab_type": "code",
        "outputId": "27501b42-f7ee-433a-831f-160bec000d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Since Collab is being used, it is necessary to install Pytorch\n",
        "!pip install torch\n",
        "import torch as torch\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8chJbeF0dXmO"
      },
      "source": [
        "# Matrices for rewriting equations and functions\n",
        "\n",
        "The following equation system:\n",
        "$$\\begin{array}{c}\n",
        "4x_{1}-5x_{2}=-13\\\\\n",
        "-2x_{1}+3x_{2}=9\n",
        "\\end{array}$$\n",
        "can be rewritten interms of vectors and matrices as follows:\n",
        "$$A\\,\\vec{x}=\\overrightarrow{b}\\Rightarrow\\vec{x}=A^{-1}\\overrightarrow{b}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iyuBQcxGdXmP",
        "outputId": "62197fe5-b093-424d-9961-01071b2c41af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "def testSolveEquationSystem1():\n",
        "    \"\"\"\n",
        "    Solve an equation system with one solution\n",
        "    \"\"\"\n",
        "    A = torch.tensor([[4.0, -5.0], [-2.0, 3.0]])\n",
        "    #create a 2d tensor even for vectors, to avoid to create 1dtensor type creation\n",
        "    b = torch.tensor([[-13.0], [9.0]])\n",
        "    Ainv = A.inverse()\n",
        "    x = Ainv.mm(b)\n",
        "    print(x)\n",
        "    \n",
        "\n",
        "def testSolveEquationSystem2():\n",
        "    \"\"\"\n",
        "    Solve an equation system with multiple solutions (one row is linear combination of the other)\n",
        "    \"\"\"\n",
        "    A = torch.tensor([[4.0, -5.0], [8.0, -10.0]])\n",
        "    #create a 2d tensor even for vectors, to avoid to create 1dtensor type creation\n",
        "    b = torch.tensor([[-13.0], [9.0]])\n",
        "    Ainv = A.inverse()\n",
        "    x = Ainv.mm(b)\n",
        "    print(x)\n",
        "    \n",
        "    \n",
        "testSolveEquationSystem1()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.],\n",
            "        [5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3uCtcT9FFQ_X"
      },
      "source": [
        "## Identity matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yqk8N_AeFRFX",
        "outputId": "4d09f4e9-2075-4018-ca65-478c2ee3077d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Create an identity matrix\n",
        "Identity = torch.eye(5)\n",
        "print(Identity)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LDRQBcuic54b"
      },
      "source": [
        "## Matrix Transpose\n",
        "The transpose operation is only defined for 2D tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCyH9GOCvxBk",
        "outputId": "6c9f01b3-f3ba-4a11-c1b3-59decc725c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Transpose cannot work with 1D tensors\n",
        "w = torch.tensor([1, 2, 3])\n",
        "#check tensor type\n",
        "print(\"Type 1D tensor: \", w.type(), w.shape)\n",
        "\n",
        "#row vector in 2D tensor\n",
        "w2Drow = w.reshape(-1, w.shape[0])\n",
        "print(\"Type 2D Tensor \", w2Drow.type(), w2Drow.shape)\n",
        "\n",
        "print(\"row vector \", w2Drow)\n",
        "\n",
        "#transpose receives the first dim0 to switch, and the second dim1 to swap, usually 0,1 is the order\n",
        "wDrowT = w2Drow.transpose(0, 1)\n",
        "\n",
        "print(wDrowT)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type 1D tensor:  torch.LongTensor torch.Size([3])\n",
            "Type 2D Tensor  torch.LongTensor torch.Size([1, 3])\n",
            "row vector  tensor([[1, 2, 3]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLhkAv72JXG7",
        "colab_type": "text"
      },
      "source": [
        "## Matrix indexing and concatenation\n",
        "Tensors can be indexed using the slicing operators, and concatenated using the function cat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REcpB5fXdXmk",
        "outputId": "ad7f2a92-d6fa-4466-81f1-43788b90cdca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# Dot product of matrices doesnt exist for 2D Tensors\n",
        "A = torch.tensor([[1, 2, 3],[1, 2, 3]])\n",
        "B = torch.tensor([[5, 5],[6, 6],[7, 7]])\n",
        "#WE RECOMMEND ALWAYS USE 2D TENSORS, EVEN IF IT IS A VECTOR\n",
        "#dotProduct = A.dot(B) it doesnt work, it is defined for 1D tensors only. \n",
        "#SOME OPERATORS ARE DEFINED FOR 1D TENSORS ONLY, AND SOME OF THEM ARE DEFINED FOR 2D TENSORS\n",
        "\n",
        "#Create a matrix C, concatenating the matrix A along its rows\n",
        "C = torch.cat((A, A), 0)\n",
        "#Create a matrix D, concatenating the matrix A along its columns\n",
        "D = torch.cat((B, B), 1)\n",
        "print(\"C concatenado, \", C)\n",
        "print(\"B concatenado \", B)\n",
        "\n",
        "\n",
        "#Put ceros in column 1 and 2, from row 0\n",
        "C[0, 1:3] = 0;\n",
        "\n",
        "\n",
        "\n",
        "#Put ones in column 1 and all the rows\n",
        "D[:, 1] = 1\n",
        "print(D)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C concatenado,  tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "B concatenado  tensor([[5, 5],\n",
            "        [6, 6],\n",
            "        [7, 7]])\n",
            "tensor([[5, 1, 5, 5],\n",
            "        [6, 1, 6, 6],\n",
            "        [7, 1, 7, 7]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LWlnjvm5dXmn"
      },
      "source": [
        "## Matrix flatenning\n",
        "Matrix flatenning refers to create a column or row vector with all the elements within a matrix.\n",
        "See more at http://deeplizard.com/learn/video/fCVuiW9AFzY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KnmH1QerdXmo",
        "outputId": "764f51ef-5c16-4f3b-cd2f-6c85b0d3c671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "A = torch.tensor([[1, 2, 3],[6, 24, 32]])\n",
        "print(\"A original \", A)\n",
        "\n",
        "Af= A.reshape(A.shape[0] * A.shape[1], -1)\n",
        "print(\"A reshaped \", Af)\n",
        "\n",
        "#if we want to remove one dimension of the tensor, we can use squeeze, transforming from 2D to 1D tensor\n",
        "Afs = Af.squeeze()\n",
        "print(\"\"Afs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A original  tensor([[ 1,  2,  3],\n",
            "        [ 6, 24, 32]])\n",
            "A reshaped  tensor([[ 1],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        [ 6],\n",
            "        [24],\n",
            "        [32]])\n",
            "tensor([ 1,  2,  3,  6, 24, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2LuIU2gKc54q"
      },
      "source": [
        "## Matrix multiplication\n",
        "\n",
        "Product of two matrices $A\\in\\mathbb{R}^{m\\times n}$ and $B\\in\\mathbb{R}^{n\\times p}$ is given by:\n",
        "$$\n",
        "C=A\\,B=\\begin{bmatrix}- & \\vec{a}_{1,:}^{T} & -\\\\\n",
        "- & \\vec{a}_{2,:}^{T} & -\\\\\n",
        " & \\vdots\\\\\n",
        "- & \\vec{a}_{m,:}^{T} & -\n",
        "\\end{bmatrix}\\,\\begin{bmatrix}| & | & \\ldots & |\\\\\n",
        "\\vec{b}_{1,:} & \\vec{b}_{2,:} & \\ldots & \\vec{b}_{p,:}\\\\\n",
        "| & | & \\ldots & |\n",
        "\\end{bmatrix}=\\begin{bmatrix}\\vec{a}_{1,:}^{T}\\vec{b}_{1,:} & \\vec{a}_{1,:}^{T}\\vec{b}_{2,:} & \\cdots & \\vec{a}_{1,:}^{T}\\vec{b}_{p,:}\\\\\n",
        "\\vec{a}_{2,:}^{T}\\vec{b}_{1,:} & \\vec{a}_{2,:}^{T}\\vec{b}_{2,:} & \\cdots & \\vec{a}_{2,:}^{T}\\vec{b}_{p,:}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "\\vec{a}_{m,:}^{T}\\vec{b}_{1,:} & \\vec{a'}_{m}^{T}\\vec{b}_{2,:} & \\cdots & \\vec{a}_{m,:}^{T}\\vec{b}_{p,:}\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ABhKozT0vwW_",
        "outputId": "dc45f089-090c-4d30-d9e6-27fb82ae2a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "#extract one row\n",
        "print(\"matriz A\")\n",
        "print(A)\n",
        "print(\"matriz B\")\n",
        "print(B)\n",
        "\n",
        "a = A[0, :]\n",
        "# extract one column\n",
        "b = B[:, 0]\n",
        "#calculate dot product\n",
        "c = torch.dot(a,b)\n",
        "print(\"Dot product\")\n",
        "print(c)\n",
        "\n",
        "\n",
        "print(\"C = A B\")\n",
        "C = A.mm(B)\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matriz A\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 6, 24, 32]])\n",
            "matriz B\n",
            "tensor([[5, 5],\n",
            "        [6, 6],\n",
            "        [7, 7]])\n",
            "Dot product\n",
            "tensor(38)\n",
            "C = A B\n",
            "tensor([[ 38,  38],\n",
            "        [398, 398]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W26r-trbc540"
      },
      "source": [
        "## Element wise multiplication of matrices\n",
        "\n",
        "The element wise multiplication of matrices A and B result in a matrix C with same dimensions, and multiplies its entries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3m3ZPiEhkkmm",
        "outputId": "0580cb90-5f8d-4431-f5e0-c3c6d72e6d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "A = torch.tensor([[1, 2], [3, 0]])\n",
        "B = torch.tensor([[5, 6], [7, 0]])\n",
        "C = A * B\n",
        "print(C)\n",
        "#Element wise multiplication allows us to calculate dot product of matrices\n",
        "dotProduct = C.sum()\n",
        "\n",
        "print(\"Dot product: \", dotProduct)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 5, 12],\n",
            "        [21,  0]])\n",
            "Dot product:  tensor(38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF3j5QP6JXHN",
        "colab_type": "text"
      },
      "source": [
        "## External product of vectors\n",
        "For two vectors\n",
        "\n",
        "$\\overrightarrow{x}\\in\\mathbb{R}^{m\\times1}$, $\\overrightarrow{y}\\in\\mathbb{R}^{1\\times n} $ is given by: \n",
        "$$\n",
        "\\vec{x}\\:\\vec{y}^{T}\\in\\mathbb{R}^{m\\times n}=\\begin{bmatrix}x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "\\vdots\\\\\n",
        "x_{m}\n",
        "\\end{bmatrix}\\begin{bmatrix}y_{1} & y_{2} & \\cdots & y_{n}\\end{bmatrix}=\\begin{bmatrix}x_{1}y_{1} & x_{1}y_{2} & \\cdots & x_{1}y_{n}\\\\\n",
        "x_{2}y_{1} & x_{2}y_{2} & \\cdots & x_{2}y_{n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "x_{m}y_{1} & x_{m}y_{2} & \\cdots & x_{m}y_{n}\n",
        "\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJvNAv-JXHN",
        "colab_type": "code",
        "outputId": "4d914b0c-ffeb-41ad-d735-3d40d29c0784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#1x3 vector\n",
        "a = torch.tensor([[1, 2, 3]])\n",
        "#3x1 vector\n",
        "b = torch.tensor([[5], [6], [7]])\n",
        "#3x3 matrix\n",
        "externalProduct = b.mm(a)\n",
        "\n",
        "print(externalProduct)\n",
        "\n",
        "#what happens if a elements are equal to b?\n",
        "b = torch.tensor([[1], [2], [3]])\n",
        "externalProduct2 = b.mm(a)\n",
        "\n",
        "print(\"External product of the same vector\", externalProduct2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 5, 10, 15],\n",
            "        [ 6, 12, 18],\n",
            "        [ 7, 14, 21]])\n",
            "External product of the same vector tensor([[1, 2, 3],\n",
            "        [2, 4, 6],\n",
            "        [3, 6, 9]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBsZJg1vNrTu",
        "colab_type": "text"
      },
      "source": [
        "# Matrix-vector product\n",
        "$$\n",
        "\\overrightarrow{y}=A\\,\\overrightarrow{x}=\\begin{bmatrix}| & | & \\ldots & |\\\\\n",
        "\\vec{a}_{:,1} & \\vec{a}_{:,2} & \\ldots & \\vec{a}_{:,n}\\\\\n",
        "| & | & \\ldots & |\n",
        "\\end{bmatrix}\\,\\begin{bmatrix}x_{1}\\\\\n",
        "x_{2}\\\\\n",
        "\\vdots\\\\\n",
        "x_{n}\n",
        "\\end{bmatrix}=\\left[\\vec{a}_{:,1}\\right]x_{1}+\\left[\\vec{a}_{:,2}\\right]x_{2}+\\ldots+\\left[\\vec{a}_{:,n}\\right]x_{n}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDkSaJ1eObsl",
        "colab_type": "code",
        "outputId": "ee7abe0f-4d87-4a6d-f1ef-0e25d0f0cb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "A = torch.tensor([[2, 3], [4, 5]])\n",
        "x = torch.tensor([[2], [3]])\n",
        "#linear combination of A's columns\n",
        "#y = 2 [[2], [4]] + 3 [[3], [5]] = [[13], [23]]\n",
        "y = A.mm(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[13],\n",
            "        [23]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r57RI2mJXHR",
        "colab_type": "text"
      },
      "source": [
        "## Symmetric Matrices\n",
        "A squared matrix is symmetric if  $A=A^{T}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isg_C_afJXHR",
        "colab_type": "code",
        "outputId": "61e83731-e7a3-4bbd-e238-5b395f01cff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "def isSymmetric(A):\n",
        "    \"\"\"\n",
        "    A: input matrix\n",
        "    \"\"\"\n",
        "    At = A.transpose(0, 1)\n",
        "    return (torch.all(A.eq(At)))\n",
        "        \n",
        "#check wether the external product of the same vector is symmetric\n",
        "B = torch.tensor([[1, 5, 3], [2, 7, 9], [2, 1, 4]])\n",
        "Bt = B.transpose(0, 1)\n",
        "\n",
        "Sym1 = B.mm(Bt)\n",
        "print(\"Sym1 \")\n",
        "print(Sym1)\n",
        "print(isSymmetric(Sym1))\n",
        "\n",
        "C = torch.tensor([[3, 4, 4], [5, 6, 7], [4, 5, 6]])\n",
        "Ct = C.transpose(0, 1)\n",
        "Sym2 = C + Ct\n",
        "print(\"Sym2\")\n",
        "print(Sym2)\n",
        "print(isSymmetric(Sym2))\n",
        "\n",
        "\n",
        "\n",
        "isSymmetric(externalProduct2)   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sym1 \n",
            "tensor([[ 35,  64,  19],\n",
            "        [ 64, 134,  47],\n",
            "        [ 19,  47,  21]])\n",
            "tensor(1, dtype=torch.uint8)\n",
            "Sym2\n",
            "tensor([[ 6,  9,  8],\n",
            "        [ 9, 12, 12],\n",
            "        [ 8, 12, 12]])\n",
            "tensor(1, dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1, dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kefoahanVdwc",
        "colab_type": "text"
      },
      "source": [
        "For any squared non symmetric matrix $A\\mathbb{\\in R}^{n\\times n}$, we can build a symmetric matrix $A+A^{T}$ \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFuq3Pn0WUyJ",
        "colab_type": "code",
        "outputId": "f52d4e4e-a13d-4489-a42f-2464aa763c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "AnonSym = torch.tensor([[3, 7, 5], [7, 3, 4], [3, 2, 1]])\n",
        "print(AnonSym)\n",
        "Bsym = AnonSym + AnonSym.transpose(0, 1)\n",
        "print(Bsym)\n",
        "#check if it is symmetric\n",
        "isSymmetric()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3, 7, 5],\n",
            "        [7, 3, 4],\n",
            "        [3, 2, 1]])\n",
            "tensor([[ 6, 14,  8],\n",
            "        [14,  6,  6],\n",
            "        [ 8,  6,  2]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-p3g_SuJXHV",
        "colab_type": "text"
      },
      "source": [
        "## Matrix Rank\n",
        "Lineally dependent vectors  $\\left\\{ \\vec{x}_{1},\\vec{x}_{2},\\ldots,\\vec{x}_{n}\\right\\} \\subset\\mathbb{R}^{m}$\n",
        "if at least one vector can be written as a lineal combination of any of the rest: \n",
        "$$\n",
        "\\vec{x}_{j}=\\sum_{i=1}^{n-1}\\alpha_{i}\\vec{x}_{i}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qzem_a_JXHW",
        "colab_type": "code",
        "outputId": "cb9d5acb-438e-410a-e1c4-c84bf0958c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Rank of 10x10 identity matrix\n",
        "Identity = torch.eye(10)\n",
        "MatrixRank = np.linalg.matrix_rank(Identity.numpy())\n",
        "print(\"Rango de matriz identidad\")\n",
        "print(MatrixRank)\n",
        "#squared matrix with linear combination of rows, rank inferior than number of rows and columns\n",
        "A = torch.tensor([[4.0, -5.0], [8.0, -10.0]])\n",
        "MatrixRank = np.linalg.matrix_rank(A.numpy())\n",
        "print(\"Matrix A rank \", MatrixRank)\n",
        "#squared matrix with independent rows\n",
        "B = torch.tensor([[4.0, -5.0], [-2.0, 3.0]])\n",
        "MatrixRank = np.linalg.matrix_rank(B.numpy())\n",
        "print(\"Matrix B rank \", MatrixRank)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rango de matriz identidad\n",
            "10\n",
            "Matrix A rank  1\n",
            "Matrix B rank  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQo296HIJXHb",
        "colab_type": "text"
      },
      "source": [
        "## Inverse Matrix\n",
        "The inverse matrix satisfies $A^{-1}A=I=A\\,A^{-1}$ and also\n",
        "$\\left(A\\,B\\right)^{-1}=B^{-1}A^{-1}.$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4a5VM9DJXHd",
        "colab_type": "code",
        "outputId": "428d17ea-9dab-48e1-ba35-0f282bdc3dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "def checkInverseMatrixMultiplicationProperty(A, B):\n",
        "    \"\"\"\n",
        "    Checks matrix inverse multiplication property\n",
        "    A: squared, full rank, non singular, invertible matrix\n",
        "    B: squared, full rank, non singular, invertible matrix\n",
        "    \"\"\"\n",
        "    Ainv = A.inverse()\n",
        "    Binv = B.inverse()\n",
        "    C = A.mm(B)\n",
        "    CinvLeft = C.inverse()\n",
        "    \n",
        "    \n",
        "    multRight = Binv.mm(Ainv)\n",
        "    \n",
        "    #for floating matrices, sum of difference must be small \n",
        "    return (CinvLeft - multRight).sum() < 0.1e-5\n",
        "\n",
        "\n",
        "C = torch.tensor([[3.0, 5.0], [1.0, 7.0]])\n",
        "#lets verify the rank\n",
        "rankC = np.linalg.matrix_rank(C.numpy())\n",
        "print(\"Rango de C \", rankC)\n",
        "\n",
        "\n",
        "print (\"Property check: \", checkInverseMatrixMultiplicationProperty(B,C))\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rango de C  2\n",
            "Property check:  tensor(1, dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax5ISHYHJXHj",
        "colab_type": "text"
      },
      "source": [
        "## Pseudo inverse matrix\n",
        "The following is a very important property:\n",
        "1. $$ \\left(A^{T}A\\right)^{-1}A^{T}\\approx A^{+} $$\n",
        "\n",
        "2. \n",
        "$$\\left(A^{T}A\\right)^{+}A^{T}=A^{+}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w73iO8yaJXHk",
        "colab_type": "code",
        "outputId": "996bbe7b-e133-4e64-a9c7-1ba95487dacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "def checkPseudoInverseProperty1(A):\n",
        "    \"\"\"\n",
        "    Check pseudo inverse property 1\n",
        "    \"\"\"\n",
        "    Apinv = torch.tensor(np.linalg.pinv(A.numpy()))\n",
        "    At = A.transpose(0, 1)\n",
        "    left = At.mm(A).inverse().mm(At)\n",
        "    \n",
        "    \n",
        "    return (left - Apinv).sum() < 0.1e-5\n",
        "  \n",
        "def checkPseudoInverseProperty2(A):\n",
        "    \"\"\"\n",
        "    Check pseudo inverse property 2\n",
        "    Pytorch pinv implementation is not recommended for non invertible matrices\n",
        "    \"\"\"\n",
        "    \n",
        "    #Apinv = A.pinverse()\n",
        "    Apinv = torch.tensor(np.linalg.pinv(A.numpy()))\n",
        "    print(Apinv)\n",
        "    \n",
        "    At = A.transpose(0, 1)\n",
        "    left = torch.tensor(np.linalg.pinv(At.mm(A).numpy())).mm(At)\n",
        "  \n",
        "    \n",
        "    return (left - Apinv).sum() < 0.1e-5\n",
        "    \n",
        "    \n",
        "#pseudo inverse of invertible matrix  \n",
        "print(\"C matrix\")\n",
        "print(C)\n",
        "\n",
        "\n",
        "Cinv = C.inverse()\n",
        "Cpinv = C.pinverse()\n",
        "print(\"Inverted C \", Cinv)\n",
        "print(\"Pseudo inverted C\", Cpinv)\n",
        "\n",
        "I = C.mm(Cpinv)\n",
        "print(\"C * Cpinv \", I)\n",
        "#check pseudo inverse property for invertible matrix\n",
        "checkPseudoInverseProperty1(C)\n",
        "\n",
        "#pseudo inverse of non invertible square matrix\n",
        "D = torch.tensor([[3.0, 5.0], [6.0, 10.0]])\n",
        "Dpinv = torch.tensor(np.linalg.pinv(D.numpy()))\n",
        "\n",
        "print(\"Dpinv\")\n",
        "print(Dpinv)\n",
        "print(\"Check second property \")\n",
        "print(checkPseudoInverseProperty2(D))\n",
        "\n",
        "\n",
        "D.inverse()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#the inverse property is not satisfied\n",
        "I = D.mm(Dpinv)\n",
        "print(\"Dinv * D \", I)\n",
        "print(\"PINV \", Dpinv)\n",
        "#check pseudo inverse property\n",
        "#print(\"Satisfies pseudo inverse property 1: \", checkPseudoInverseProperty1(D))\n",
        "result = checkPseudoInverseProperty1(D)\n",
        "print(\"Satisfies pseudo inverse property 2: \", result)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C matrix\n",
            "tensor([[3., 5.],\n",
            "        [1., 7.]])\n",
            "Inverted C  tensor([[ 0.4375, -0.3125],\n",
            "        [-0.0625,  0.1875]])\n",
            "Pseudo inverted C tensor([[ 0.4375, -0.3125],\n",
            "        [-0.0625,  0.1875]])\n",
            "C * Cpinv  tensor([[1.0000e+00, 1.7881e-07],\n",
            "        [5.9605e-08, 1.0000e+00]])\n",
            "Dpinv\n",
            "tensor([[0.0176, 0.0353],\n",
            "        [0.0294, 0.0588]])\n",
            "Check second property \n",
            "tensor([[0.0176, 0.0353],\n",
            "        [0.0294, 0.0588]])\n",
            "tensor(1, dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a1a9f6f3aefd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Lapack Error getrf : U(2,2) is 0, U is singular at /pytorch/aten/src/TH/generic/THTensorLapack.cpp:468"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fjSUptw8Pf8",
        "colab_type": "text"
      },
      "source": [
        "## Vector projection\n",
        "Projection of $\\vec{y}\\in\\mathbb{R}^{n}$ over the vectors generated by the set of base vectors $\\left\\{ \\vec{a}_{1},\\vec{a}_{2},\\ldots,\\vec{a}_{m}\\right\\} \\qquad\\vec{a}_{i}\\in\\mathbb{R}^{n}$\n",
        "$$\n",
        "\\textrm{proy}\\left(\\vec{y};\\left\\{ \\vec{a}_{1},\\vec{a}_{2},\\ldots,\\vec{a}_{m}\\right\\} \\right)=\\textrm{argmin}_{\\vec{v}\\in\\textrm{espacioGenerado}\\left(\\left\\{ \\vec{a}_{1},\\vec{a}_{2},\\ldots,\\vec{a}_{m}\\right\\} \\right)}\\left\\Vert \\vec{v}-\\vec{y}\\right\\Vert _{2}.\n",
        "$$\n",
        "with the generated space given by the column space:\n",
        "$$\n",
        "\\mathcal{C}\\left(A\\right)=\\left\\{ \\vec{v}\\in\\mathbb{R}^{n}:\\vec{v}=A\\,\\vec{x},\\;\\vec{x}\\in\\mathbb{R}^{m},\\:A\\in\\mathbb{R}^{n\\times m}\\right\\} \n",
        "$$\n",
        "\n",
        "with the optimal solution given by:\n",
        "\n",
        "$$\n",
        "\\textrm{proy}\\left(\\vec{y};A\\right)=A\\,\\left(A^{T}A\\right)^{-1}A^{T}\\vec{y}\n",
        "$$\n",
        "\n",
        "\n",
        "### Example 1: Same number of base vectors $m$ and vector dimensionality $n$, lineally independent base vectors\n",
        "Given the independent base vectors  $$\\vec{a}_{1}=\\begin{bmatrix}0.5\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}, \\vec{a}_{2}=\\begin{bmatrix}0\\\\\n",
        "0.25\\\\\n",
        "0\n",
        "\\end{bmatrix},  \\vec{a}_{3}=\\begin{bmatrix}0\\\\\n",
        "0\\\\\n",
        "2\n",
        "\\end{bmatrix}$$\n",
        "Calculate the projection vector  $\\textrm{proy}\\left(\\vec{y};A\\right)\\in\\mathbb{R}^{3}$ with $ \\vec{y}=\\begin{bmatrix}1\\\\\n",
        "2\\\\\n",
        "3\n",
        "\\end{bmatrix}$ and evaluate its error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gZXxBIMEwZe",
        "colab_type": "text"
      },
      "source": [
        "### Example 2: Same number of base vectors $m$ and vector dimensionality $n$, lineally dependent base vectors\n",
        "$$\n",
        "\\vec{a}_{1}=\\begin{bmatrix}0.5\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}, \\vec{a}_{2}=\\begin{bmatrix}1\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}  \\vec{a}_{3}=\\begin{bmatrix}0\\\\\n",
        "1\\\\\n",
        "2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "Calculate the projection vector  $\\textrm{proy}\\left(\\vec{y};A\\right)\\in\\mathbb{R}^{3}$ with $ \\vec{y}=\\begin{bmatrix}1\\\\\n",
        "2\\\\\n",
        "3\n",
        "\\end{bmatrix}$ and evaluate its error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEOxwbMxIutm",
        "colab_type": "text"
      },
      "source": [
        "### Example 3: More base vectors $m$ than vector dimensionality $n$\n",
        "With the following base vectors $$\\vec{a}_{1}=\\begin{bmatrix}0.5\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}, \\vec{a}_{2}=\\begin{bmatrix}0\\\\\n",
        "0.25\\\\\n",
        "3\n",
        "\\end{bmatrix}, \\vec{a}_{3}=\\begin{bmatrix}0\\\\\n",
        "0\\\\\n",
        "2\n",
        "\\end{bmatrix}, \\vec{a}_{3}=\\begin{bmatrix}23\\\\\n",
        "5\\\\\n",
        "3\n",
        "\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbdzzraVNeLb",
        "colab_type": "text"
      },
      "source": [
        "### Example 4: Less base vectors $m$ than vector dimensionality $n$\n",
        "Given the following base vectors:\n",
        "\n",
        "$$ \\vec{a}_{1}=\\begin{bmatrix}5\\\\\n",
        "7\\\\\n",
        "21\n",
        "\\end{bmatrix},  \\vec{a}_{2}=\\begin{bmatrix}0\\\\\n",
        "13\\\\\n",
        "9\n",
        "\\end{bmatrix}$$"
      ]
    }
  ]
}