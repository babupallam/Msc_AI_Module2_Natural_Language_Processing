{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM5rX+hWhDRMZISWcR2/Sn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babupallam/Msc_AI_Module2_Natural_Language_Processing/blob/main/L05-Analyzing%20Sentence%20Structure/Note_5_Research_Observations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Parsing Sentences with Context-Free Grammar (CFG)**\n",
        "  - Write a CFG that can parse simple sentences involving nouns, verbs, and prepositions. Parse the sentence \"The cat sat on the mat\" and print the resulting parse tree.\n"
      ],
      "metadata": {
        "id": "O7qVKLKo8igb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules from the NLTK library.\n",
        "import nltk\n",
        "from nltk import CFG, ChartParser\n",
        "\n",
        "# Define the context-free grammar (CFG) for a simple English-like language.\n",
        "# The grammar specifies how sentences (S), noun phrases (NP), verb phrases (VP), and prepositional phrases (PP) are constructed.\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> Det N | Det N PP\n",
        "  VP -> V NP | V PP\n",
        "  PP -> P NP\n",
        "  Det -> 'The' | 'a' | 'the'\n",
        "  N -> 'cat' | 'mat'\n",
        "  V -> 'sat'\n",
        "  P -> 'on'\n",
        "\"\"\")\n",
        "\n",
        "# Tokenize the sentence by splitting it into individual words, ensuring proper capitalization.\n",
        "sentence = \"The cat sat on the mat\".split()\n",
        "\n",
        "# Create a ChartParser instance using the defined CFG.\n",
        "parser = ChartParser(grammar)\n",
        "\n",
        "# Parse the sentence using the chart parser and print the resulting parse tree(s).\n",
        "for tree in parser.parse(sentence):\n",
        "    print(tree)  # Print each possible parse tree.\n",
        "    tree.pretty_print()  # Pretty-print each parse tree.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1W-cJBJ95HC",
        "outputId": "2ba58f87-9980-4bf4-86d1-412fe41ec062"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Det The) (N cat))\n",
            "  (VP (V sat) (PP (P on) (NP (Det the) (N mat)))))\n",
            "             S                     \n",
            "      _______|_______               \n",
            "     |               VP            \n",
            "     |        _______|___           \n",
            "     |       |           PP        \n",
            "     |       |    _______|___       \n",
            "     NP      |   |           NP    \n",
            "  ___|___    |   |        ___|___   \n",
            "Det      N   V   P      Det      N \n",
            " |       |   |   |       |       |  \n",
            "The     cat sat  on     the     mat\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 2. **Ambiguity in Parsing**\n",
        "  - Write a CFG that can parse the ambiguous sentence \"I saw the man with the telescope\".\n",
        "  - Use NLTK to generate all possible parse trees and discuss the ambiguity.\n",
        "\n"
      ],
      "metadata": {
        "id": "yIzrzHV48iiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grammar_ambiguous = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Det N | Det N PP | 'I'\n",
        "    VP -> V NP | VP PP\n",
        "    PP -> P NP\n",
        "    Det -> 'the'\n",
        "    N -> 'man' | 'telescope'\n",
        "    V -> 'saw'\n",
        "    P -> 'with'\n",
        "\"\"\")\n",
        "\n",
        "# The ambiguous sentence is tokenized (split into words) and stored as a list of tokens.\n",
        "ambiguous_sentence = \"I saw the man with the telescope\".split()\n",
        "\n",
        "# Assuming 'grammar_ambiguous' is a CFG that is defined elsewhere, we use it to create a ChartParser.\n",
        "parser_ambiguous = ChartParser(grammar_ambiguous)\n",
        "\n",
        "# Parse the ambiguous sentence using the ChartParser and print the resulting parse tree(s).\n",
        "for tree in parser_ambiguous.parse(ambiguous_sentence):\n",
        "    print(tree)  # Each possible parse tree is printed, representing a different interpretation.\n",
        "    tree.pretty_print()  # Pretty-print each parse tree for better readability.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZWFG8dF97mV",
        "outputId": "1cb314ad-4ccf-47c0-d6e3-1f4fe8f2e42e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (VP (V saw) (NP (Det the) (N man)))\n",
            "    (PP (P with) (NP (Det the) (N telescope)))))\n",
            "     S                                    \n",
            "  ___|___________                          \n",
            " |               VP                       \n",
            " |        _______|________                 \n",
            " |       VP               PP              \n",
            " |    ___|___         ____|___             \n",
            " |   |       NP      |        NP          \n",
            " |   |    ___|___    |     ___|______      \n",
            " NP  V  Det      N   P   Det         N    \n",
            " |   |   |       |   |    |          |     \n",
            " I  saw the     man with the     telescope\n",
            "\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))))\n",
            "     S                                \n",
            "  ___|_______                          \n",
            " |           VP                       \n",
            " |    _______|___                      \n",
            " |   |           NP                   \n",
            " |   |    _______|____                 \n",
            " |   |   |   |        PP              \n",
            " |   |   |   |    ____|___             \n",
            " |   |   |   |   |        NP          \n",
            " |   |   |   |   |     ___|______      \n",
            " NP  V  Det  N   P   Det         N    \n",
            " |   |   |   |   |    |          |     \n",
            " I  saw the man with the     telescope\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Dependency Parsing**\n",
        "  - Define a dependency grammar for the sentence \"The dog chased the cat\" and use NLTK's ProjectiveDependencyParser to parse the sentence.\n"
      ],
      "metadata": {
        "id": "N6MRU0Ao8il7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dependency_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
        "  'chased' -> 'dog' | 'cat'\n",
        "  'dog' -> 'The'\n",
        "  'cat' -> 'the'\n",
        "\"\"\")\n",
        "\n",
        "# Import necessary modules from NLTK (we assume ProjectiveDependencyParser and dependency_grammar are already imported).\n",
        "dep_parser = nltk.ProjectiveDependencyParser(dependency_grammar)\n",
        "\n",
        "# The sentence to be parsed, split into individual words (tokens).\n",
        "sentence_dep = \"The dog chased the cat\".split()\n",
        "\n",
        "# Parse the sentence using the dependency parser.\n",
        "for tree in dep_parser.parse(sentence_dep):\n",
        "    print(tree)               # Print the tree in textual form.\n",
        "    tree.pretty_print()        # Pretty-print the tree in a visual format (ascii art).\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMJX1yCz9_NH",
        "outputId": "13fe036f-a7b5-4089-fb6a-ac0f2ae1ca01"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(chased (dog The) (cat the))\n",
            "    chased    \n",
            "  ____|_____   \n",
            "dog        cat\n",
            " |          |  \n",
            "The        the\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **CFG Development and Parsing Longer Sentences**\n",
        "  - Create a CFG that includes recursive rules for constructing longer sentences.\n",
        "  - Parse the sentence \"The small cat chased the big dog with a collar\".\n"
      ],
      "metadata": {
        "id": "whpFcmxE8iox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grammar_recursive = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> Det Adj N | Det N PP\n",
        "  VP -> V NP | VP PP\n",
        "  PP -> P NP\n",
        "  Det -> 'The' | 'a'|'the'\n",
        "  Adj -> 'small' | 'big'\n",
        "  N -> 'cat' | 'dog' | 'collar'\n",
        "  V -> 'chased'\n",
        "  P -> 'with'\n",
        "\"\"\")\n",
        "\n",
        "# Tokenize the longer sentence \"The small cat chased the big dog with a collar\" into individual words.\n",
        "long_sentence = \"The small cat chased the big dog with a collar\".split()\n",
        "\n",
        "# Assuming 'grammar_recursive' is a CFG that allows recursive structures (like nested noun phrases or prepositional phrases),\n",
        "# create a ChartParser instance using this recursive grammar.\n",
        "parser_recursive = ChartParser(grammar_recursive)\n",
        "\n",
        "# Parse the sentence using the recursive chart parser.\n",
        "# The parser will explore all possible parse trees that conform to the recursive grammar for the given sentence.\n",
        "for tree in parser_recursive.parse(long_sentence):\n",
        "    # Print each parsed tree in a structured textual format.\n",
        "    print(tree)\n",
        "\n",
        "    # Display the parse tree in an ASCII-style tree structure for better visual understanding of the parse.\n",
        "    tree.pretty_print()\n",
        "\n"
      ],
      "metadata": {
        "id": "UMo-uqa9-Biu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Evaluating Grammar on Treebank Data**\n",
        "  - Load the Penn Treebank sample from NLTK.\n",
        "  - Extract a few sentences and compare how well a custom CFG matches the syntactic structure of the Penn Treebank.\n"
      ],
      "metadata": {
        "id": "tdxi3Dob8ir4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.corpus import treebank\n",
        "nltk.download('treebank')\n",
        "\n",
        "treebank_sentence = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
        "print(treebank_sentence)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9nudlz1-Dt2",
        "outputId": "dd5e5183-8e96-4494-e53e-b1427285d892"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP-SBJ\n",
            "    (NP (NNP Pierre) (NNP Vinken))\n",
            "    (, ,)\n",
            "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
            "    (, ,))\n",
            "  (VP\n",
            "    (MD will)\n",
            "    (VP\n",
            "      (VB join)\n",
            "      (NP (DT the) (NN board))\n",
            "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
            "      (NP-TMP (NNP Nov.) (CD 29))))\n",
            "  (. .))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. **Exploring Ambiguity with Probabilistic Parsing**\n",
        "  - Create a probabilistic CFG (PCFG) that assigns different probabilities to ambiguous constructions.\n",
        "  - Parse the sentence \"I saw the man with the telescope\" and observe which parse tree has the highest probability.\n"
      ],
      "metadata": {
        "id": "NqEgiZYW8iug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar_pcfg = nltk.PCFG.fromstring(\"\"\"\n",
        "  S -> NP VP [1.0]\n",
        "  NP -> Det N [0.4] | Det N PP [0.4] | 'I' [0.2]\n",
        "  VP -> V NP [0.7] | VP PP [0.3]\n",
        "  PP -> P NP [1.0]\n",
        "  Det -> 'the' [1.0]\n",
        "  N -> 'man' [0.5] | 'telescope' [0.5]\n",
        "  V -> 'saw' [1.0]\n",
        "  P -> 'with' [1.0]\n",
        "\"\"\")\n",
        "\n",
        "# Initialize a Viterbi parser using a probabilistic context-free grammar (PCFG).\n",
        "viterbi_parser = nltk.ViterbiParser(grammar_pcfg)\n",
        "\n",
        "# Parse the ambiguous sentence using the Viterbi parser.\n",
        "# The Viterbi algorithm will determine the most probable parse tree for the sentence based on the grammar's probabilities.\n",
        "for tree in viterbi_parser.parse(ambiguous_sentence):\n",
        "    # Print the most probable parse tree (based on production rule probabilities).\n",
        "    print(tree)\n",
        "    tree.pretty_print()  # Pretty-print the parse tree for better readability."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6FS3M1x-GFO",
        "outputId": "f627dfd8-b99e-4687-d926-944328e4a391"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP\n",
            "      (Det the)\n",
            "      (N man)\n",
            "      (PP (P with) (NP (Det the) (N telescope)))))) (p=0.0056)\n",
            "     S                                \n",
            "  ___|_______                          \n",
            " |           VP                       \n",
            " |    _______|___                      \n",
            " |   |           NP                   \n",
            " |   |    _______|____                 \n",
            " |   |   |   |        PP              \n",
            " |   |   |   |    ____|___             \n",
            " |   |   |   |   |        NP          \n",
            " |   |   |   |   |     ___|______      \n",
            " NP  V  Det  N   P   Det         N    \n",
            " |   |   |   |   |    |          |     \n",
            " I  saw the man with the     telescope\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. **Recursive Parsing of Nested Sentences**\n",
        "  - Write a CFG that can handle recursive sentences such as \"The cat that the dog chased sat on the mat\".\n",
        "  - Parse the sentence and display the resulting parse tree.\n"
      ],
      "metadata": {
        "id": "l5RWtq0-8ixV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grammar_nested = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> Det N | Det N RelClause\n",
        "  VP -> V NP | V PP\n",
        "  PP -> P NP\n",
        "  RelClause -> RelPron VP\n",
        "  Det -> 'The' | 'the'\n",
        "  N -> 'cat' | 'dog' | 'mat'\n",
        "  V -> 'chased' | 'sat'\n",
        "  P -> 'on'\n",
        "  RelPron -> 'that'\n",
        "\"\"\")\n",
        "\n",
        "# Tokenize the nested sentence \"The cat that the dog chased sat on the mat\" into individual words (tokens).\n",
        "nested_sentence = \"The cat that the dog chased sat on the mat\".split()\n",
        "\n",
        "# Assuming 'grammar_nested' is a CFG that supports nested clauses (e.g., relative clauses like \"that the dog chased\"),\n",
        "# create a ChartParser instance using this nested grammar.\n",
        "parser_nested = ChartParser(grammar_nested)\n",
        "\n",
        "# Parse the sentence using the chart parser designed for nested structures.\n",
        "# The parser will generate all valid parse trees that conform to the grammar for this complex sentence.\n",
        "for tree in parser_nested.parse(nested_sentence):\n",
        "    # Print the parsed tree in a structured textual format.\n",
        "    print(tree)\n",
        "\n",
        "    # Display the parse tree in an ASCII-style tree structure for clearer visualization of the nested syntax.\n",
        "    tree.pretty_print()\n"
      ],
      "metadata": {
        "id": "RZQZzlH6-ISK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. **Parsing Coordinated Phrases**\n",
        "  - Create a CFG to parse coordinated noun phrases such as \"The cat and the dog sat on the mat\".\n",
        "  - Generate the parse tree and discuss the structure of coordination.\n"
      ],
      "metadata": {
        "id": "0JfG7YKu8i0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grammar_coordination = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> NP Conj NP | Det N\n",
        "  VP -> V PP | V\n",
        "  PP -> P NP\n",
        "  Det -> 'The' | 'the'\n",
        "  N -> 'cat' | 'dog' | 'mat'\n",
        "  V -> 'sat'\n",
        "  P -> 'on'\n",
        "  Conj -> 'and'\n",
        "\"\"\")\n",
        "\n",
        "coordinated_sentence = \"The cat and the dog sat on the mat\".split()\n",
        "parser_coordination = ChartParser(grammar_coordination)\n",
        "for tree in parser_coordination.parse(coordinated_sentence):\n",
        "  print(tree)\n",
        "  tree.pretty_print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTemWlD0-KZa",
        "outputId": "63da4aee-93a2-437d-a744-aa98184b9e23"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (NP (Det The) (N cat)) (Conj and) (NP (Det the) (N dog)))\n",
            "  (VP (V sat) (PP (P on) (NP (Det the) (N mat)))))\n",
            "                          S                         \n",
            "              ____________|___________               \n",
            "             |                        VP            \n",
            "             |                 _______|___           \n",
            "             NP               |           PP        \n",
            "      _______|________        |    _______|___       \n",
            "     NP      |        NP      |   |           NP    \n",
            "  ___|___    |     ___|___    |   |        ___|___   \n",
            "Det      N  Conj Det      N   V   P      Det      N \n",
            " |       |   |    |       |   |   |       |       |  \n",
            "The     cat and  the     dog sat  on     the     mat\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. **Analyzing Prepositional Phrase Attachment**\n",
        "  - Write a CFG that can handle prepositional phrase attachment ambiguity, such as \"The boy saw the girl with a telescope\".\n",
        "  - Generate all possible parse trees and analyze the different attachments.\n"
      ],
      "metadata": {
        "id": "IKJ9cUBy8i2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar_pp_attachment = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> Det N | Det N PP | 'The' N\n",
        "  VP -> V NP | VP PP\n",
        "  PP -> P NP\n",
        "  Det -> 'the' | 'a'\n",
        "  N -> 'boy' | 'girl' | 'telescope'\n",
        "  V -> 'saw'\n",
        "  P -> 'with'\n",
        "\"\"\")\n",
        "\n",
        "#The '#' symbol was part of a comment. CFG.fromstring() does not recognize comments.\n",
        "#Remove the comment or place it on a separate line that starts with '#'\n",
        "\n",
        "\n",
        "pp_attachment_sentence = \"The boy saw the girl with a telescope\".split()\n",
        "parser_pp_attachment = ChartParser(grammar_pp_attachment)\n",
        "for tree in parser_pp_attachment.parse(pp_attachment_sentence):\n",
        "  print(tree)\n",
        "  tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEG5LZ78-MZb",
        "outputId": "a0bc6f0e-101e-4fc8-fd16-ca9ca178219d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP The (N boy))\n",
            "  (VP\n",
            "    (VP (V saw) (NP (Det the) (N girl)))\n",
            "    (PP (P with) (NP (Det a) (N telescope)))))\n",
            "                 S                                 \n",
            "      ___________|_______                           \n",
            "     |                   VP                        \n",
            "     |            _______|_________                 \n",
            "     |           VP                PP              \n",
            "     |        ___|___          ____|___             \n",
            "     NP      |       NP       |        NP          \n",
            "  ___|___    |    ___|___     |     ___|______      \n",
            " |       N   V  Det      N    P   Det         N    \n",
            " |       |   |   |       |    |    |          |     \n",
            "The     boy saw the     girl with  a      telescope\n",
            "\n",
            "(S\n",
            "  (NP The (N boy))\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP (Det the) (N girl) (PP (P with) (NP (Det a) (N telescope))))))\n",
            "                 S                             \n",
            "      ___________|___                           \n",
            "     |               VP                        \n",
            "     |        _______|____                      \n",
            "     |       |            NP                   \n",
            "     |       |    ________|____                 \n",
            "     |       |   |   |         PP              \n",
            "     |       |   |   |     ____|___             \n",
            "     NP      |   |   |    |        NP          \n",
            "  ___|___    |   |   |    |     ___|______      \n",
            " |       N   V  Det  N    P   Det         N    \n",
            " |       |   |   |   |    |    |          |     \n",
            "The     boy saw the girl with  a      telescope\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. **Building a Simple Chunk Parser**\n",
        "  - Write a simple chunk grammar to identify noun phrases (NP) in a sentence.\n",
        "  - Use the RegexpParser in NLTK to extract all noun phrases from the sentence \"The quick brown fox jumps over the lazy dog\".\n"
      ],
      "metadata": {
        "id": "rIOqpdt18i6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk import RegexpParser, pos_tag, word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6TbplKB-VsY",
        "outputId": "cb6860d8-9787-42c7-cd77-164516cf85e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import RegexpParser, pos_tag, word_tokenize\n",
        "\n",
        "# Define a simple chunk grammar for noun phrases (NP). The pattern specifies:\n",
        "# - An optional determiner (<DT>),\n",
        "# - Followed by zero or more adjectives (<JJ>*),\n",
        "# - And a mandatory noun (<NN>).\n",
        "chunk_grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "\n",
        "# Create a chunk parser using the regular expression-based chunk grammar.\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Define a sentence for chunking.\n",
        "chunk_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Tokenize the sentence into words and assign part-of-speech (POS) tags.\n",
        "# The pos_tag function tags each word with its part-of-speech (like <DT>, <JJ>, <NN>, etc.).\n",
        "chunk_pos_tags = pos_tag(word_tokenize(chunk_sentence))\n",
        "\n",
        "# Parse the POS-tagged sentence to identify chunks (based on the chunk grammar).\n",
        "chunk_tree = chunk_parser.parse(chunk_pos_tags)\n",
        "\n",
        "# Print the resulting chunk tree structure, which identifies the noun phrases (NP).\n",
        "print(chunk_tree)\n",
        "\n",
        "# Use pretty_print() to display the chunk tree in a structured format.\n",
        "chunk_tree.pretty_print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrvq_7lOVnkx",
        "outputId": "4315452d-bade-4261-ef85-53519984ccd5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN)\n",
            "  (NP fox/NN)\n",
            "  jumps/VBZ\n",
            "  over/IN\n",
            "  (NP the/DT lazy/JJ dog/NN))\n",
            "                                     S                                 \n",
            "     ________________________________|______________________            \n",
            "    |        |              NP               NP             NP         \n",
            "    |        |       _______|________        |       _______|______     \n",
            "jumps/VBZ over/IN The/DT quick/JJ brown/NN fox/NN the/DT lazy/JJ dog/NN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. **Creating a Left-Corner Parser**\n",
        "  - Implement a simple left-corner parser using the provided CFG.\n",
        "  - Parse the sentence \"The cat chased the dog\" using your left-corner parser.\n",
        "\n",
        "(Note: Implementing a left-corner parser can be challenging. This exercise encourages exploration of advanced parsing techniques in NLTK.)\n",
        "\n",
        "Placeholder for left-corner parser implementation and usage.\n",
        "\n"
      ],
      "metadata": {
        "id": "pDKSyUXj9x_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. **Probabilistic Parsing with Hidden Markov Models (HMM)**\n",
        "  - Train an HMM using a tagged corpus from NLTK (such as Brown).\n",
        "  - Use the trained HMM to parse a sentence and analyze the tags.\n"
      ],
      "metadata": {
        "id": "9iofAfxV9xk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.corpus import brown\n",
        "from nltk.tag import hmm\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY5wvnUp-aEm",
        "outputId": "1a4fa1e0-2066-4bde-c7c9-4b08036dfdf0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tags = brown.tagged_sents(categories='news')[:500]  # Training data (first 500 tagged sentences)\n",
        "\n",
        "# Train the HMM Tagger using the HiddenMarkovModelTrainer.\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "hmm_tagger = trainer.train(tags)\n",
        "\n",
        "# Print out information about the trained tagger.\n",
        "print(\"Trained HMM Tagger:\")\n",
        "print(hmm_tagger)\n",
        "\n",
        "# Example sentence for tagging.\n",
        "test_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Tokenize the sentence.\n",
        "test_tokens = word_tokenize(test_sentence)\n",
        "\n",
        "# Use the HMM tagger to tag the tokens.\n",
        "tagged_sentence = hmm_tagger.tag(test_tokens)\n",
        "print(\"\\nTagged Sentence:\")\n",
        "print(tagged_sentence)\n",
        "\n",
        "# Evaluate the HMM tagger on a sample from the Brown corpus.\n",
        "# Use a different portion of the corpus (e.g., sentences 501-600).\n",
        "test_data = brown.tagged_sents(categories='news')[500:600]\n",
        "\n",
        "# Calculate accuracy of the tagger on the test dataset.\n",
        "accuracy = hmm_tagger.evaluate(test_data)\n",
        "print(f\"\\nAccuracy on Brown corpus (sentences 501-600): {accuracy:.2f}\")\n",
        "\n",
        "# Tagging multiple sentences for demonstration.\n",
        "additional_sentences = [\n",
        "    \"She enjoys playing the piano.\",\n",
        "    \"The weather today is exceptionally sunny and warm.\",\n",
        "    \"Artificial Intelligence is transforming various industries.\",\n",
        "    \"The new product launched yesterday.\"\n",
        "]\n",
        "\n",
        "print(\"\\nAdditional Tagged Sentences:\")\n",
        "for sentence in additional_sentences:\n",
        "    tokens = word_tokenize(sentence)\n",
        "    tagged = hmm_tagger.tag(tokens)\n",
        "    print(tagged)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpH9lQ7WWTnc",
        "outputId": "23b87777-ffb5-4150-9901-ff9f4c50083a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained HMM Tagger:\n",
            "<HiddenMarkovModelTagger 122 states and 2946 output symbols>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:334: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:336: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:332: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "<ipython-input-44-bc600d53f40a>:27: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = hmm_tagger.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tagged Sentence:\n",
            "[('The', 'AT'), ('quick', 'AT'), ('brown', 'AT'), ('fox', 'AT'), ('jumps', 'AT'), ('over', 'AT'), ('the', 'AT'), ('lazy', 'AT'), ('dog', 'AT')]\n",
            "\n",
            "Accuracy on Brown corpus (sentences 501-600): 0.17\n",
            "\n",
            "Additional Tagged Sentences:\n",
            "[('She', 'AT'), ('enjoys', 'AT'), ('playing', 'AT'), ('the', 'AT'), ('piano', 'AT'), ('.', 'AT')]\n",
            "[('The', 'AT'), ('weather', 'AT'), ('today', 'AT'), ('is', 'AT'), ('exceptionally', 'AT'), ('sunny', 'AT'), ('and', 'AT'), ('warm', 'AT'), ('.', 'AT')]\n",
            "[('Artificial', 'AT'), ('Intelligence', 'AT'), ('is', 'AT'), ('transforming', 'AT'), ('various', 'AT'), ('industries', 'AT'), ('.', 'AT')]\n",
            "[('The', 'AT'), ('new', 'JJ'), ('product', 'NN'), ('launched', 'VBD'), ('yesterday', 'NR'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G81qAG5YWUgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}