{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babupallam/Msc_AI_Module2_Natural_Language_Processing/blob/main/Note_07_Miscellaneous_Advanced_Topics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqjjwTYSz7fc"
      },
      "source": [
        "- This file discusses about the sophisticated methods for improving the accuracy and adaptability of tagging systems.\n",
        "- While traditional approaches like unigram and bigram taggers perform reasonably well for simple tagging tasks, these advanced methods push the boundaries of POS tagging, making it more robust, scalable, and adaptable to real-world use cases.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGD0pKtz7b9"
      },
      "source": [
        "### **1. Transformation-Based Tagging**\n",
        "\n",
        "- **Transformation-Based Learning (TBL)**, also known as **Brill Tagging**, is a rule-based approach that iteratively refines tagging decisions by learning transformation rules from data.\n",
        "- This method was proposed by Eric Brill in 1995 and provides a hybrid approach between rule-based and statistical methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHr0xVWiz7Y9"
      },
      "source": [
        "#### Key Concepts:\n",
        "- **Initial State Tagging**:\n",
        "  - The algorithm starts with a basic tagger, often assigning the most frequent tag (e.g., a unigram tagger).\n",
        "- **Learning Transformations**:\n",
        "  - During training, the algorithm learns a set of transformation rules that \"correct\" mistakes made by the initial tagger.\n",
        "  - Each rule specifies conditions under which the tag should be changed (e.g., \"if a word is tagged as a noun but is preceded by an adjective, change it to a verb\").\n",
        "- **Iterative Refinement**:\n",
        "  - At each iteration, the system looks for the most effective transformation that improves tagging accuracy.\n",
        "  - Over multiple iterations, the system learns a sequence of rules that correct errors, improving accuracy over time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ4AQXSYz7WW"
      },
      "source": [
        "#### Example of a Transformation Rule:\n",
        "1. **Before Rule Application**:  \n",
        "   Input sentence: \"The **bank** closes at 5 PM.\"  \n",
        "   Incorrect Tagging: `bank` is tagged as a verb.\n",
        "2. **Rule Learned**:  \n",
        "   \"If a word is preceded by a determiner (e.g., 'The'), it is more likely to be a noun.\"\n",
        "3. **After Rule Application**:  \n",
        "   Correct Tagging: `bank` is tagged as a noun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeofDFuTz7Ta"
      },
      "source": [
        "#### Advantages:\n",
        "- **Explainability**: The rules are human-readable and interpretable, making the tagging process transparent.\n",
        "- **Customizability**: Since the rules are explicitly learned, they can be fine-tuned to specific domains (e.g., medical or legal text).\n",
        "- **Efficiency**: The method is computationally efficient and can be trained on relatively small datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbQQFtxJz7QU"
      },
      "source": [
        "#### Limitations:\n",
        "- **Requires Domain-Specific Knowledge**: While the rules are interpretable, they may need to be adapted or extended when dealing with domain-specific texts.\n",
        "- **Limited in Handling Long-Range Dependencies**: TBL works well with local contextual information but may struggle with long-range dependencies in sentences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUPfynOCyajU",
        "outputId": "73efb61c-a347-4b72-8b60-c5933da1b60c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading brill_tagger: Package 'brill_tagger' not\n",
            "[nltk_data]     found in index\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary libraries and classes from NLTK\n",
        "import nltk  # Main library for NLP tools\n",
        "from nltk.corpus import treebank  # Penn Treebank corpus with POS-tagged data\n",
        "from nltk.tag import UnigramTagger, BrillTaggerTrainer  # Unigram tagger and Brill trainer for tagging\n",
        "from nltk.tag.brill import Template, Pos  # Template class for defining transformation rules for Brill Tagger\n",
        "\n",
        "# Download necessary data resources\n",
        "nltk.download('brill_tagger')  # Download Brill tagger templates\n",
        "nltk.download('treebank')  # Download the Penn Treebank corpus for tagged sentences\n",
        "nltk.download('punkt')  # Download the tokenizer required for sentence tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gyx11ixyaUb",
        "outputId": "82806193-6db3-4410-a9bb-4464616da449"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-18c0d8af4b84>:17: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(f\"Unigram Tagger Accuracy: {unigram_tagger.evaluate(test_data):.4f}\")  # Output the accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigram Tagger Accuracy: 0.8572\n"
          ]
        }
      ],
      "source": [
        "# Load the tagged sentences from the Penn Treebank corpus\n",
        "# These sentences are manually annotated with parts of speech\n",
        "tagged_sents = treebank.tagged_sents()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# train_data: The data used to train the taggers (first 3000 sentences)\n",
        "# test_data: The data used to evaluate the tagger's performance (remaining sentences)\n",
        "train_data = tagged_sents[:3000]\n",
        "test_data = tagged_sents[3000:]\n",
        "\n",
        "# Step 1: Create a baseline Unigram tagger\n",
        "# Unigram tagger tags each word with the most frequent tag it has in the training data\n",
        "unigram_tagger = UnigramTagger(train_data)\n",
        "\n",
        "# Evaluate the performance of the Unigram tagger on the test data\n",
        "# The evaluate method checks how well the tagger performs by comparing predicted tags with the actual tags\n",
        "print(f\"Unigram Tagger Accuracy: {unigram_tagger.evaluate(test_data):.4f}\")  # Output the accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-RqYQ1ZzSpC"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define transformation templates for Brill Tagger\n",
        "# Templates tell the Brill tagger which patterns to look for when learning rules\n",
        "# Pos([-1]) means looking at the POS tag of the previous word\n",
        "# Pos([1]) means looking at the POS tag of the next word\n",
        "# Pos([-1, 0]) means looking at the previous and current POS tags\n",
        "# Pos([0, 1]) means looking at the current and next POS tags\n",
        "templates = [\n",
        "    Template(Pos([-1])),  # Check previous POS tag to create transformation rules\n",
        "    Template(Pos([1])),   # Check next POS tag\n",
        "    Template(Pos([-1, 0])),  # Check both previous and current POS tags\n",
        "    Template(Pos([0, 1])),   # Check both current and next POS tags\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m95UFRD8zSlu"
      },
      "outputs": [],
      "source": [
        "# Step 3: Initialize BrillTaggerTrainer\n",
        "# BrillTaggerTrainer is initialized with the initial UnigramTagger and the set of transformation templates\n",
        "trainer = BrillTaggerTrainer(initial_tagger=unigram_tagger, templates=templates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFBMArg3zYMk",
        "outputId": "71cd7a0d-a55d-4838-e0e2-77bafc1edacb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-5ca094e3d2a4>:9: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(f\"Brill Tagger Accuracy: {brill_tagger.evaluate(test_data):.4f}\")  # Output the improved accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brill Tagger Accuracy: 0.8695\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the Brill Tagger\n",
        "# Train the Brill tagger using the training data\n",
        "# max_rules=50: Learn up to 50 transformation rules\n",
        "# min_score=3.0: Only learn rules that improve accuracy by a score of 3.0 or higher\n",
        "brill_tagger = trainer.train(train_data, max_rules=50, min_score=3.0)\n",
        "\n",
        "# Step 5: Evaluate the Brill Tagger on the test data\n",
        "# The evaluate method calculates the accuracy of the Brill tagger\n",
        "print(f\"Brill Tagger Accuracy: {brill_tagger.evaluate(test_data):.4f}\")  # Output the improved accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVUTFc8OzYJL",
        "outputId": "6a020b8b-5d28-4991-bc07-f48c2abd8e07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-b4746905e8d9>:3: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  unigram_accuracy = unigram_tagger.evaluate(test_data)\n",
            "<ipython-input-22-b4746905e8d9>:4: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  brill_accuracy = brill_tagger.evaluate(test_data)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Unigram Tagger Accuracy: 0.8572\n",
            "Improved Brill Tagger Accuracy: 0.8695\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Compare the accuracy of Unigram Tagger and Brill Tagger\n",
        "# Evaluate both taggers and compare their performance\n",
        "unigram_accuracy = unigram_tagger.evaluate(test_data)\n",
        "brill_accuracy = brill_tagger.evaluate(test_data)\n",
        "\n",
        "# Print both accuracies for comparison\n",
        "print(f\"Initial Unigram Tagger Accuracy: {unigram_accuracy:.4f}\")\n",
        "print(f\"Improved Brill Tagger Accuracy: {brill_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Dkey76zYGa",
        "outputId": "9d8d93fb-60ea-4639-975c-0ff49b969e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', None), ('fox', None), ('jumps', None), ('over', 'IN'), ('the', 'DT'), ('lazy', None), ('dog', None), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Apply the Brill Tagger on a new sentence\n",
        "# Example sentence for tagging\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize the sentence into individual words\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Tag the tokenized sentence using the Brill tagger\n",
        "tagged_sentence = brill_tagger.tag(tokens)\n",
        "\n",
        "# Output the tagged sentence to see the POS tags assigned by the Brill tagger\n",
        "print(tagged_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZKXW4bEz7Nn"
      },
      "source": [
        "### **2. Machine Learning-Based Tagging**\n",
        "\n",
        "- The application of **machine learning algorithms** to POS tagging has become increasingly prevalent.\n",
        "- These methods move beyond rule-based approaches by learning from data and making probabilistic predictions about the appropriate tags for each word.\n",
        "- Two common machine learning techniques applied to POS tagging are **Naive Bayes** and **Decision Trees**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9hVE76z7K1"
      },
      "source": [
        "#### a. **Naive Bayes Tagging**\n",
        "- Note:\n",
        "  - The **Naive Bayes classifier** assumes that the probability of a word having a particular POS tag is independent of other words in the sentence, given the tag.\n",
        "  - While this assumption is rarely true in practice, Naive Bayes often performs well for POS tagging due to its simplicity and efficiency.\n",
        "\n",
        "- **Conditional Probabilities**: The classifier assigns a tag to a word based on the maximum likelihood, computed using the conditional probability of the word given the tag and the prior probability of the tag.\n",
        "  \n",
        "  Formula:  \n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "- **Strengths**:\n",
        "  - Fast and easy to implement.\n",
        "  - Performs well with limited training data.\n",
        "  \n",
        "- **Weaknesses**:\n",
        "  - The independence assumption is often violated in natural language.\n",
        "  - Less effective when dealing with complex sentence structures and long-range dependencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh-3DHUN09BZ",
        "outputId": "4d92b888-16cb-4759-a183-b4bea9d4add5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary libraries and modules from NLTK\n",
        "import nltk  # NLTK is the Natural Language Toolkit, a popular library for text processing in Python\n",
        "from nltk.corpus import treebank  # The Penn Treebank corpus contains manually annotated parts-of-speech (POS) tagged sentences\n",
        "from nltk import NaiveBayesClassifier, classify  # Import NaiveBayesClassifier for classification and classify module for accuracy evaluation\n",
        "from nltk.tag import UnigramTagger  # UnigramTagger is a simple POS tagger based on word frequency\n",
        "from nltk.classify import apply_features  # A helper function to efficiently apply features to datasets\n",
        "\n",
        "# Download necessary NLTK resources (treebank corpus and tokenizers)\n",
        "nltk.download('treebank')  # Penn Treebank contains syntactically parsed sentences (POS-tagged)\n",
        "nltk.download('punkt')  # Punkt tokenizer used for word tokenization in NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9stRtqvL0890"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the Penn Treebank corpus\n",
        "# The treebank corpus consists of sentences that are manually annotated with POS tags.\n",
        "# Each sentence is a list of (word, POS tag) tuples.\n",
        "tagged_sents = treebank.tagged_sents()  # Load all the POS-tagged sentences\n",
        "\n",
        "# Split the data into training and test sets\n",
        "# train_data: This data will be used to train the Naive Bayes classifier.\n",
        "# test_data: This data will be used to evaluate how well the trained classifier performs.\n",
        "train_data = tagged_sents[:3000]  # First 3000 sentences are used for training\n",
        "test_data = tagged_sents[3000:]   # The remaining sentences are used for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyG41OzO0868"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define a feature extraction function for each word in the sentence\n",
        "# The Naive Bayes classifier requires a set of features for each word to make predictions.\n",
        "# Features may include the word itself, surrounding words (previous, next), and any suffixes.\n",
        "def pos_features(sentence, i):\n",
        "    \"\"\"\n",
        "    Feature extractor for each word in the sentence.\n",
        "    Features extracted:\n",
        "    - The word itself (current word)\n",
        "    - The previous word (if it exists, otherwise mark as '<START>')\n",
        "    - The next word (if it exists, otherwise mark as '<END>')\n",
        "    - The suffix of the word (e.g., last three characters to capture patterns like 'ing', 'ed')\n",
        "\n",
        "    Parameters:\n",
        "    - sentence: list of words in the sentence\n",
        "    - i: the index of the word we want to extract features for\n",
        "\n",
        "    Returns:\n",
        "    - A dictionary of features for the word at index i\n",
        "    \"\"\"\n",
        "    features = {}  # Dictionary to hold the features for the current word\n",
        "    word = sentence[i]  # The current word we are extracting features for\n",
        "\n",
        "    # Current word as a feature (basic feature)\n",
        "    features['word'] = word\n",
        "\n",
        "    # Previous word as a feature\n",
        "    if i == 0:  # If this is the first word in the sentence\n",
        "        features['prev-word'] = '<START>'  # Use <START> to indicate no previous word\n",
        "    else:\n",
        "        features['prev-word'] = sentence[i - 1]  # The actual previous word\n",
        "\n",
        "    # Next word as a feature\n",
        "    if i == len(sentence) - 1:  # If this is the last word in the sentence\n",
        "        features['next-word'] = '<END>'  # Use <END> to indicate no next word\n",
        "    else:\n",
        "        features['next-word'] = sentence[i + 1]  # The actual next word\n",
        "\n",
        "    # Suffix feature (the last three characters of the word)\n",
        "    # This is useful for identifying common suffixes in words like '-ing', '-ed', etc.\n",
        "    if len(word) > 3:\n",
        "        features['suffix'] = word[-3:]  # The last 3 characters of the word\n",
        "    else:\n",
        "        features['suffix'] = word  # If the word is too short, use the entire word as the suffix\n",
        "\n",
        "    return features  # Return the dictionary of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWH7QNOm1VRP"
      },
      "outputs": [],
      "source": [
        "# Step 3: Prepare the data by converting each word into feature sets\n",
        "# We need to apply our feature extraction function to both the training and test data\n",
        "# The classifier expects a list of tuples where each tuple is (features, label)\n",
        "def prepare_data(tagged_sentences):\n",
        "    \"\"\"\n",
        "    Prepare the feature sets and labels (tags) for the classifier.\n",
        "    Converts tagged sentences into feature-tag pairs.\n",
        "\n",
        "    Parameters:\n",
        "    - tagged_sentences: list of tagged sentences, where each sentence is a list of (word, POS tag) tuples\n",
        "\n",
        "    Returns:\n",
        "    - A list of feature sets and corresponding POS tags\n",
        "    \"\"\"\n",
        "    feature_sets = []  # This will hold the feature-tag pairs\n",
        "    for tagged_sentence in tagged_sentences:  # Loop over each tagged sentence\n",
        "        untagged_sentence = [word for word, tag in tagged_sentence]  # Extract the words from the tagged sentence\n",
        "        tagged_words = [tag for word, tag in tagged_sentence]  # Extract the POS tags from the tagged sentence\n",
        "        for i in range(len(tagged_sentence)):  # Loop over each word in the sentence\n",
        "            features = pos_features(untagged_sentence, i)  # Extract features for the current word\n",
        "            feature_sets.append((features, tagged_words[i]))  # Append (features, POS tag) to the feature set\n",
        "    return feature_sets  # Return the complete feature set\n",
        "\n",
        "# Convert the training and test data into feature sets\n",
        "# We apply the feature extraction function to each sentence in the training and test data\n",
        "train_set = prepare_data(train_data)  # Prepare feature sets from the training data\n",
        "test_set = prepare_data(test_data)  # Prepare feature sets from the test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5gI8ZPf1VOB",
        "outputId": "6ec9b015-23ee-4527-c1ea-cc6947d2c50b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes POS Tagger Accuracy: 0.9305\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the Naive Bayes classifier using the feature sets\n",
        "# We use the NaiveBayesClassifier provided by NLTK to train the model\n",
        "# The classifier will learn the relationships between features and POS tags\n",
        "classifier = NaiveBayesClassifier.train(train_set)  # Train the classifier on the training data\n",
        "\n",
        "# Step 5: Evaluate the accuracy of the Naive Bayes classifier on the test data\n",
        "# We use the NLTK classify.accuracy() function to measure how well the classifier performs on the test set\n",
        "accuracy = classify.accuracy(classifier, test_set)  # Calculate the accuracy of the classifier\n",
        "print(f\"Naive Bayes POS Tagger Accuracy: {accuracy:.4f}\")  # Output the accuracy as a percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReIWR0B01VLU",
        "outputId": "e90b24c7-3f5e-4f1c-bed8-5748cd706096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tagged Sentence: [('The', 'DT'), ('quick', 'NNP'), ('brown', 'JJ'), ('fox', 'VBP'), ('jumps', 'NNS'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NNS'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Test the classifier on a new sentence\n",
        "# Tokenize a sample sentence and use the trained classifier to predict POS tags for each word\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"  # Example sentence\n",
        "tokens = nltk.word_tokenize(sentence)  # Tokenize the sentence into words\n",
        "\n",
        "# Extract features for each word in the new sentence using the pos_features function\n",
        "sentence_features = [pos_features(tokens, i) for i in range(len(tokens))]  # Extract features for each word\n",
        "\n",
        "# Use the trained Naive Bayes classifier to classify the POS tags of each word in the sentence\n",
        "classified_tags = classifier.classify_many(sentence_features)  # Classify all the words at once\n",
        "\n",
        "# Output the words and their predicted POS tags\n",
        "tagged_sentence = list(zip(tokens, classified_tags))  # Combine the words with their predicted POS tags\n",
        "print(\"Tagged Sentence:\", tagged_sentence)  # Print the tagged sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I95wJugWz7Hq"
      },
      "source": [
        "#### b. **Decision Tree Tagging**\n",
        "**Decision trees** provide a more flexible way to model tagging decisions by learning a series of decision rules based on word features, such as whether a word is capitalized or its position in the sentence.\n",
        "\n",
        "- **Feature Selection**: The decision tree algorithm splits the data based on features that provide the most significant reduction in uncertainty (e.g., entropy).\n",
        "- **Recursive Partitioning**: The tree recursively splits the data into subsets, learning rules for assigning tags based on features.\n",
        "  \n",
        "  Example:\n",
        "  1. If a word is at the beginning of a sentence and capitalized, it is more likely to be a proper noun.\n",
        "  2. If a word ends in \"ing,\" it is likely a verb.\n",
        "\n",
        "- **Advantages**:\n",
        "  - **Non-linear**: Decision trees can model non-linear relationships in the data.\n",
        "  - **Feature Flexibility**: The algorithm can incorporate a wide range of features, not just the word itself, but also context, word morphology, etc.\n",
        "  \n",
        "- **Disadvantages**:\n",
        "  - Prone to overfitting, especially with small datasets.\n",
        "  - Sensitive to noise and requires careful tuning.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk-YWudt3UzV"
      },
      "source": [
        "#### Code Demonstrations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkAPxYc21rx4",
        "outputId": "ae2af52a-5370-42df-c1b0-694979f66767"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary libraries and modules from NLTK\n",
        "import nltk  # NLTK is a comprehensive library for working with NLP tasks in Python\n",
        "from nltk.corpus import treebank  # Penn Treebank corpus, which contains POS-tagged sentences\n",
        "from nltk import DecisionTreeClassifier, classify  # Import DecisionTreeClassifier for POS tagging and classify for evaluating performance\n",
        "\n",
        "# Step 1: Download necessary resources from NLTK\n",
        "nltk.download('treebank')  # Download the Penn Treebank corpus, which is used for training and testing\n",
        "nltk.download('punkt')  # Download the Punkt tokenizer model for word tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqcGq08o1rux"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 2: Load the Penn Treebank corpus\n",
        "# The Penn Treebank contains manually tagged POS data, which we'll use for training and evaluation.\n",
        "# `tagged_sents` retrieves a list of sentences where each sentence contains tuples of (word, POS tag).\n",
        "tagged_sents = treebank.tagged_sents()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66wtIl1e1rsL"
      },
      "outputs": [],
      "source": [
        "# Step 3: Split the data into training and test sets\n",
        "# Here we limit the number of sentences to avoid memory overuse (200 for training and 50 for testing).\n",
        "# `train_data` will be used to train the Decision Tree Classifier, while `test_data` will be used to test its performance.\n",
        "train_data = tagged_sents[:200]  # First 200 sentences for training\n",
        "test_data = tagged_sents[200:250]  # Next 50 sentences for testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAJv9_VR1rpV"
      },
      "outputs": [],
      "source": [
        "# Step 4: Feature Extraction Function\n",
        "# To train the Decision Tree Classifier, we need to extract relevant features from each word in a sentence.\n",
        "# This function generates features for each word such as the word itself, whether it's capitalized, and its suffix.\n",
        "def pos_features(sentence, i):\n",
        "    \"\"\"\n",
        "    Extracts features for the word at index i in the sentence.\n",
        "\n",
        "    Features:\n",
        "    - 'word': the word itself (in lowercase)\n",
        "    - 'is_first': whether it's the first word in the sentence\n",
        "    - 'is_last': whether it's the last word in the sentence\n",
        "    - 'is_capitalized': whether the word starts with an uppercase letter\n",
        "    - 'suffix': the last three characters of the word (useful for identifying patterns like '-ing', '-ed')\n",
        "    - 'prev_word': the previous word (if it exists, else a special '<START>' marker)\n",
        "    - 'next_word': the next word (if it exists, else a special '<END>' marker)\n",
        "\n",
        "    Parameters:\n",
        "    - sentence: a list of words in the sentence\n",
        "    - i: the index of the word to extract features for\n",
        "\n",
        "    Returns:\n",
        "    - A dictionary of extracted features for the word at index i\n",
        "    \"\"\"\n",
        "    # Initialize a dictionary to store features\n",
        "    features = {\n",
        "        'word': sentence[i].lower(),  # Store the word itself in lowercase to avoid case sensitivity\n",
        "        'is_first': i == 0,  # True if it's the first word in the sentence, otherwise False\n",
        "        'is_last': i == len(sentence) - 1,  # True if it's the last word in the sentence, otherwise False\n",
        "        'is_capitalized': sentence[i][0].isupper(),  # True if the word starts with a capital letter\n",
        "        'suffix': sentence[i][-3:],  # The last three characters of the word (helps with patterns like '-ing', '-ed')\n",
        "        'prev_word': '' if i == 0 else sentence[i - 1].lower(),  # The previous word (empty if it's the first word)\n",
        "        'next_word': '' if i == len(sentence) - 1 else sentence[i + 1].lower(),  # The next word (empty if it's the last word)\n",
        "    }\n",
        "    return features  # Return the dictionary of features for the word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwAYsa4g3jWx"
      },
      "outputs": [],
      "source": [
        "# Step 5: Data Preparation Function\n",
        "# This function converts each sentence into feature sets (dictionary of features for each word) paired with the corresponding POS tag.\n",
        "# These feature-tag pairs will be used by the classifier to learn the mapping from features to POS tags.\n",
        "def prepare_data(tagged_sentences):\n",
        "    \"\"\"\n",
        "    Converts tagged sentences into feature-label pairs (for training/testing).\n",
        "\n",
        "    Parameters:\n",
        "    - tagged_sentences: A list of sentences, where each sentence is a list of (word, POS tag) tuples\n",
        "\n",
        "    Returns:\n",
        "    - A list of feature sets and corresponding POS tags\n",
        "    \"\"\"\n",
        "    feature_sets = []  # List to store (features, tag) pairs for all words in all sentences\n",
        "    for tagged_sentence in tagged_sentences:  # Loop over each sentence\n",
        "        words = [word for word, tag in tagged_sentence]  # Extract the list of words from the sentence\n",
        "        tags = [tag for word, tag in tagged_sentence]  # Extract the corresponding POS tags from the sentence\n",
        "        for i in range(len(tagged_sentence)):  # Loop over each word in the sentence\n",
        "            features = pos_features(words, i)  # Extract features for the current word\n",
        "            feature_sets.append((features, tags[i]))  # Pair the features with the corresponding POS tag\n",
        "    return feature_sets  # Return the list of (features, tag) pairs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9Iylvi73jTd"
      },
      "outputs": [],
      "source": [
        "# Step 6: Prepare the training and testing datasets\n",
        "train_set = prepare_data(train_data)  # Extract feature-tag pairs for the training data\n",
        "test_set = prepare_data(test_data)  # Extract feature-tag pairs for the test data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDFtdriV3jQx"
      },
      "outputs": [],
      "source": [
        "# Step 7: Train the Decision Tree Classifier\n",
        "# We train the DecisionTreeClassifier using the feature sets from the training data.\n",
        "# `entropy_cutoff` and `depth_cutoff` are used to prevent overfitting and reduce memory usage.\n",
        "classifier = nltk.DecisionTreeClassifier.train(train_set, entropy_cutoff=0.05, depth_cutoff=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pgGmBlm3nua",
        "outputId": "2347d657-6f38-4532-8240-593c5937a392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree POS Tagger Accuracy: 0.6396\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Evaluate the classifier's performance\n",
        "# `classify.accuracy()` computes the accuracy of the classifier on the test data.\n",
        "accuracy = classify.accuracy(classifier, test_set)  # Measure how well the classifier performs on unseen data (test set)\n",
        "print(f\"Decision Tree POS Tagger Accuracy: {accuracy:.4f}\")  # Output the accuracy as a percentage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4wRfLDl3nrE"
      },
      "outputs": [],
      "source": [
        "# Step 9: Test the classifier on a new, unseen sentence\n",
        "# We tokenize a sample sentence and use the trained classifier to predict POS tags for each word.\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"  # Example sentence for testing\n",
        "tokens = nltk.word_tokenize(sentence)  # Tokenize the sentence into individual words\n",
        "test_features = [pos_features(tokens, i) for i in range(len(tokens))]  # Extract features for each word in the sentence\n",
        "predicted_tags = [classifier.classify(f) for f in test_features]  # Classify each word using the trained classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsyeQ5l93rXV",
        "outputId": "a040b263-4feb-4b01-d66c-bf5b4d07db3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tagged Sentence: [('The', 'DT'), ('quick', '.'), ('brown', '.'), ('fox', '.'), ('jumps', '.'), ('over', 'IN'), ('the', 'DT'), ('lazy', '.'), ('dog', '.'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Step 10: Print the tagged sentence (word-POS pairs)\n",
        "tagged_sentence = list(zip(tokens, predicted_tags))  # Pair each word with its predicted POS tag\n",
        "print(\"Tagged Sentence:\", tagged_sentence)  # Print the POS-tagged sentence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmNVZ8nMz7FG"
      },
      "source": [
        "### **3. Maximum Entropy Models**\n",
        "\n",
        "A more sophisticated machine learning technique for POS tagging is the **Maximum Entropy (MaxEnt) model**. Unlike Naive Bayes, which makes simplifying independence assumptions, MaxEnt allows for dependencies between features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af6aa3Gpz7CZ"
      },
      "source": [
        "#### Key Concepts:\n",
        "- **Conditional Probability Modeling**: MaxEnt models estimate the probability of a tag given a set of features (e.g., surrounding words, word morphology) without making strong independence assumptions.\n",
        "- **Feature Weights**: The model assigns weights to each feature based on its importance for predicting the correct tag.\n",
        "  \n",
        "  ![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsHMvNYSz6-9"
      },
      "source": [
        "#### Advantages:\n",
        "- **Flexibility**: Can model more complex dependencies between words and their context.\n",
        "- **High Accuracy**: Often achieves better accuracy than simpler models like Naive Bayes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xghbSkkFz68l"
      },
      "source": [
        "#### Disadvantages:\n",
        "- **Computational Cost**: Training MaxEnt models can be computationally expensive due to the need for iterative optimization.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgFZpYg4KO5"
      },
      "source": [
        "#### Code Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mil01AHA4M8y",
        "outputId": "bb709c23-0b58-4530-8ac3-40ca41b26c50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries and modules\n",
        "import nltk\n",
        "from nltk.corpus import treebank  # Penn Treebank corpus for POS-tagged sentences\n",
        "from nltk.classify import MaxentClassifier  # MaxEnt classifier in NLTK\n",
        "from nltk import classify  # For evaluating the classifier\n",
        "\n",
        "# Download required resources from NLTK\n",
        "nltk.download('treebank')  # Download Penn Treebank corpus\n",
        "nltk.download('punkt')  # Tokenizer used for tokenizing new input sentences\n",
        "\n",
        "# Step 1: Load the Penn Treebank corpus\n",
        "# Load sentences that are POS-tagged from the Penn Treebank corpus\n",
        "tagged_sents = treebank.tagged_sents()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Nv9NB85BeF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "# Train with the first 3000 sentences and test with the next 500 sentences\n",
        "train_data = tagged_sents[:3000]\n",
        "test_data = tagged_sents[3000:3500]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw1_zRsF5BaM"
      },
      "outputs": [],
      "source": [
        "# Step 3: Define the feature extraction function\n",
        "# The features used here include the word itself, whether it's capitalized, and its suffix.\n",
        "def pos_features(sentence, i):\n",
        "    \"\"\"\n",
        "    Feature extractor for each word in the sentence.\n",
        "    Features include:\n",
        "    - The word itself (lowercased).\n",
        "    - Whether it's the first word in the sentence.\n",
        "    - Whether it's the last word in the sentence.\n",
        "    - Whether the word is capitalized.\n",
        "    - The suffix of the word (last 3 characters).\n",
        "    - The previous word and the next word (context).\n",
        "\n",
        "    Parameters:\n",
        "    - sentence: list of words in the sentence\n",
        "    - i: index of the word in the sentence\n",
        "\n",
        "    Returns:\n",
        "    - A dictionary of features for the word at index i.\n",
        "    \"\"\"\n",
        "    features = {\n",
        "        'word': sentence[i].lower(),  # The current word, in lowercase\n",
        "        'is_first': i == 0,  # Whether this is the first word\n",
        "        'is_last': i == len(sentence) - 1,  # Whether this is the last word\n",
        "        'is_capitalized': sentence[i][0].isupper(),  # Whether the word is capitalized\n",
        "        'suffix': sentence[i][-3:],  # The last 3 characters of the word (helps with identifying suffix patterns)\n",
        "        'prev_word': '' if i == 0 else sentence[i - 1].lower(),  # The previous word\n",
        "        'next_word': '' if i == len(sentence) - 1 else sentence[i + 1].lower()  # The next word\n",
        "    }\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djFYTqND5BXk"
      },
      "outputs": [],
      "source": [
        "# Step 4: Prepare the dataset by converting sentences to feature-tag pairs\n",
        "# We loop through each sentence and for each word, extract features and pair them with their respective POS tag.\n",
        "def prepare_data(tagged_sentences):\n",
        "    \"\"\"\n",
        "    Converts a list of tagged sentences into feature-tag pairs.\n",
        "\n",
        "    Parameters:\n",
        "    - tagged_sentences: list of sentences where each sentence is a list of (word, POS tag) tuples\n",
        "\n",
        "    Returns:\n",
        "    - A list of (features, POS tag) pairs.\n",
        "    \"\"\"\n",
        "    feature_sets = []\n",
        "    for tagged_sentence in tagged_sentences:  # Loop over each tagged sentence\n",
        "        sentence = [word for word, tag in tagged_sentence]  # Extract the words from the sentence\n",
        "        tags = [tag for word, tag in tagged_sentence]  # Extract the POS tags from the sentence\n",
        "        for i in range(len(tagged_sentence)):  # For each word in the sentence\n",
        "            features = pos_features(sentence, i)  # Extract features for the word\n",
        "            feature_sets.append((features, tags[i]))  # Pair the features with the POS tag\n",
        "    return feature_sets\n",
        "\n",
        "# Prepare the training and test datasets\n",
        "train_set = prepare_data(train_data)\n",
        "test_set = prepare_data(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56RodcNn5BUy"
      },
      "outputs": [],
      "source": [
        "# Step 5: Train the Maximum Entropy (MaxEnt) classifier\n",
        "# We use the MaxentClassifier.train() method from NLTK to train the model\n",
        "# MaxEnt allows us to avoid independence assumptions by considering multiple features simultaneously.\n",
        "classifier = MaxentClassifier.train(train_set, algorithm='iis', trace=0, max_iter=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYbumktr5mHw"
      },
      "source": [
        "`classifier = MaxentClassifier.train(train_set, algorithm='iis', trace=0, max_iter=10)`\"\n",
        "\n",
        "1. **`train_set`**: This is the dataset used for training the classifier. It consists of a list of feature-label pairs. In this case, the feature set includes word-level features like capitalization, suffix, and context, and the label corresponds to the POS tag.\n",
        "\n",
        "2. **`algorithm='iis'`**: The algorithm specifies the optimization algorithm used to train the Maximum Entropy model. The available algorithms in NLTK include:\n",
        "   - `'gis'` (Generalized Iterative Scaling)\n",
        "   - `'iis'` (Improved Iterative Scaling)\n",
        "   \n",
        "   In this case, `'iis'` is chosen, which is typically faster and more efficient than `'gis'`, especially for NLP tasks.\n",
        "\n",
        "3. **`trace=0`**: This argument controls the verbosity of the training process. A `trace` value of `0` means that no output will be displayed during training. Setting this to a higher value, like `1` or `2`, will show more information about the training progress (e.g., the number of iterations, improvements in accuracy).\n",
        "\n",
        "4. **`max_iter=10`**: This specifies the maximum number of iterations for the training algorithm. The model will keep iterating and improving until this limit is reached, or until the algorithm converges (i.e., no further improvement in accuracy).\n",
        "\n",
        "**Why MaxEnt and `iis` Algorithm?**\n",
        "\n",
        "- **MaxEnt models** are particularly useful in cases where feature independence is not a valid assumption, unlike Naive Bayes. MaxEnt models make use of multiple features simultaneously and apply weights to these features based on their contribution to the classification task.\n",
        "- The **IIS (Improved Iterative Scaling)** algorithm is chosen here because it generally converges faster and handles a wider variety of feature sets compared to GIS (Generalized Iterative Scaling).\n",
        "\n",
        "By setting `max_iter=10`, the training is limited to 10 iterations, ensuring that the model does not overtrain. However, if you need better performance, increasing this value might lead to better results, but at the cost of longer training times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8TXOef-5BSe",
        "outputId": "ae4e765c-e447-4111-b21d-ddb60ac03f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Entropy POS Tagger Accuracy: 0.8672\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Evaluate the classifier's performance\n",
        "# We evaluate how well the classifier performs on the test data by calculating its accuracy\n",
        "accuracy = classify.accuracy(classifier, test_set)\n",
        "print(f\"Maximum Entropy POS Tagger Accuracy: {accuracy:.4f}\")  # Print the accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP6fIMHJ5JYz",
        "outputId": "874647ff-2c51-475c-d4ba-e6fc4ae1ae34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tagged Sentence: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'NNS'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Test the classifier on a new, unseen sentence\n",
        "# Tokenize a sample sentence and classify its POS tags using the trained MaxEnt model\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"  # Sample test sentence\n",
        "tokens = nltk.word_tokenize(sentence)  # Tokenize the sentence into words\n",
        "\n",
        "# Extract features for each word in the sentence\n",
        "sentence_features = [pos_features(tokens, i) for i in range(len(tokens))]\n",
        "\n",
        "# Use the classifier to predict the POS tags for the words in the sentence\n",
        "predicted_tags = [classifier.classify(f) for f in sentence_features]\n",
        "\n",
        "# Print the tagged sentence (word, POS tag) pairs\n",
        "tagged_sentence = list(zip(tokens, predicted_tags))  # Zip the tokens with their predicted tags\n",
        "print(\"Tagged Sentence:\", tagged_sentence)  # Print the result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb8ZfP_lz651"
      },
      "source": [
        "### **4. Deep Learning-Based Tagging**\n",
        "\n",
        "While traditional machine learning methods have been effective for POS tagging, **deep learning** has pushed the boundaries even further by automating feature extraction and learning from large datasets. Though not fully explored in this section, deep learning methods like **Recurrent Neural Networks (RNNs)**, **LSTMs**, and **Transformers** excel at capturing long-range dependencies and handling the intricacies of natural language.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXUNJO8_6MgT"
      },
      "source": [
        "### 4.1 POS Tagging Using Deep Learning-Based Methods (LSTM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxHWN0Hk6V3F",
        "outputId": "4ede86bd-b005-43b6-df6d-df5b75add450"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import nltk  # Natural Language Toolkit for text processing\n",
        "import torch  # PyTorch for building neural networks\n",
        "import torch.nn as nn  # Neural network module from PyTorch\n",
        "import torch.optim as optim  # Optimization algorithms\n",
        "from sklearn.preprocessing import LabelEncoder  # For encoding POS tags\n",
        "from nltk.corpus import treebank  # Penn Treebank for POS-tagged sentences\n",
        "from torch.utils.data import Dataset, DataLoader  # For loading data in PyTorch\n",
        "from sklearn.model_selection import train_test_split  # For splitting data into training and testing\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('treebank')  # Download the Penn Treebank corpus\n",
        "nltk.download('punkt')  # Download tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzCZkWd_AUJ"
      },
      "source": [
        "#### **Step 1: Load the Dataset**\n",
        "   - **What Happens**:\n",
        "     - The **Penn Treebank** corpus from **NLTK** is loaded, which contains sentences with words that are tagged with parts of speech.\n",
        "     - The dataset is split into two lists: one containing sentences (words), and the other containing their corresponding POS tags.\n",
        "   - **Purpose**:\n",
        "     - The data is pre-tagged with POS information, making it suitable for training a supervised learning model like an LSTM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pGXkNZ46p1d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Load the Penn Treebank dataset\n",
        "tagged_sentences = treebank.tagged_sents()\n",
        "\n",
        "# Split the words and tags from each sentence\n",
        "sentences = [[word for word, tag in sentence] for sentence in tagged_sentences]\n",
        "pos_tags = [[tag for word, tag in sentence] for sentence in tagged_sentences]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTLNY5n2_FUh"
      },
      "source": [
        "#### **Step 2: Preprocessing the Data**\n",
        "   - **What Happens**:\n",
        "     - Each unique word in the dataset is mapped to a unique integer (word-to-index mapping) using a dictionary (`word_to_ix`). This allows the LSTM to work with numerical input data.\n",
        "     - POS tags are also encoded into integers using **LabelEncoder**. This encoder assigns a unique number to each distinct POS tag in the dataset.\n",
        "   - **Purpose**:\n",
        "     - Machine learning models like LSTMs operate on numerical data, so text (words and POS tags) must be converted into numerical representations. This step prepares the data for model input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb6cvGVZ7FQm"
      },
      "outputs": [],
      "source": [
        "# Step 2: Preprocessing - Encoding words and POS tags into integers\n",
        "# Use a dictionary for word indexing\n",
        "word_to_ix = {}\n",
        "for sent in sentences:\n",
        "    for word in sent:\n",
        "        if word.lower() not in word_to_ix:  # Lowercasing to handle case-insensitivity\n",
        "            word_to_ix[word.lower()] = len(word_to_ix) + 1  # Assign a unique index to each word\n",
        "\n",
        "# Encode POS tags\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for tags in pos_tags for tag in tags])  # Fit on all POS tags in the corpus\n",
        "\n",
        "# Create the vocabulary size and number of tags\n",
        "vocab_size = len(word_to_ix) + 1  # Add 1 for padding index\n",
        "num_tags = len(tag_encoder.classes_)  # Number of unique POS tags\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r_OkcrP_IB9"
      },
      "source": [
        "#### **Step 3: Create a PyTorch Dataset**\n",
        "   - **What Happens**:\n",
        "     - A custom `POSTaggingDataset` class is created, inheriting from PyTorch's `Dataset` class.\n",
        "     - In the `__getitem__()` method, each sentence is converted into a list of word indices (using the `word_to_ix` dictionary), and each POS tag is converted to its corresponding index.\n",
        "     - Sentences and tags are padded to a fixed length (`max_len`) to ensure all sequences have the same length (necessary for batch processing in LSTM models).\n",
        "   - **Purpose**:\n",
        "     - The dataset is wrapped in a PyTorch-compatible structure so that it can be loaded efficiently using `DataLoader`. Padding ensures that all input sequences are of the same length, which is required for batch training in LSTMs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaIObLgC7FNA"
      },
      "outputs": [],
      "source": [
        "# Step 3: Dataset Preparation\n",
        "# Define a PyTorch Dataset class for handling the data\n",
        "class POSTaggingDataset(Dataset):\n",
        "    def __init__(self, sentences, pos_tags, word_to_ix, tag_encoder, max_len):\n",
        "        self.sentences = sentences\n",
        "        self.pos_tags = pos_tags\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_encoder = tag_encoder\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tags = self.pos_tags[idx]\n",
        "\n",
        "        # Convert words to indices\n",
        "        word_indices = [self.word_to_ix[word.lower()] for word in sentence]\n",
        "\n",
        "        # Pad or truncate sentences\n",
        "        word_indices = word_indices[:self.max_len] + [0] * (self.max_len - len(word_indices))\n",
        "\n",
        "        # Convert tags to indices\n",
        "        tag_indices = self.tag_encoder.transform(tags)\n",
        "        tag_indices = list(tag_indices[:self.max_len]) + [0] * (self.max_len - len(tag_indices))\n",
        "\n",
        "        return torch.tensor(word_indices), torch.tensor(tag_indices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLYgwstS_O-B"
      },
      "source": [
        "#### **Step 4: Data Loading**\n",
        "   - **What Happens**:\n",
        "     - The dataset is split into training and testing sets using `train_test_split` (80% training, 20% testing).\n",
        "     - Data is loaded into PyTorch `DataLoader` objects for mini-batch processing.\n",
        "   - **Purpose**:\n",
        "     - The training and testing data is prepared and loaded in batches to feed into the LSTM model. This step improves computational efficiency during training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4Fb799m6pyv"
      },
      "outputs": [],
      "source": [
        "# Step 4: Prepare Data for Training and Testing\n",
        "# Set a maximum sequence length for padding\n",
        "max_len = max(len(sentence) for sentence in sentences)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, pos_tags, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize datasets and data loaders\n",
        "train_dataset = POSTaggingDataset(X_train, y_train, word_to_ix, tag_encoder, max_len)\n",
        "test_dataset = POSTaggingDataset(X_test, y_test, word_to_ix, tag_encoder, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q4bdLlV_RHe"
      },
      "source": [
        "#### **Step 5: Define the LSTM Model**\n",
        "   - **What Happens**:\n",
        "     - An LSTM-based model (`LSTMTagger`) is defined, consisting of the following layers:\n",
        "       1. **Embedding Layer**: Converts word indices into dense word vectors (embeddings) that represent the semantic meaning of the words.\n",
        "       2. **LSTM Layer**: Processes the sequence of word embeddings and captures dependencies between words. It outputs a hidden representation for each word in the sentence.\n",
        "       3. **Linear Layer**: Maps the hidden representation of each word to the space of possible POS tags.\n",
        "       4. **Log Softmax**: Applies a softmax activation to obtain a probability distribution over the POS tags for each word.\n",
        "   - **Purpose**:\n",
        "     - The LSTM is well-suited for sequence data because it can capture the dependencies between words in a sentence (such as the relationship between a verb and a noun).\n",
        "     - The model learns to predict the POS tag for each word based on its context in the sentence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wdUDdZp7j-9"
      },
      "outputs": [],
      "source": [
        "# Step 5: Define the LSTM Model for POS Tagging\n",
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim=128, hidden_dim=64):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Embedding layer to convert words to dense vectors\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)  # LSTM layer\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)  # Linear layer to map LSTM output to tagset size\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.embedding(sentence)  # Convert word indices to dense vectors\n",
        "        lstm_out, _ = self.lstm(embeds)  # Feed the embeddings through the LSTM\n",
        "        tag_space = self.hidden2tag(lstm_out)  # Map LSTM output to tag predictions\n",
        "        tag_scores = torch.log_softmax(tag_space, dim=2)  # Use log softmax for multi-class classification\n",
        "        return tag_scores\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = LSTMTagger(vocab_size, num_tags)\n",
        "loss_function = nn.NLLLoss()  # Negative log likelihood loss for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95e_BHMj_Tkm"
      },
      "source": [
        "#### **Step 6: Train the LSTM Model**\n",
        "   - **What Happens**:\n",
        "     - The model is trained for a certain number of epochs (5 in this case).\n",
        "     - For each batch of sentences in the training set:\n",
        "       1. The model receives a batch of sentences and predicts the POS tags for each word in those sentences.\n",
        "       2. The predicted POS tags are compared to the actual POS tags, and a loss is calculated using **NLLLoss** (Negative Log-Likelihood Loss).\n",
        "       3. The loss is backpropagated through the network to adjust the models weights.\n",
        "       4. The optimizer (Adam) updates the models weights to minimize the loss.\n",
        "   - **Purpose**:\n",
        "     - The model learns to predict POS tags by minimizing the error between predicted and actual tags during each training iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhz5kkXq7lQn",
        "outputId": "80e9d6c1-be51-4799-a1c9-2efb3c4fef93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.7767\n",
            "Epoch 2/5, Loss: 0.3030\n",
            "Epoch 3/5, Loss: 0.2189\n",
            "Epoch 4/5, Loss: 0.1692\n",
            "Epoch 5/5, Loss: 0.1367\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Train the LSTM model\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for sentences, tags in train_loader:\n",
        "        model.zero_grad()  # Zero the gradients before each batch\n",
        "        tag_scores = model(sentences)  # Get the tag scores (predictions)\n",
        "\n",
        "        # Reshape tags and predictions for the loss function\n",
        "        tag_scores = tag_scores.view(-1, num_tags)\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        loss = loss_function(tag_scores, tags)  # Calculate the loss\n",
        "        loss.backward()  # Backpropagate the loss\n",
        "        optimizer.step()  # Update the model parameters\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hDG6-Ni_WUM"
      },
      "source": [
        "#### **Step 7: Evaluate the Model**\n",
        "   - **What Happens**:\n",
        "     - The trained model is evaluated on the test set by making predictions on unseen data and comparing the predicted POS tags to the actual POS tags.\n",
        "     - The accuracy is calculated by counting the number of correctly predicted tags and dividing by the total number of tags.\n",
        "   - **Purpose**:\n",
        "     - Evaluating on a separate test set helps assess how well the model generalizes to unseen data, and thus, gives an indication of the model's real-world performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRCiQeKP7j7a",
        "outputId": "b9776b08-d165-4314-ba52-f84bc5182703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9694\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Evaluate the model on the test set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sentences, tags in test_loader:\n",
        "        tag_scores = model(sentences)\n",
        "        predicted_tags = torch.argmax(tag_scores, dim=2)  # Get the tag with the highest score\n",
        "\n",
        "        # Compare predictions with actual tags\n",
        "        correct += (predicted_tags == tags).sum().item()\n",
        "        total += tags.numel()\n",
        "\n",
        "print(f'Test Accuracy: {correct/total:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoVxC06B_Yco"
      },
      "source": [
        "#### **Step 8: Test the Model on a New Sentence**\n",
        "   - **What Happens**:\n",
        "     - A new sentence (e.g., \"The quick brown fox jumps over the lazy dog.\") is tokenized into words.\n",
        "     - The words are converted into indices using the same word-to-index mapping (`word_to_ix`) used during training.\n",
        "     - The model predicts the POS tags for the sentence using the LSTM.\n",
        "     - The predicted tag indices are converted back into POS tag names using the **LabelEncoder** that was fitted earlier.\n",
        "   - **Purpose**:\n",
        "     - This step demonstrates how the model can be used for inference on new, unseen sentences. The model predicts the POS tags for each word in the sentence, based on the patterns it learned during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXLs0nVW7j4x",
        "outputId": "3997c9ac-338d-4067-8d11-028fce4353d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NNP'), ('fox', '#'), ('jumps', 'NN'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', '#'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Test the model on a new sentence\n",
        "test_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "test_tokens = [word_to_ix.get(word.lower(), 0) for word in nltk.word_tokenize(test_sentence)]  # Convert sentence to indices, handle unknown words\n",
        "test_tokens = torch.tensor(test_tokens).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Get tag predictions\n",
        "with torch.no_grad():\n",
        "    tag_scores = model(test_tokens)\n",
        "    predicted_tags = torch.argmax(tag_scores, dim=2).squeeze().tolist()\n",
        "\n",
        "# Convert tag indices back to POS tags\n",
        "predicted_pos_tags = tag_encoder.inverse_transform(predicted_tags)\n",
        "print(list(zip(nltk.word_tokenize(test_sentence), predicted_pos_tags)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9JbfErq_qhV"
      },
      "source": [
        "### 4.2 POS Tagging Using Recurrent Neural Networks (RNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAewqQp4Ab7n",
        "outputId": "719b4552-8046-43b6-efdb-f0be2cef929a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import nltk  # Natural Language Toolkit (for data)\n",
        "import torch  # PyTorch for building the neural network\n",
        "import torch.nn as nn  # For defining neural network layers\n",
        "import torch.optim as optim  # For optimization algorithms (e.g., Adam)\n",
        "from nltk.corpus import treebank  # Penn Treebank corpus for POS-tagged sentences\n",
        "from sklearn.preprocessing import LabelEncoder  # For encoding POS tags\n",
        "from torch.utils.data import Dataset, DataLoader  # For handling data loading and batching\n",
        "from sklearn.model_selection import train_test_split  # For splitting data into train and test sets\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('treebank')  # Download the Penn Treebank corpus\n",
        "nltk.download('punkt')  # Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp0v3lerBcVk"
      },
      "source": [
        "#### **Step 1: Load and Prepare the Penn Treebank Dataset**\n",
        "   - **What Happens**:\n",
        "     - The **NLTK Penn Treebank** dataset is loaded, which contains sentences with words tagged by parts of speech (POS).\n",
        "     - Each sentence is a list of (word, POS tag) tuples.\n",
        "     - We extract the sentences (words) and corresponding POS tags into two separate lists.\n",
        "   - **Purpose**:\n",
        "     - We need POS-tagged sentences to train a supervised model for POS tagging. Extracting words and tags allows us to process the data separately for use in the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS6EUfeLAb5X"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Load and prepare the Penn Treebank dataset\n",
        "tagged_sentences = treebank.tagged_sents()  # Load tagged sentences (POS-tagged)\n",
        "\n",
        "# Split the words and the corresponding tags from each sentence\n",
        "sentences = [[word for word, tag in sentence] for sentence in tagged_sentences]\n",
        "pos_tags = [[tag for word, tag in sentence] for sentence in tagged_sentences]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwskcKkrBcRJ"
      },
      "source": [
        "#### **Step 2: Preprocess the Words and POS Tags**\n",
        "   - **What Happens**:\n",
        "     - A **word-to-index mapping** (`word_to_ix`) is created by iterating through each word in the sentences. Each unique word is assigned a unique integer (starting from 1). This is necessary for transforming words into numerical format for the RNN model.\n",
        "     - The **POS tags** are encoded into integers using **LabelEncoder**, which assigns a unique integer to each POS tag.\n",
        "   - **Purpose**:\n",
        "     - RNN models can only work with numerical data. By converting words and POS tags into integers, we can represent them in a format suitable for feeding into the RNN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMBIYieOAb3T"
      },
      "outputs": [],
      "source": [
        "# Step 2: Preprocess words and POS tags (encode them into integers)\n",
        "# Create a word-to-index dictionary for words\n",
        "word_to_ix = {}\n",
        "for sent in sentences:\n",
        "    for word in sent:\n",
        "        if word.lower() not in word_to_ix:  # Lowercase for case-insensitivity\n",
        "            word_to_ix[word.lower()] = len(word_to_ix) + 1  # Unique index for each word\n",
        "\n",
        "# Encode POS tags using LabelEncoder\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for tags in pos_tags for tag in tags])  # Flatten all tags into a single list and fit encoder\n",
        "\n",
        "# Vocabulary size and number of POS tags\n",
        "vocab_size = len(word_to_ix) + 1  # Adding 1 for padding index\n",
        "num_tags = len(tag_encoder.classes_)  # Number of unique POS tags\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YuxAChXBb70"
      },
      "source": [
        "#### **Step 3: Define a Custom PyTorch Dataset Class**\n",
        "   - **What Happens**:\n",
        "     - A custom PyTorch **Dataset** class (`POSTaggingDataset`) is created to handle the transformation of sentences and their corresponding POS tags into tensor format.\n",
        "     - The class handles padding or truncating sequences to ensure that all sequences are of the same length (using a predefined `max_len`).\n",
        "     - The `__getitem__()` method converts words into their respective indices (based on the `word_to_ix` dictionary) and POS tags into their respective indices (based on the `LabelEncoder`).\n",
        "   - **Purpose**:\n",
        "     - This class makes it easier to load data into the RNN model in batches. It also ensures that input sequences are padded to a uniform length, which is necessary for batch processing in RNNs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mpYwdTvAb1E"
      },
      "outputs": [],
      "source": [
        "# Step 3: Define a PyTorch Dataset for handling word and tag sequences\n",
        "class POSTaggingDataset(Dataset):\n",
        "    def __init__(self, sentences, pos_tags, word_to_ix, tag_encoder, max_len):\n",
        "        self.sentences = sentences\n",
        "        self.pos_tags = pos_tags\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_encoder = tag_encoder\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tags = self.pos_tags[idx]\n",
        "\n",
        "        # Convert words to indices and pad/truncate\n",
        "        word_indices = [self.word_to_ix[word.lower()] for word in sentence]\n",
        "        word_indices = word_indices[:self.max_len] + [0] * (self.max_len - len(word_indices))  # Padding\n",
        "\n",
        "        # Convert POS tags to indices and pad/truncate\n",
        "        tag_indices = self.tag_encoder.transform(tags)\n",
        "        tag_indices = list(tag_indices[:self.max_len]) + [0] * (self.max_len - len(tag_indices))  # Padding\n",
        "\n",
        "        return torch.tensor(word_indices), torch.tensor(tag_indices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMUEnCqMBb4i"
      },
      "source": [
        "#### **Step 4: Split the Data and Load It for Training**\n",
        "   - **What Happens**:\n",
        "     - The dataset is split into **training** and **test** sets using the `train_test_split()` function from **sklearn**.\n",
        "     - **DataLoader** objects are created for both the training and testing sets. These objects handle batching and shuffling of data during training and evaluation.\n",
        "   - **Purpose**:\n",
        "     - By splitting the dataset, we can train the RNN on one portion of the data (training set) and evaluate its performance on unseen data (test set). The `DataLoader` simplifies the process of feeding batches of data to the model during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE90aT6kAbzG"
      },
      "outputs": [],
      "source": [
        "# Step 4: Data preparation and loading\n",
        "# Set the maximum sentence length based on the longest sentence in the dataset\n",
        "max_len = max(len(sentence) for sentence in sentences)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, pos_tags, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Dataset and DataLoader for training and testing\n",
        "train_dataset = POSTaggingDataset(X_train, y_train, word_to_ix, tag_encoder, max_len)\n",
        "test_dataset = POSTaggingDataset(X_test, y_test, word_to_ix, tag_encoder, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1oN-bDDBb1j"
      },
      "source": [
        "#### **Step 5: Define the RNN Model**\n",
        "   - **What Happens**:\n",
        "     - The **RNNTagger** class is defined using PyTorchs **nn.Module**. It consists of:\n",
        "       1. **Embedding Layer**: Converts the input word indices into dense word vectors (embeddings), which serve as input to the RNN.\n",
        "       2. **RNN Layer**: A basic **Recurrent Neural Network (RNN)** processes the word embeddings and captures sequential information across the sentence.\n",
        "       3. **Linear Layer**: The output from the RNN is passed through a fully connected (linear) layer to predict POS tags.\n",
        "       4. **Log-Softmax Layer**: A log-softmax is applied to the output to calculate the probability distribution over POS tags for each word in the sentence.\n",
        "   - **Purpose**:\n",
        "     - The RNN is designed to process sequences of words and predict a sequence of POS tags. The hidden state in the RNN maintains information from previous words, which helps in making more accurate predictions for the current word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dbZ0kkuAbw0"
      },
      "outputs": [],
      "source": [
        "# Step 5: Define the RNN model for POS tagging\n",
        "class RNNTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim=128, hidden_dim=64):\n",
        "        super(RNNTagger, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Embedding layer\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)  # RNN layer\n",
        "        self.fc = nn.Linear(hidden_dim, tagset_size)  # Fully connected layer to predict POS tags\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.embedding(sentence)  # Convert words to dense vectors\n",
        "        rnn_out, _ = self.rnn(embeds)  # Process the sequence through the RNN\n",
        "        tag_space = self.fc(rnn_out)  # Map RNN outputs to POS tags\n",
        "        tag_scores = torch.log_softmax(tag_space, dim=2)  # Apply log-softmax for multi-class classification\n",
        "        return tag_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXPebBRkBbyx"
      },
      "source": [
        "#### **Step 6: Initialize the Model, Loss Function, and Optimizer**\n",
        "   - **What Happens**:\n",
        "     - The RNN model is instantiated with the vocabulary size, tagset size, and other parameters (embedding dimension and hidden dimension).\n",
        "     - The **Negative Log-Likelihood Loss (NLLLoss)** is used as the loss function since it's appropriate for multi-class classification tasks.\n",
        "     - The **Adam optimizer** is used to update the models parameters based on the computed gradients.\n",
        "   - **Purpose**:\n",
        "     - This step sets up the components necessary for training the RNN model. The loss function measures the difference between predicted and actual POS tags, while the optimizer adjusts the model's weights to minimize this difference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xskcWgCtAbsd"
      },
      "outputs": [],
      "source": [
        "# Step 6: Initialize the model, loss function, and optimizer\n",
        "model = RNNTagger(vocab_size, num_tags)  # Initialize RNN model\n",
        "loss_function = nn.NLLLoss()  # Negative Log Likelihood Loss for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMw7JoLDBbwI"
      },
      "source": [
        "#### **Step 7: Train the Model**\n",
        "   - **What Happens**:\n",
        "     - The training process involves iterating over the training data for a specified number of **epochs** (5 in this case).\n",
        "     - For each batch of sentences and tags:\n",
        "       1. The model makes predictions for the POS tags of each word.\n",
        "       2. The predicted tags are compared to the actual tags, and a **loss** is calculated.\n",
        "       3. The loss is **backpropagated** through the network, and the optimizer updates the model's parameters to minimize the loss.\n",
        "   - **Purpose**:\n",
        "     - Training allows the model to learn from the data by adjusting its parameters. After each epoch, the model should get better at predicting the correct POS tags.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux53t_0tAbpW",
        "outputId": "fa23abfd-be58-4404-96c2-10aca9c516ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.6470\n",
            "Epoch 2/5, Loss: 0.2567\n",
            "Epoch 3/5, Loss: 0.1847\n",
            "Epoch 4/5, Loss: 0.1447\n",
            "Epoch 5/5, Loss: 0.1175\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Train the RNN model\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for sentences, tags in train_loader:\n",
        "        model.zero_grad()  # Zero out the gradients for each batch\n",
        "        tag_scores = model(sentences)  # Get predictions from the model\n",
        "\n",
        "        # Reshape predictions and targets to match the loss function requirements\n",
        "        tag_scores = tag_scores.view(-1, num_tags)  # Flatten out the sequence dimension\n",
        "        tags = tags.view(-1)  # Flatten out the targets\n",
        "\n",
        "        loss = loss_function(tag_scores, tags)  # Compute loss\n",
        "        loss.backward()  # Backpropagate the gradients\n",
        "        optimizer.step()  # Update model weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uwY6NmiBbsy"
      },
      "source": [
        "#### **Step 8: Evaluate the Model**\n",
        "   - **What Happens**:\n",
        "     - The model is evaluated on the test set. The models predictions are compared to the actual POS tags, and the **accuracy** is calculated.\n",
        "     - The `torch.no_grad()` context is used to disable gradient computation during evaluation, which saves memory and speeds up the process.\n",
        "   - **Purpose**:\n",
        "     - Evaluating the model on unseen data (test set) gives an indication of how well it generalizes beyond the training data. High accuracy on the test set suggests the model has learned the task well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUWz4lMAbm9",
        "outputId": "407e464f-ad92-47a8-811c-4cf7159cb9d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9730\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Evaluate the model on the test set\n",
        "model.eval()  # Switch to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # No need to track gradients during evaluation\n",
        "    for sentences, tags in test_loader:\n",
        "        tag_scores = model(sentences)  # Get predictions from the model\n",
        "        predicted_tags = torch.argmax(tag_scores, dim=2)  # Get the tag with the highest score\n",
        "\n",
        "        # Calculate accuracy by comparing predictions to the actual tags\n",
        "        correct += (predicted_tags == tags).sum().item()\n",
        "        total += tags.numel()\n",
        "\n",
        "print(f'Test Accuracy: {correct/total:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsi6WU-zBuf5"
      },
      "source": [
        "#### **Step 9: Test the Model on a New Sentence**\n",
        "   - **What Happens**:\n",
        "     - A new sentence is tokenized and converted into word indices using the `word_to_ix` dictionary.\n",
        "     - The model predicts the POS tags for each word in the sentence.\n",
        "     - The predicted tag indices are converted back to POS tags using the **LabelEncoder**.\n",
        "   - **Purpose**:\n",
        "     - This step demonstrates how the trained model can be used for **inference**. The model takes a new, unseen sentence and predicts the POS tags for each word, showcasing its ability to generalize to new input data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh0S-D3FAbj8",
        "outputId": "5ef3ac99-5d76-4d7e-c301-de57e7309aea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('The', 'DT'), ('quick', 'NN'), ('brown', 'NNP'), ('fox', '#'), ('jumps', '#'), ('over', 'IN'), ('the', 'DT'), ('lazy', '#'), ('dog', '#'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Test the model on a new sentence\n",
        "test_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "test_tokens = [word_to_ix.get(word.lower(),0) for word in nltk.word_tokenize(test_sentence)]  # Tokenize and convert to indices\n",
        "test_tokens = torch.tensor(test_tokens).unsqueeze(0)  # Add batch dimension for processing\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    tag_scores = model(test_tokens)\n",
        "    predicted_tags = torch.argmax(tag_scores, dim=2).squeeze().tolist()  # Get predicted POS tag indices\n",
        "\n",
        "# Convert indices back to POS tags using LabelEncoder\n",
        "predicted_pos_tags = tag_encoder.inverse_transform(predicted_tags)\n",
        "print(list(zip(nltk.word_tokenize(test_sentence), predicted_pos_tags)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AirIgpL4AVs3"
      },
      "source": [
        "### 4.3 POS Tagging Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch  # PyTorch for building neural networks\n",
        "import torch.nn as nn  # Neural network layers\n",
        "import numpy as np  # For numerical operations\n",
        "from transformers import BertTokenizer, BertForTokenClassification  # Pre-trained BERT tokenizer and model\n",
        "from transformers import AdamW  # Optimizer for fine-tuning BERT\n",
        "from torch.utils.data import Dataset, DataLoader  # PyTorch Dataset and DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder  # For encoding POS tags\n",
        "\n"
      ],
      "metadata": {
        "id": "PCosZY6Ot6Hp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 1: Create a Small Toy Dataset**\n",
        "   - **What Happens**:\n",
        "     - We manually define a small set of toy sentences (e.g., `\"I love Python\"`, `\"He is a developer\"`) and their corresponding part-of-speech (POS) tags (e.g., `\"PRP\"`, `\"VBP\"`, `\"NNP\"`).\n",
        "   - **Purpose**:\n",
        "     - This toy dataset simplifies the training process, allowing the model to run much faster. Since we are using a smaller dataset, the model can complete both training and testing quickly, ideal for demonstration or experimentation.\n",
        "\n"
      ],
      "metadata": {
        "id": "UO1KgGCWKsi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a small toy dataset\n",
        "# Manually define a small set of sentences and their corresponding POS tags\n",
        "toy_sentences = [\n",
        "    [\"I\", \"love\", \"Python\"],\n",
        "    [\"He\", \"is\", \"a\", \"developer\"],\n",
        "    [\"She\", \"writes\", \"code\"],\n",
        "    [\"They\", \"are\", \"working\", \"on\", \"a\", \"project\"]\n",
        "]\n",
        "\n",
        "toy_pos_tags = [\n",
        "    [\"PRP\", \"VBP\", \"NNP\"],\n",
        "    [\"PRP\", \"VBZ\", \"DT\", \"NN\"],\n",
        "    [\"PRP\", \"VBZ\", \"NN\"],\n",
        "    [\"PRP\", \"VBP\", \"VBG\", \"IN\", \"DT\", \"NN\"]\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "RZphBHGVKTH-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2: Encode POS Tags**\n",
        "   - **What Happens**:\n",
        "     - The POS tags (e.g., `\"PRP\"`, `\"VBP\"`, `\"NNP\"`) are converted into **integer labels** using **LabelEncoder** from `sklearn`. Each unique tag is assigned a unique integer ID, which is necessary because BERT expects numerical labels for classification.\n",
        "   - **Purpose**:\n",
        "     - Converting POS tags to numerical form is essential for training the BERT model, which performs token classification. The integer labels will represent the correct POS tag for each word in the sentence.\n"
      ],
      "metadata": {
        "id": "rs_J2_ATKsfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess POS tags (encode them into integers)\n",
        "# Use LabelEncoder to encode the POS tags into integers\n",
        "tag_encoder = LabelEncoder()\n",
        "tag_encoder.fit([tag for tags in toy_pos_tags for tag in tags])  # Fit on all POS tags\n",
        "num_tags = len(tag_encoder.classes_)  # Get the number of unique POS tags\n",
        "\n"
      ],
      "metadata": {
        "id": "7Jnj4qlvKTEj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3: Load the Pre-trained BERT Tokenizer**\n",
        "   - **What Happens**:\n",
        "     - The **BERT tokenizer** is loaded using `BertTokenizer.from_pretrained()`. The tokenizer splits sentences into **subword tokens** (if necessary) and converts them into token IDs that can be processed by the BERT model.\n",
        "     - The tokenizer also ensures that the sentences are padded or truncated to a fixed length (`max_len`), making the input sequences uniform in size.\n",
        "   - **Purpose**:\n",
        "     - BERT models require tokenized input, and sentences need to be standardized (by padding or truncating) to a fixed length. The tokenizer handles both these tasks and converts the sentences into a format that BERT can process.\n"
      ],
      "metadata": {
        "id": "tJD_N1aIKsc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')  # BERT tokenizer for tokenization\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "4b9aedd495e046d6b10de09f9f58c7e2",
            "073deba89f2d415fae415e8ae9285ea5",
            "c8858ed327aa4bc08aa5ff28801ba18d",
            "1c34191c442044dd9aa0c7c6f7a9b7ce",
            "343857d6eec74270b9313a61e2fa3645",
            "823b862c32d04cbda5e657656c26fdf3",
            "5b8cc32b3f5c43648da9b6a66e0784ba",
            "a42067aca0c74c7e97618ca4ad908e64",
            "99243252f98e4f43a6d56f71dc1d5855",
            "1c52b1b54c8c4c58a043cc6c81fa93a2",
            "a89d589ed12447ff88fd01ba677f5837",
            "b7a7c53de780405b9dae1f446a58fb01",
            "ba87aea1bc154ad4b9032d14ade9752c",
            "c8912f8a5bf5496e90ce72d466c547ea",
            "1fca463f5693409287a549b78f25cf0f",
            "5b44745b6dad455facb9d2ee8ebdb2e4",
            "40b826c0fc7d401e8ca2b12f77cda360",
            "fbfa226348d44e7caae68e556e14c125",
            "87815ee3ab9242f98f09fd8d045d34f1",
            "c50998a7dac3482eb184e2d157d0b388",
            "51c0bc07281f41e1a006b31e9e7504ea",
            "ffc6cdcd048b469a88f9ff1e50992144",
            "04995525a9d240cdafe83c7de005bf32",
            "3719f9cacbb449adad6a89c840d47332",
            "cd7f7a27ff02400393279f108fffe5fc",
            "3788016aa2ca48c28250199e8de701d6",
            "432a643f7dd34f40a24e121c69f1b8c6",
            "624b489d59a342f08fd0d6503f9c9dfe",
            "7319a7bdfda04e71ba559209797cb71e",
            "019655241d134f329223f7d025bacb7b",
            "3d2895eaf5384b7e88ff7cdad55450f3",
            "792db2ba7b6844e7a67edf469be7f28a",
            "d481d11a62cb4176991500d4a06d1aa7",
            "ee45bb15a57a40c588a7895632f640d2",
            "2e16845fdf404d6c956aa048d639a92f",
            "e4e22050efe740b79abe2e3cb131382f",
            "e68fc25b0e634d09a8266da5791756fc",
            "b68461e8fc5c493e93f948a00f88ae74",
            "bcbefd3acd5b4962b85188c570f7e781",
            "e45faeb9cb454bc79724bd53d5f9b625",
            "83f0664cc3524a2dbb8f4f2d101307e0",
            "ec41f264c2be48cca2a206a331abf152",
            "d0499f27d0544b8794d98d2ead2ebe4e",
            "f9cec975227c4302a0326410a92c56ea"
          ]
        },
        "id": "EYN_k1sBKS-j",
        "outputId": "97908188-054c-438d-c61a-b13adc10fab6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b9aedd495e046d6b10de09f9f58c7e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7a7c53de780405b9dae1f446a58fb01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04995525a9d240cdafe83c7de005bf32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee45bb15a57a40c588a7895632f640d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 4: Define a Custom PyTorch Dataset**\n",
        "   - **What Happens**:\n",
        "     - A **custom PyTorch Dataset class** is created (`ToyPOSTaggingDataset`) that prepares the input sentences and tags for the model.\n",
        "     - The sentences are tokenized using BERT's tokenizer, and the POS tags are converted to integer labels using the **LabelEncoder**.\n",
        "     - Sentences and tags are padded or truncated to a fixed maximum length (`max_len`), ensuring that all inputs are of uniform size.\n",
        "   - **Purpose**:\n",
        "     - This class provides a clean interface for loading and processing data during training and testing. It returns tokenized input sentences, attention masks (to handle padding), and the corresponding POS tag labels.\n"
      ],
      "metadata": {
        "id": "uYlXWyEbKwQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create a custom PyTorch Dataset for the toy dataset\n",
        "class ToyPOSTaggingDataset(Dataset):\n",
        "    def __init__(self, sentences, pos_tags, tokenizer, tag_encoder, max_len=10):\n",
        "        self.sentences = sentences\n",
        "        self.pos_tags = pos_tags\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tag_encoder = tag_encoder\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tags = self.pos_tags[idx]\n",
        "\n",
        "        # Tokenize the sentence and pad/truncate to max_len\n",
        "        encoding = self.tokenizer(sentence,\n",
        "                                  is_split_into_words=True,\n",
        "                                  padding='max_length',\n",
        "                                  truncation=True,\n",
        "                                  max_length=self.max_len,\n",
        "                                  return_tensors='pt')\n",
        "\n",
        "        # Encode the POS tags and pad/truncate to max_len\n",
        "        tag_indices = self.tag_encoder.transform(tags)\n",
        "        tag_indices = list(tag_indices[:self.max_len]) + [0] * (self.max_len - len(tag_indices))  # Padding\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(tag_indices)\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "9YTQdcDlKS6_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 5: DataLoader Preparation**\n",
        "   - **What Happens**:\n",
        "     - The **Dataset** is wrapped in a **DataLoader** to handle batching and shuffling during training. We set a batch size of `2` for the toy dataset to ensure fast training.\n",
        "   - **Purpose**:\n",
        "     - The **DataLoader** efficiently loads batches of data during training, improving computational efficiency and making the process of feeding data into the model simpler.\n"
      ],
      "metadata": {
        "id": "HKXx_sW0KsSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Prepare DataLoader for the toy dataset\n",
        "max_len = 10  # Max length for padding/truncating sentences\n",
        "\n",
        "# Create dataset object\n",
        "toy_dataset = ToyPOSTaggingDataset(toy_sentences, toy_pos_tags, tokenizer, tag_encoder, max_len)\n",
        "\n",
        "# Create DataLoader object for batching\n",
        "toy_loader = DataLoader(toy_dataset, batch_size=2, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "aOBr2S26KS4c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 6: Load Pre-trained BERT Model for Token Classification**\n",
        "   - **What Happens**:\n",
        "     - We load a pre-trained BERT model (`BertForTokenClassification`) from the Hugging Face library. This model is specifically designed for **token-level classification** tasks (such as POS tagging).\n",
        "     - The model is configured to predict from a set number of possible POS tags (as defined by `num_labels`).\n",
        "   - **Purpose**:\n",
        "     - The pre-trained BERT model provides a powerful foundation for token classification. By fine-tuning it on our toy dataset, the model can learn to predict POS tags for each word in the input sequence.\n"
      ],
      "metadata": {
        "id": "8yjWmvjtKwQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Load pre-trained BERT model for token classification\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=num_tags)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795,
          "referenced_widgets": [
            "33ccf2b656a1423d86978b46987a2c27",
            "e521b324997445b8b541eaa5ab03e175",
            "a8a6eb16115544148fc5ee42fc1dd1b4",
            "045967dae9e9416daa4c93c9c4a3ab2e",
            "5bd769ad1d054ec081b31fae16473f18",
            "44a0ebe833914c2dba47d6905899677a",
            "7a35bac0792d457895412f1eeb5362ad",
            "4f12d8cfe04045a5bee1d0a7e7dab8fe",
            "b60f3080aef74b9fbc6529af0adc0726",
            "46e3bff6a9f348428b502f871ff61b3a",
            "27f632dc3c82448daf320b1a64a6b7bf"
          ]
        },
        "id": "qWTLq8F-KS12",
        "outputId": "fcdef93e-c04c-41a2-9d5d-18251c958955"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33ccf2b656a1423d86978b46987a2c27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 7: Define Optimizer and Loss Function**\n",
        "   - **What Happens**:\n",
        "     - We use the **AdamW optimizer**, a variant of the Adam optimizer, which is optimized for handling weight decay (important in transformer models like BERT).\n",
        "     - **CrossEntropyLoss** is used as the loss function for multi-class classification, where the model learns to minimize the difference between predicted and actual POS tag labels.\n",
        "   - **Purpose**:\n",
        "     - These components are essential for training. The optimizer updates the model weights based on the calculated loss, while the loss function measures how well the model's predictions match the actual POS tags.\n"
      ],
      "metadata": {
        "id": "NVh4qfyAK2pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()  # CrossEntropyLoss for classification\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwJKNgZtKSzB",
        "outputId": "b1210597-47da-4518-90e8-78acc63b164f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 8: Training Loop**\n",
        "   - **What Happens**:\n",
        "     - The training process runs for **3 epochs**. For each batch of input sentences:\n",
        "       1. The model makes predictions for the POS tags of each word in the sentence.\n",
        "       2. The **loss** is computed by comparing the model's predictions to the actual POS tags.\n",
        "       3. The loss is **backpropagated**, and the optimizer updates the model's parameters.\n",
        "   - **Purpose**:\n",
        "     - This loop trains the BERT model on the toy dataset. The model improves its POS tag predictions by learning from its mistakes and updating its weights."
      ],
      "metadata": {
        "id": "Zu85pVb6K3UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Training loop (simplified for toy dataset)\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in toy_loader:\n",
        "        optimizer.zero_grad()  # Zero gradients\n",
        "\n",
        "        # Move batch to device (GPU or CPU)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss  # Loss is computed automatically\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()  # Backpropagate loss\n",
        "        optimizer.step()  # Update model weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(toy_loader)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luHI8AWMKb1R",
        "outputId": "ebba8adf-fd51-49fe-bedf-3c7eb7c48355"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 1.8704\n",
            "Epoch 2/3, Loss: 1.2648\n",
            "Epoch 3/3, Loss: 1.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 9: Testing on a New Sentence**\n",
        "   - **What Happens**:\n",
        "     - After training, the model is tested on a new sentence (`\"He loves coding\"`). The sentence is tokenized using the BERT tokenizer and passed through the trained model to predict the POS tags for each word.\n",
        "     - The predicted tag indices are then converted back to their original POS tags using the **LabelEncoder**.\n",
        "   - **Purpose**:\n",
        "     - This step demonstrates how the trained BERT model can be used for **inference** on new, unseen sentences. The model predicts POS tags for each word based on the patterns it learned during training.\n"
      ],
      "metadata": {
        "id": "3cSIR6TAK37B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Test the model on a new sentence\n",
        "test_sentence = \"He loves coding\"\n",
        "inputs = tokenizer(test_sentence, return_tensors='pt', padding=True, truncation=True, max_length=max_len)\n",
        "\n",
        "# Move inputs to the device (GPU or CPU)\n",
        "input_ids = inputs['input_ids'].to(device)\n",
        "attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "# Get model predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=2).squeeze().tolist()  # Get predicted tag indices\n",
        "\n",
        "# Convert indices back to POS tags using LabelEncoder\n",
        "predicted_tags = tag_encoder.inverse_transform(predictions[:len(test_sentence.split())])\n",
        "\n",
        "# Display the tagged sentence\n",
        "print(list(zip(test_sentence.split(), predicted_tags)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5-sp4CQKbvK",
        "outputId": "5e3681b8-3d6e-4a81-f53a-b0a3b7c2548f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'DT'), ('loves', 'DT'), ('coding', 'DT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HPCXl7Nz63Y"
      },
      "source": [
        "# Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sb1tOuuz60V"
      },
      "source": [
        "## Type of Taggers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24b84EoOz6xW"
      },
      "source": [
        "### **I. Traditional Taggers**\n",
        "\n",
        "Traditional taggers rely on simpler, rule-based, or probabilistic methods. These taggers work well for smaller datasets or situations where the structure of language is relatively simple. These taggers often require a lot of manual effort and fine-tuning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHuENW5Qz6ud"
      },
      "source": [
        "#### **1. Default Tagger**\n",
        "- Assigns the most common or default tag (e.g., 'NOUN') to every word.\n",
        "- Simple but not accurate for complex texts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkHGWA3Oz6sI"
      },
      "source": [
        "#### **2. Regular Expression Tagger**\n",
        "- Uses patterns in word morphology (e.g., words ending in 'ing' are often verbs) to assign tags.\n",
        "- Efficient for basic rule-based tagging but lacks contextual understanding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jFj4IFJz6ok"
      },
      "source": [
        "#### **3. Unigram Tagger**\n",
        "- Tags words based on their frequency in a training corpus.\n",
        "- Each word is tagged with the most frequent tag it was assigned in the training data.\n",
        "- Accurate for words seen in the training data but struggles with unseen words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBR9mEFwz6mI"
      },
      "source": [
        "#### **4. N-Gram Taggers (Bigram, Trigram, etc.)**\n",
        "- Uses sequences of words to predict tags, considering context in adjacent words (e.g., bigrams look at two-word pairs, trigrams at three).\n",
        "- Improves accuracy by using context but suffers from data sparsity and struggles with unseen data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoVo2LY_z6is"
      },
      "source": [
        "#### **5. Backoff Tagger**\n",
        "- Combines multiple taggers in sequence (e.g., unigram, bigram, and default tagger).\n",
        "- If a more complex tagger fails, it \"backs off\" to a simpler one (e.g., if the bigram tagger fails, it falls back to the unigram tagger).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th7d57UDwlUD"
      },
      "source": [
        "#### **6. Lookup Tagger**\n",
        "- **Definition**: A simple tagger that assigns tags based on a lookup table built from a training corpus.\n",
        "- **Functionality**: Words are tagged according to the most frequent tag they received in the training data.\n",
        "- **Use Case**: Similar to the unigram tagger but can be enhanced with additional lookup tables for specific cases.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE6hrCskwlQk"
      },
      "source": [
        "#### **7. Affix Tagger**\n",
        "- **Definition**: A tagger that assigns tags based on word suffixes or prefixes (e.g., words ending in \"ed\" are likely past-tense verbs).\n",
        "- **Use Case**: Useful in languages where affixes are highly indicative of word categories, such as in morphology-rich languages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JWnFClZz6f9"
      },
      "source": [
        "### **II. Advanced Taggers**\n",
        "\n",
        "Advanced taggers leverage more sophisticated statistical models and machine learning techniques. These taggers are often used for large datasets and complex language tasks, where traditional methods fall short.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU9rQNfhUB-W"
      },
      "source": [
        "#### **1. Transformation-Based Tagger (Brill Tagger)**\n",
        "- Learns a set of transformation rules to correct errors made by an initial tagger (e.g., default or unigram).\n",
        "- Iteratively improves accuracy by learning from its mistakes.\n",
        "- Efficient and interpretable but requires a lot of computational iterations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUR44vXObjw6"
      },
      "source": [
        "#### **2. Hidden Markov Model (HMM) Tagger**\n",
        "- Uses probabilistic models to determine the most likely sequence of tags given a sequence of words.\n",
        "- Combines both the frequency of tags and the probability of transitioning between tags (Markov assumption).\n",
        "- Strong for structured, predictable sequences but limited by the Markov property (only considers short-range dependencies).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPhZCvztbjtP"
      },
      "source": [
        "#### **3. Maximum Entropy Tagger (MaxEnt)**\n",
        "- A machine learning method that estimates the conditional probability of a tag given a set of features.\n",
        "- Allows for the use of arbitrary features (e.g., surrounding words, word morphology).\n",
        "- More flexible than HMM and works well with domain-specific data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thBABXNnbjqk"
      },
      "source": [
        "#### **4. Conditional Random Fields (CRF)**\n",
        "- An extension of MaxEnt that models sequences of tags while considering the entire input sentence (global optimization).\n",
        "- More accurate than HMM because it doesnt rely on independence assumptions.\n",
        "- Computationally expensive but performs well in tasks with high dependencies between words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CnrG4S_bjn-"
      },
      "source": [
        "#### **5. Deep Learning-Based Taggers**\n",
        "   - **Recurrent Neural Networks (RNN) Tagger**\n",
        "     - Processes sequences of words, maintaining \"memory\" of previous words to tag the current word.\n",
        "     - Handles sequential data better than traditional statistical methods but struggles with long dependencies.\n",
        "     \n",
        "     - More discussed in section: https://colab.research.google.com/drive/16sJda7O_SYUEr4HoJRWMl_RCe12iPo5-#scrollTo=FXUNJO8_6MgT&line=1&uniqifier=1\n",
        "  \n",
        "  \n",
        "   - **LSTM (Long Short-Term Memory) Tagger**\n",
        "     - An advanced form of RNN that overcomes the vanishing gradient problem, enabling it to model long-range dependencies in sentences.\n",
        "     - Highly accurate for tasks involving long sequences of text.\n",
        "\n",
        "     - More discussed in section: https://colab.research.google.com/drive/16sJda7O_SYUEr4HoJRWMl_RCe12iPo5-#scrollTo=FXUNJO8_6MgT&line=1&uniqifier=1\n",
        "  \n",
        "   - **Transformer-Based Taggers (BERT, GPT, etc.)**\n",
        "     - Utilizes self-attention mechanisms to process the entire input sequence at once.\n",
        "     - Can capture both short- and long-range dependencies in text.\n",
        "     - State-of-the-art accuracy for many NLP tasks, including POS tagging.\n",
        "     \n",
        "     - More discussed in section: https://colab.research.google.com/drive/16sJda7O_SYUEr4HoJRWMl_RCe12iPo5-#scrollTo=AirIgpL4AVs3&line=1&uniqifier=1\n",
        "  \n",
        "Are these tagger differ only based on algorithm used and database, or is there any more difference we could find?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ70Zd6Nwusk"
      },
      "source": [
        "#### **6. Support Vector Machines (SVMs)**\n",
        "- **Definition**: A supervised learning algorithm that can be used for classification tasks, including POS tagging.\n",
        "- **Functionality**: SVMs find a hyperplane that best separates the data into classes (tags) by maximizing the margin between different classes.\n",
        "- **Use Case**: SVMs can be used in POS tagging to predict the part of speech of a word based on features like its neighboring words, suffixes, or prefixes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ8PoUVXwwfC"
      },
      "source": [
        "#### **7. Neural CRF (Conditional Random Fields + Neural Networks)**\n",
        "- **Definition**: A hybrid model that combines the sequential nature of CRF with the feature learning capabilities of neural networks (e.g., using LSTM or CNN layers to automatically learn features).\n",
        "- **Functionality**: Instead of manually defining features, this tagger learns features using neural networks and applies CRF to label sequences.\n",
        "- **Use Case**: Widely used in modern NLP tasks like POS tagging, Named Entity Recognition (NER), and other sequence labeling tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9iXNr8gwwbj"
      },
      "source": [
        "#### **8. BERT-Based Tagger (Bidirectional Encoder Representations from Transformers)**\n",
        "- **Definition**: BERT is a pre-trained transformer-based model that captures context by reading text bidirectionally, i.e., from both the left and right contexts of each word.\n",
        "- **Functionality**: It can be fine-tuned for specific tagging tasks like POS tagging by adding a simple classification head to the pre-trained model.\n",
        "- **Use Case**: BERT is now the go-to model for high-accuracy NLP tasks, including POS tagging, and offers state-of-the-art results on many benchmarks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOShl0VOweK3"
      },
      "source": [
        "### **III. Hybrid Taggers**\n",
        "\n",
        "#### **1. Rule-Based + Statistical Hybrid Tagger**\n",
        "- **Definition**: Combines rule-based systems (which can handle exceptions well) with statistical methods (which generalize well to unseen data).\n",
        "- **Functionality**: Rules are used to tag simple and frequent cases, while statistical models handle more complex, ambiguous cases.\n",
        "- **Use Case**: Common in industrial NLP applications where interpretability and high accuracy are equally important.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IAclDzww6sP"
      },
      "source": [
        "\n",
        "#### **2. Machine Learning + Deep Learning Hybrid**\n",
        "- **Definition**: Combines machine learning algorithms like SVM or CRF with deep learning-based embeddings (e.g., using word embeddings from BERT or GloVe).\n",
        "- **Functionality**: The machine learning model makes the final prediction based on features generated by a deep learning model.\n",
        "- **Use Case**: Used when there is a need to leverage the feature-learning power of deep models while retaining the simplicity and speed of classical models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxUBo-zxQ2L"
      },
      "source": [
        "## Research Perspective\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZrDDcESxQyq"
      },
      "source": [
        "### **I. Transfer Learning and Pretrained Models**\n",
        "\n",
        "- **Pretrained Models for Tagging**: Research is increasingly focused on **transfer learning** approaches using large, pretrained models like **BERT**, **GPT**, **T5**, and **XLNet**. These models are trained on vast amounts of text data and can be fine-tuned for downstream tasks like POS tagging. In addition to providing high accuracy, these models significantly reduce the need for task-specific data.\n",
        "  \n",
        "  - **Research Impact**: The use of transfer learning has led to state-of-the-art performance on many NLP tasks, including POS tagging. The ability of these models to understand both word-level and sentence-level context is far superior to traditional taggers.\n",
        "  \n",
        "  - **Gaps**: Research is still ongoing to make these models more computationally efficient (e.g., through model pruning, quantization, and distillation).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-X6VGrlxQv3"
      },
      "source": [
        "### **II. Multilingual and Cross-lingual POS Tagging**\n",
        "\n",
        "- **Multilingual Taggers**: There is a growing research trend in developing POS taggers that work across multiple languages. Tools like **XLM-Roberta** and **mBERT** (Multilingual BERT) are capable of tagging sentences in multiple languages without requiring language-specific models. These models perform transfer learning across languages and are useful for tasks in under-resourced languages where annotated corpora are scarce.\n",
        "\n",
        "  - **Research Impact**: Multilingual models enable cross-lingual transfer, allowing POS taggers to be applied to languages with little or no annotated data. Research in this area is looking into improving cross-lingual alignment, domain adaptation, and handling language-specific nuances.\n",
        "\n",
        "  - **Challenges**: There's ongoing research into improving accuracy in low-resource languages and addressing syntactic and morphological differences between languages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUBKxDZLxQtb"
      },
      "source": [
        "### **III. Zero-Shot and Few-Shot Learning for POS Tagging**\n",
        "\n",
        "- **Zero-Shot/Few-Shot Learning**: With the rise of pretrained models, researchers are exploring ways to perform **zero-shot** or **few-shot learning** for POS tagging, where models are required to tag sentences with little or no task-specific training data. This involves leveraging general-purpose language models and adapting them to new tasks with minimal examples.\n",
        "\n",
        "  - **Research Impact**: These approaches are critical for developing NLP systems in languages or domains where data is scarce. They allow for faster deployment of POS taggers without the need for extensive annotated datasets.\n",
        "\n",
        "  - **Challenges**: Current models still struggle with complex linguistic structures and domain-specific terminology, and research is ongoing to improve the generalization capabilities of zero-shot models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVElIlRFxQq0"
      },
      "source": [
        "### **IV. Robustness and Domain Adaptation**\n",
        "\n",
        "- **Domain Adaptation**: Research in **domain adaptation** aims to develop POS taggers that can generalize across different domains (e.g., news, social media, legal text). While traditional taggers may perform well on the corpus they are trained on, they often fail to generalize to new domains with different vocabularies and syntactic structures.\n",
        "  \n",
        "  - **Research Approaches**: Researchers are exploring adversarial learning, domain-specific fine-tuning, and self-training techniques to make POS taggers more robust across domains.\n",
        "\n",
        "  - **Challenges**: Domain adaptation often requires balancing between overfitting to a specific domain and maintaining general performance across varied datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGS1wLchxQj5"
      },
      "source": [
        "### **V. Semi-supervised and Unsupervised Tagging**\n",
        "\n",
        "- **Semi-supervised Learning**: In cases where annotated data is scarce, semi-supervised learning techniques are employed to leverage large amounts of unlabeled data. Methods like **self-training**, **co-training**, or **EM algorithms** are used to iteratively improve tagging performance by training on both labeled and unlabeled corpora.\n",
        "\n",
        "  - **Research Impact**: Semi-supervised methods allow for improved POS tagging performance without the need for extensive manual annotations. These methods are useful in low-resource languages or domains with limited labeled data.\n",
        "\n",
        "  - **Challenges**: One of the main challenges is ensuring that the model does not propagate errors during self-training, which can degrade performance over time.\n",
        "\n",
        "- **Unsupervised Learning**: Research into **unsupervised POS tagging** seeks to tag words without using any labeled data. Methods like **clustering** (e.g., clustering similar words based on co-occurrence) or **Bayesian models** (e.g., the Hidden Markov Model with unsupervised learning) are often employed.\n",
        "\n",
        "  - **Research Impact**: Unsupervised methods are promising for languages or domains where no annotated data is available. However, they generally underperform compared to supervised or semi-supervised models.\n",
        "\n",
        "  - **Challenges**: The accuracy of unsupervised taggers is typically lower than that of supervised models. Research is ongoing to integrate more linguistic knowledge into these models to improve their performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJvL9EMixQgk"
      },
      "source": [
        "### **VI. Low-Resource and Indigenous Languages**\n",
        "\n",
        "- **POS Tagging for Low-Resource Languages**: Another important research area focuses on developing POS tagging systems for **low-resource and indigenous languages**. The lack of large-scale corpora and annotated datasets for these languages presents significant challenges.\n",
        "\n",
        "  - **Research Solutions**: Approaches such as **cross-lingual transfer learning**, **active learning**, and **data augmentation** are being researched to tackle the lack of data. Researchers are also focusing on developing unsupervised or weakly supervised methods that rely less on large annotated corpora.\n",
        "\n",
        "  - **Challenges**: Capturing linguistic nuances in low-resource languages (which may have complex morphology or syntax) requires further research into language-specific models and hybrid approaches.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5PxN63hxlcx"
      },
      "source": [
        "### **VII. Evaluation Metrics and Bias Detection**\n",
        "\n",
        "- **Evaluation Beyond Accuracy**: Traditional evaluation metrics like **accuracy** or **F1-score** are still important, but researchers are increasingly concerned with **robustness** and **fairness** in tagging systems. Models that perform well on benchmark datasets may not generalize well to noisy, real-world data or may exhibit biases in tagging based on gender, race, or dialects.\n",
        "\n",
        "  - **Research Focus**: Developing more comprehensive evaluation metrics that assess how well models perform in diverse, real-world scenarios. Researchers are also working on methods for detecting and mitigating bias in POS taggers, ensuring that models work fairly across different populations and text genres.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8N0kS9zxl5V"
      },
      "source": [
        "### **VIII. Explainability in Tagging Systems**\n",
        "\n",
        "- **Explainability of POS Tagging Systems**: As models become more complex (especially deep learning-based models), the demand for **explainable AI** (XAI) in POS tagging has grown. Researchers are exploring ways to make the decision-making process of taggers more interpretable to humans.\n",
        "\n",
        "  - **Research Focus**: Techniques such as **attention mechanisms**, **feature importance**, and **layer-wise relevance propagation** are being investigated to provide insights into why a model assigned a particular tag. This is crucial in applications where transparency and accountability are important.\n",
        "\n",
        "  - **Challenges**: Balancing model complexity (for better performance) with explainability remains an open challenge. Explainability methods often add computational overhead and may still lack full transparency.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPcz43YpFN9yHS0ZRqCwiuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b9aedd495e046d6b10de09f9f58c7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_073deba89f2d415fae415e8ae9285ea5",
              "IPY_MODEL_c8858ed327aa4bc08aa5ff28801ba18d",
              "IPY_MODEL_1c34191c442044dd9aa0c7c6f7a9b7ce"
            ],
            "layout": "IPY_MODEL_343857d6eec74270b9313a61e2fa3645"
          }
        },
        "073deba89f2d415fae415e8ae9285ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_823b862c32d04cbda5e657656c26fdf3",
            "placeholder": "",
            "style": "IPY_MODEL_5b8cc32b3f5c43648da9b6a66e0784ba",
            "value": "tokenizer_config.json:100%"
          }
        },
        "c8858ed327aa4bc08aa5ff28801ba18d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a42067aca0c74c7e97618ca4ad908e64",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99243252f98e4f43a6d56f71dc1d5855",
            "value": 49
          }
        },
        "1c34191c442044dd9aa0c7c6f7a9b7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c52b1b54c8c4c58a043cc6c81fa93a2",
            "placeholder": "",
            "style": "IPY_MODEL_a89d589ed12447ff88fd01ba677f5837",
            "value": "49.0/49.0[00:00&lt;00:00,2.01kB/s]"
          }
        },
        "343857d6eec74270b9313a61e2fa3645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823b862c32d04cbda5e657656c26fdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b8cc32b3f5c43648da9b6a66e0784ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a42067aca0c74c7e97618ca4ad908e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99243252f98e4f43a6d56f71dc1d5855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c52b1b54c8c4c58a043cc6c81fa93a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89d589ed12447ff88fd01ba677f5837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7a7c53de780405b9dae1f446a58fb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba87aea1bc154ad4b9032d14ade9752c",
              "IPY_MODEL_c8912f8a5bf5496e90ce72d466c547ea",
              "IPY_MODEL_1fca463f5693409287a549b78f25cf0f"
            ],
            "layout": "IPY_MODEL_5b44745b6dad455facb9d2ee8ebdb2e4"
          }
        },
        "ba87aea1bc154ad4b9032d14ade9752c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b826c0fc7d401e8ca2b12f77cda360",
            "placeholder": "",
            "style": "IPY_MODEL_fbfa226348d44e7caae68e556e14c125",
            "value": "vocab.txt:100%"
          }
        },
        "c8912f8a5bf5496e90ce72d466c547ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87815ee3ab9242f98f09fd8d045d34f1",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c50998a7dac3482eb184e2d157d0b388",
            "value": 213450
          }
        },
        "1fca463f5693409287a549b78f25cf0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c0bc07281f41e1a006b31e9e7504ea",
            "placeholder": "",
            "style": "IPY_MODEL_ffc6cdcd048b469a88f9ff1e50992144",
            "value": "213k/213k[00:00&lt;00:00,5.61MB/s]"
          }
        },
        "5b44745b6dad455facb9d2ee8ebdb2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b826c0fc7d401e8ca2b12f77cda360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfa226348d44e7caae68e556e14c125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87815ee3ab9242f98f09fd8d045d34f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50998a7dac3482eb184e2d157d0b388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51c0bc07281f41e1a006b31e9e7504ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffc6cdcd048b469a88f9ff1e50992144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04995525a9d240cdafe83c7de005bf32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3719f9cacbb449adad6a89c840d47332",
              "IPY_MODEL_cd7f7a27ff02400393279f108fffe5fc",
              "IPY_MODEL_3788016aa2ca48c28250199e8de701d6"
            ],
            "layout": "IPY_MODEL_432a643f7dd34f40a24e121c69f1b8c6"
          }
        },
        "3719f9cacbb449adad6a89c840d47332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624b489d59a342f08fd0d6503f9c9dfe",
            "placeholder": "",
            "style": "IPY_MODEL_7319a7bdfda04e71ba559209797cb71e",
            "value": "tokenizer.json:100%"
          }
        },
        "cd7f7a27ff02400393279f108fffe5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019655241d134f329223f7d025bacb7b",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d2895eaf5384b7e88ff7cdad55450f3",
            "value": 435797
          }
        },
        "3788016aa2ca48c28250199e8de701d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_792db2ba7b6844e7a67edf469be7f28a",
            "placeholder": "",
            "style": "IPY_MODEL_d481d11a62cb4176991500d4a06d1aa7",
            "value": "436k/436k[00:00&lt;00:00,18.6MB/s]"
          }
        },
        "432a643f7dd34f40a24e121c69f1b8c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624b489d59a342f08fd0d6503f9c9dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7319a7bdfda04e71ba559209797cb71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019655241d134f329223f7d025bacb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2895eaf5384b7e88ff7cdad55450f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "792db2ba7b6844e7a67edf469be7f28a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d481d11a62cb4176991500d4a06d1aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee45bb15a57a40c588a7895632f640d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e16845fdf404d6c956aa048d639a92f",
              "IPY_MODEL_e4e22050efe740b79abe2e3cb131382f",
              "IPY_MODEL_e68fc25b0e634d09a8266da5791756fc"
            ],
            "layout": "IPY_MODEL_b68461e8fc5c493e93f948a00f88ae74"
          }
        },
        "2e16845fdf404d6c956aa048d639a92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbefd3acd5b4962b85188c570f7e781",
            "placeholder": "",
            "style": "IPY_MODEL_e45faeb9cb454bc79724bd53d5f9b625",
            "value": "config.json:100%"
          }
        },
        "e4e22050efe740b79abe2e3cb131382f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83f0664cc3524a2dbb8f4f2d101307e0",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec41f264c2be48cca2a206a331abf152",
            "value": 570
          }
        },
        "e68fc25b0e634d09a8266da5791756fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0499f27d0544b8794d98d2ead2ebe4e",
            "placeholder": "",
            "style": "IPY_MODEL_f9cec975227c4302a0326410a92c56ea",
            "value": "570/570[00:00&lt;00:00,22.9kB/s]"
          }
        },
        "b68461e8fc5c493e93f948a00f88ae74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbefd3acd5b4962b85188c570f7e781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45faeb9cb454bc79724bd53d5f9b625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83f0664cc3524a2dbb8f4f2d101307e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec41f264c2be48cca2a206a331abf152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0499f27d0544b8794d98d2ead2ebe4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9cec975227c4302a0326410a92c56ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33ccf2b656a1423d86978b46987a2c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e521b324997445b8b541eaa5ab03e175",
              "IPY_MODEL_a8a6eb16115544148fc5ee42fc1dd1b4",
              "IPY_MODEL_045967dae9e9416daa4c93c9c4a3ab2e"
            ],
            "layout": "IPY_MODEL_5bd769ad1d054ec081b31fae16473f18"
          }
        },
        "e521b324997445b8b541eaa5ab03e175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a0ebe833914c2dba47d6905899677a",
            "placeholder": "",
            "style": "IPY_MODEL_7a35bac0792d457895412f1eeb5362ad",
            "value": "model.safetensors:100%"
          }
        },
        "a8a6eb16115544148fc5ee42fc1dd1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f12d8cfe04045a5bee1d0a7e7dab8fe",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b60f3080aef74b9fbc6529af0adc0726",
            "value": 435755784
          }
        },
        "045967dae9e9416daa4c93c9c4a3ab2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e3bff6a9f348428b502f871ff61b3a",
            "placeholder": "",
            "style": "IPY_MODEL_27f632dc3c82448daf320b1a64a6b7bf",
            "value": "436M/436M[00:06&lt;00:00,31.5MB/s]"
          }
        },
        "5bd769ad1d054ec081b31fae16473f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a0ebe833914c2dba47d6905899677a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a35bac0792d457895412f1eeb5362ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f12d8cfe04045a5bee1d0a7e7dab8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60f3080aef74b9fbc6529af0adc0726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46e3bff6a9f348428b502f871ff61b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f632dc3c82448daf320b1a64a6b7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}