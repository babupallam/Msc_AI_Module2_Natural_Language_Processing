{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMAarJ9Ig7kqvVe6Tg7lEru"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Chunking is an essential part of natural language processing (NLP) for grouping tokens into meaningful units. Advanced chunking involves not only handling basic chunks but also managing more complex structures and dealing with multi-layered linguistic features. This section explores advanced chunking and nested structures, which are critical for handling complex text, such as hierarchical relationships in language.\n","\n"],"metadata":{"id":"vHK4XDeIy1qp"}},{"cell_type":"markdown","source":["### 7.1 Introduction to Advanced Chunking\n","\n","- **Definition**: Advanced chunking is the process of using sophisticated methods to chunk text, enabling the detection of both simple and nested structures in sentences.\n","- **Purpose**: To extend basic chunking techniques and identify deeper linguistic relationships.\n","- **Challenges**: Handling overlapping chunks, nested structures, and maintaining accuracy while increasing complexity.\n","\n"],"metadata":{"id":"82QPZDLxy1t0"}},{"cell_type":"markdown","source":["### 7.2 Cascaded Chunking\n","\n","#### 7.2.1 Multi-Level Chunkers\n","\n","- **Concept**: Cascaded chunking involves creating multiple layers of chunkers that sequentially identify various types of linguistic phrases. For example, multi-level chunkers can be used in extracting hierarchical information in medical texts, such as identifying symptoms, diagnoses, and treatments in clinical reports. Each layer focuses on a specific type, such as noun phrases, verb phrases, or prepositional phrases.\n","  - **Observation**: This hierarchical approach enables more fine-grained extraction of linguistic structures, providing better context representation.\n","  - **Code Demonstration**: Demonstrate a multi-level chunker in NLTK to first chunk noun phrases, followed by prepositional phrases.\n"],"metadata":{"id":"IuikgTvEy1v1"}},{"cell_type":"code","source":["import nltk  # Importing the NLTK (Natural Language Toolkit) library.\n","from nltk import RegexpParser  # Importing the RegexpParser to create chunk parsers using regular expressions.\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","\n","# Sample text to process.\n","text = \"The quick brown fox jumps over the lazy dog.\"\n","\n","# Tokenizing the text into individual words and assigning part-of-speech (POS) tags to each token.\n","# 'nltk.word_tokenize' splits the text into tokens (words), and 'nltk.pos_tag' assigns POS tags (e.g., DT for determiner, NN for noun).\n","tokens = nltk.pos_tag(nltk.word_tokenize(text))\n","\n","# Defining a grammar rule for noun phrases (NP).\n","# This rule matches optional determiners (DT), followed by zero or more adjectives (JJ*), and a noun (NN).\n","grammar_np = \"NP: {<DT>?<JJ>*<NN>}\"\n","\n","# Creating a RegexpParser object to find noun phrases based on the grammar.\n","chunker_np = RegexpParser(grammar_np)\n","\n","# Parsing the tokenized and POS-tagged sentence to identify noun phrases.\n","chunked_np = chunker_np.parse(tokens)\n","\n","# Defining a grammar rule for prepositional phrases (PP).\n","# A prepositional phrase typically starts with a preposition (IN) followed by a noun phrase (NP).\n","grammar_pp = \"PP: {<IN><NP>}\"\n","\n","# Creating a new RegexpParser object to find prepositional phrases based on the grammar.\n","chunker_pp = RegexpParser(grammar_pp)\n","\n","# Parsing the previously chunked noun phrases to also find prepositional phrases.\n","chunked_pp = chunker_pp.parse(chunked_np)\n","\n","# Printing the tree structure of the chunked sentence, which shows the identified noun and prepositional phrases.\n","print(chunked_pp)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8yBDD0yxzRq6","executionInfo":{"status":"ok","timestamp":1728838666100,"user_tz":-60,"elapsed":255,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"d851e50b-3219-4120-a6d7-77a89748b35e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (NP The/DT quick/JJ brown/NN)\n","  (NP fox/NN)\n","  jumps/VBZ\n","  (PP over/IN (NP the/DT lazy/JJ dog/NN))\n","  ./.)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["#### 7.2.2 Advantages of Cascaded Chunking\n","\n","- **Layered Processing**: Each level can correct or refine the output from the previous level.\n","- **Granular Control**: Facilitates better error handling and customization in chunking rules.\n","- **Code Demonstration**: Extend the previous code by adding a verb phrase (VP) chunker to capture verb and auxiliary verb patterns.\n"],"metadata":{"id":"bKg4bV_dy1yp"}},{"cell_type":"code","source":["# Install necessary libraries\n","import nltk\n","from nltk import RegexpParser\n","\n","# Make sure you have the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Example sentence for demonstration\n","sentence = \"The quick brown fox jumps over the lazy dog.\"\n","\n","# Tokenize and tag parts of speech\n","tokens = nltk.word_tokenize(sentence)\n","tagged = nltk.pos_tag(tokens)\n","\n","# Grammar rule to identify verb phrases (VP)\n","grammar_vp = \"VP: {<VB.*><NP|PP|RB>*}\"\n","\n","# Creating a RegexpParser object to identify verb phrases based on the grammar rule\n","chunker_vp = RegexpParser(grammar_vp)\n","\n","# Parsing the sentence to identify verb phrases\n","chunked_vp = chunker_vp.parse(tagged)\n","\n","# Print the tree structure of the chunked sentence, including the identified verb phrases\n","print(chunked_vp)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04UQ2Y5czXH9","executionInfo":{"status":"ok","timestamp":1728838873954,"user_tz":-60,"elapsed":311,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"d8b8b3d5-b993-4be1-9f3a-b65d2c9d8fff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  The/DT\n","  quick/JJ\n","  brown/NN\n","  fox/NN\n","  (VP jumps/VBZ)\n","  over/IN\n","  the/DT\n","  lazy/JJ\n","  dog/NN\n","  ./.)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}]},{"cell_type":"markdown","source":["### 7.3 Recursive Chunking\n","\n","- **Definition**: Recursive chunking, also called nested chunking, involves detecting chunks within chunks, such as parsing nested noun phrases in legal documents where phrases may contain multiple layers of embedded information. leading to hierarchical structures.\n","- **Use Cases**: Useful in extracting nested noun phrases, such as \"[The quick brown fox [with [a bushy tail]]].\"\n","- **Observation**: Recursive chunking allows for a more detailed representation of complex syntactic relationships within sentences.\n","\n"],"metadata":{"id":"HohTa8Xiy12C"}},{"cell_type":"markdown","source":["#### 7.2.2 Advantages of Cascaded Chunking\n","\n","- **Layered Processing**: Each level can correct or refine the output from the previous level.\n","- **Granular Control**: Facilitates better error handling and customization in chunking rules.\n","- **Code Demonstration**: Extend the previous code by adding a verb phrase (VP) chunker to capture verb and auxiliary verb patterns.\n","\n"],"metadata":{"id":"WqPVTbsNzUGr"}},{"cell_type":"code","source":["# Grammar rule to identify verb phrases (VP).\n","# - <VB.*> matches any verb form (VB = base form, VBD = past tense, VBG = gerund, etc.).\n","# - <NP|PP|RB>* allows zero or more noun phrases (NP), prepositional phrases (PP), or adverbs (RB) following the verb.\n","#   This is flexible, as it can match many verb phrase structures, such as \"jumps quickly\", \"jumps over the dog\", etc.\n","grammar_vp = \"VP: {<VB.*><NP|PP|RB>*}\"\n","\n","# Creating a RegexpParser object to identify verb phrases using the defined grammar rule.\n","chunker_vp = RegexpParser(grammar_vp)\n","\n","# Parsing the previously chunked sentence (which includes noun phrases and prepositional phrases).\n","# Now, it will additionally identify and chunk verb phrases.\n","chunked_vp = chunker_vp.parse(chunked_pp)\n","\n","# Printing the full parse tree, which now includes verb phrases.\n","print(chunked_vp)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4jAEFqqzYYY","executionInfo":{"status":"ok","timestamp":1728838941149,"user_tz":-60,"elapsed":252,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"8ff80f77-1c36-4b71-9559-d1f5a28453f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (NP The/DT quick/JJ brown/NN)\n","  (NP fox/NN)\n","  (VP jumps/VBZ (PP over/IN (NP the/DT lazy/JJ dog/NN)))\n","  ./.)\n"]}]},{"cell_type":"markdown","source":["#### 7.3.1 Implementation of Recursive Chunking\n","\n","- **Approach**: Apply chunkers iteratively to handle deeper nested structures in sentences.\n","  - **Code Demonstration**: Use multiple passes to create a tree structure representing nested chunks.\n"],"metadata":{"id":"EDQPCw2uy14T"}},{"cell_type":"code","source":["# Sample text with a more complex structure, containing prepositional phrases that modify the noun.\n","nested_text = \"The quick brown fox with a bushy tail jumps over the lazy dog.\"\n","\n","# Tokenizing the text into individual words and assigning part-of-speech (POS) tags to each token.\n","tokens = nltk.pos_tag(nltk.word_tokenize(nested_text))\n","\n","# Grammar rule for identifying nested noun phrases (NPs).\n","# - <DT>? allows for an optional determiner.\n","# - <JJ>* allows for zero or more adjectives.\n","# - <NN> matches a noun.\n","# - (<IN><DT>?<JJ>*<NN>)* captures prepositional phrases (introduced by a preposition, IN) modifying the noun,\n","#   including their own determiner, adjectives, and noun structure.\n","grammar_nested_np = \"NP: {<DT>?<JJ>*<NN>(<IN><DT>?<JJ>*<NN>)*}\"\n","\n","# Creating a RegexpParser to identify nested noun phrases using the defined grammar rule.\n","chunker_nested_np = RegexpParser(grammar_nested_np)\n","\n","# Parsing the tokenized and POS-tagged sentence to identify nested noun phrases.\n","nested_chunked = chunker_nested_np.parse(tokens)\n","\n","# Printing the full parse tree of the sentence with the nested noun phrases identified.\n","print(nested_chunked)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufwV8gsCzY_W","executionInfo":{"status":"ok","timestamp":1728838977711,"user_tz":-60,"elapsed":268,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"c6bb6011-029a-40d7-93f6-e646352ef540"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (NP The/DT quick/JJ brown/NN)\n","  (NP fox/NN with/IN a/DT bushy/JJ tail/NN)\n","  jumps/NNS\n","  over/IN\n","  (NP the/DT lazy/JJ dog/NN)\n","  ./.)\n"]}]},{"cell_type":"markdown","source":["#### 7.3.2 Handling Complex Structures\n","\n","- **Observation**: Recursive chunking is prone to errors such as over-chunking or under-chunking due to ambiguity in sentence structure.\n","- **Techniques to Handle Complexity**:\n","  - **Feature Enrichment**: Using additional features such as POS tags, word embeddings, or dependency parsing to improve chunk detection.\n","  - **Post-Processing**: Apply rules after chunking to correct errors and remove ambiguities.\n","\n"],"metadata":{"id":"5FJpUI7sy169"}},{"cell_type":"markdown","source":["### 7.4 Chunking Nested Entities\n","\n"],"metadata":{"id":"zdS6nNuYy19t"}},{"cell_type":"markdown","source":["#### 7.4.1 Nested Named Entities\n","\n","- **Concept**: Extracting named entities that are nested within other entities, such as \"[ORG: [BBC News]] Headquarters.\"\n","- **Applications**: Biomedical texts, where entities like proteins and genes often appear within other named entities.\n","- **Code Demonstration**: Use SpaCy to extract nested named entities.\n"],"metadata":{"id":"0MpdiovUy2Ag"}},{"cell_type":"code","source":["import spacy  # Importing the spaCy library for Natural Language Processing (NLP).\n","\n","# Loading the small English NLP model in spaCy. This model includes capabilities such as part-of-speech tagging and Named Entity Recognition (NER).\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Processing the input text using the loaded spaCy model. This produces a Doc object, which contains linguistic annotations.\n","doc = nlp(\"BBC News headquarters is located in London.\")\n","\n","# Iterating over all the named entities (ents) in the Doc object.\n","# Named entities are pre-identified phrases in the text, such as organizations, locations, etc.\n","for ent in doc.ents:\n","    # Printing the entity's text and its label (the type of entity, such as 'ORG' for organization or 'GPE' for geographical entity).\n","    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n","\n","    # For each token (word) within the named entity, check its type.\n","    for token in ent:\n","        # If the token has an entity type, print the nested token and its entity type.\n","        # This can be useful if the entity contains multiple tokens (e.g., \"BBC News\" or \"New York\").\n","        if token.ent_type_:\n","            print(f\" - Nested Token: {token.text}, Type: {token.ent_type_}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCjUzPtWzaMd","executionInfo":{"status":"ok","timestamp":1728839018694,"user_tz":-60,"elapsed":9768,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"3243e996-97db-4163-c42d-15b505cb3e7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: BBC News, Label: ORG\n"," - Nested Token: BBC, Type: ORG\n"," - Nested Token: News, Type: ORG\n","Entity: London, Label: GPE\n"," - Nested Token: London, Type: GPE\n"]}]},{"cell_type":"markdown","source":["#### 7.4.2 Challenges in Extracting Nested Entities\n","\n","- **Ambiguity**: Nested entities can lead to ambiguity, particularly when entities belong to overlapping classes (e.g., \"University of [ORG: California]\"). Hierarchical tagging can help resolve this by ensuring each entity is tagged at the appropriate level of specificity. For example, in a legal document, an organization might be nested within a larger entity, and hierarchical tagging helps distinguish these layers effectively. (e.g., \"University of [ORG: California]\").\n","- **Approach to Resolve Ambiguity**:\n","  - **Hierarchical Tagging**: Assign tags in a hierarchical manner to avoid overlap.\n","  - **Code Demonstration**: Implement a tagging mechanism using conditional checks to determine if entities belong to multiple classes.\n"],"metadata":{"id":"3XEqAtxZy2Dl"}},{"cell_type":"code","source":["# Iterating over all the named entities (ents) in the SpaCy Doc object.\n","for ent in doc.ents:\n","    # Checking if the entity label includes \"ORG\" (which stands for organizations).\n","    # This will print out any entities that are recognized as organizations.\n","    if \"ORG\" in ent.label_:\n","        print(f\"Organization Entity: {ent.text}\")\n","\n","    # Checking if the entity label includes \"GPE\" (which stands for Geopolitical Entity, i.e., countries, cities, etc.).\n","    # This will print out any entities recognized as geographical locations.\n","    elif \"GPE\" in ent.label_:\n","        print(f\"Geopolitical Entity: {ent.text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AI_Pezi-zapk","executionInfo":{"status":"ok","timestamp":1728839033765,"user_tz":-60,"elapsed":256,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"cd2981e6-bc59-4090-b640-ca60d2fa6000"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Organization Entity: BBC News\n","Geopolitical Entity: London\n"]}]},{"cell_type":"markdown","source":["### 7.5 Handling Overlapping Chunks\n","\n","- **Definition**: Overlapping chunks are segments of text that belong to more than one chunk category, resulting in overlapping spans. leading to overlapping spans.\n","- **Techniques to Handle Overlapping**:\n","  - **Chunk Pruning**: Prune chunks to ensure only one chunk type is assigned to a specific span of text.\n","  - **Voting Mechanism**: Use a voting system from multiple chunkers to determine the final chunk label.\n","\n"],"metadata":{"id":"YYekKleVy2GY"}},{"cell_type":"markdown","source":["#### 7.5.1 Overlapping Chunk Detection and Resolution\n","\n","- **Code Demonstration**: Use custom logic to detect overlaps and determine the appropriate chunk based on predefined rules.\n"],"metadata":{"id":"OHc_MpY_y2I-"}},{"cell_type":"code","source":["# Sample sentence that includes both noun phrases (NP) and prepositional phrases (PP), potentially overlapping.\n","sentence = \"The tall building in New York City.\"\n","\n","# Tokenizing the sentence and assigning part-of-speech (POS) tags.\n","tokens = nltk.pos_tag(nltk.word_tokenize(sentence))\n","\n","# Defining a grammar that captures both noun phrases (NP) and prepositional phrases (PP).\n","# - NP: Noun phrases consisting of an optional determiner (<DT>?), zero or more adjectives (<JJ>*), and a noun (<NN>).\n","# - PP: Prepositional phrases that consist of a preposition (<IN>) followed by a noun phrase (<NP>).\n","grammar_overlap = \"\"\"\n","NP: {<DT>?<JJ>*<NN>}   # Noun Phrase\n","PP: {<IN><NP>}         # Prepositional Phrase\n","\"\"\"\n","\n","# Creating a RegexpParser to chunk the sentence using the defined grammar.\n","overlap_chunker = RegexpParser(grammar_overlap)\n","\n","# Parsing the tokenized sentence, producing a tree structure of chunks (including potential overlaps).\n","chunked_overlap = overlap_chunker.parse(tokens)\n","\n","# Iterating through the resulting chunks (subtrees) in the parsed sentence.\n","# This part resolves the overlaps by identifying and printing the dominant chunks.\n","for subtree in chunked_overlap:\n","    # Check if the subtree is an actual chunk (i.e., a Tree object in NLTK).\n","    if isinstance(subtree, nltk.Tree):\n","        # Printing the type of the chunk (NP or PP) and the words it contains.\n","        print(f\"Chunk Type: {subtree.label()}, Text: {' '.join(word for word, tag in subtree.leaves())}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8klpvyHPzbHW","executionInfo":{"status":"ok","timestamp":1728839078653,"user_tz":-60,"elapsed":254,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"7467cf89-5f65-47c4-96b9-c501513f5f28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Chunk Type: NP, Text: The tall building\n"]}]},{"cell_type":"markdown","source":["### 7.6 Challenges in Advanced Chunking\n","\n","- **Ambiguity and Complexity**: More complex grammatical structures, such as subordinate clauses or appositives, lead to ambiguities in chunk boundaries.\n","- **Scalability**: As sentences become longer and more complex, the computational cost of chunking increases.\n","- **Code Demonstration**: Measure the complexity of chunking using a timing function to assess performance on large texts.\n"],"metadata":{"id":"FTlTB5vQy2Lw"}},{"cell_type":"code","source":["import time  # Importing the time module to measure the execution time.\n","\n","# Sample long text to tokenize and chunk.\n","long_text = \"The quick brown fox jumped over the lazy dog multiple times. The dog, however, remained indifferent.\"\n","\n","# Tokenizing the text and assigning part-of-speech (POS) tags to each token.\n","tokens = nltk.pos_tag(nltk.word_tokenize(long_text))\n","\n","# Recording the start time before chunking begins.\n","start_time = time.time()\n","\n","# Chunking the tokenized text using a previously defined chunker (in this case, 'chunker_np').\n","# This assumes you have already defined 'chunker_np' earlier (for noun phrase chunking, for example).\n","chunked_long = chunker_np.parse(tokens)\n","\n","# Recording the end time after chunking is completed.\n","end_time = time.time()\n","\n","# Calculating and printing the time taken to perform the chunking process.\n","# The time difference (end_time - start_time) gives the elapsed time, which is formatted to 2 decimal places.\n","print(f\"Time taken to chunk: {end_time - start_time:.2f} seconds\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8c2iP-2zcPO","executionInfo":{"status":"ok","timestamp":1728839108189,"user_tz":-60,"elapsed":262,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"835d5f80-d48a-438d-e17a-cc9d56d37abd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Time taken to chunk: 0.00 seconds\n"]}]},{"cell_type":"markdown","source":["### 7.7 Applications of Advanced Chunking\n","\n","- **Information Extraction**: Extracting key information such as named entities, relationships, and nested facts from unstructured data.\n","- **Question Answering**: Leveraging chunked and nested structures to identify precise answers in response to user queries.\n","- **Text Summarization**: Using hierarchical chunk structures to summarize documents by extracting key phrases and their relationships.\n","\n"],"metadata":{"id":"QbXn6ekOy2Ok"}},{"cell_type":"markdown","source":["#### 7.7.1 Use Case Demonstration: Information Extraction\n","\n","- **Code Demonstration**: Extract nested entities to build a knowledge base.\n"],"metadata":{"id":"tWpp_W62y2RV"}},{"cell_type":"code","source":["# An empty list to store extracted entities (i.e., noun phrases) from the text.\n","knowledge_base = []\n","\n","# Sample text that includes multiple noun phrases like \"Barack Obama\", \"former president\", \"United States\", and \"Honolulu\".\n","text = \"Barack Obama, the former president of the United States, was born in Honolulu.\"\n","\n","# Tokenizing the text and assigning part-of-speech (POS) tags to each token.\n","tokens = nltk.pos_tag(nltk.word_tokenize(text))\n","\n","# Defining a grammar to chunk noun phrases (NP).\n","# - <DT>? : Optional determiner (e.g., \"the\").\n","# - <JJ>* : Zero or more adjectives (e.g., \"former\", \"quick\").\n","# - <NN.*>: Noun (e.g., \"president\", \"United States\"). The .* allows for any noun type (singular/plural).\n","nested_chunk_grammar = \"NP: {<DT>?<JJ>*<NN.*>}\"\n","\n","# Creating a RegexpParser object to chunk the sentence based on the defined grammar.\n","nested_chunker = RegexpParser(nested_chunk_grammar)\n","\n","# Parsing the tokenized sentence to identify and chunk noun phrases (NPs).\n","chunked_entities = nested_chunker.parse(tokens)\n","\n","# Iterating through the chunks (subtrees) in the chunked sentence.\n","for subtree in chunked_entities:\n","    # Checking if the subtree is a noun phrase (NP) chunk.\n","    if isinstance(subtree, nltk.Tree) and subtree.label() == 'NP':\n","        # Extracting the words that form the noun phrase by joining the individual words in the chunk.\n","        entity = \" \".join([word for word, pos in subtree.leaves()])\n","        # Adding the extracted noun phrase entity to the knowledge base list.\n","        knowledge_base.append(entity)\n","\n","# Printing the extracted noun phrases that have been stored in the knowledge base.\n","print(f\"Extracted Entities: {knowledge_base}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_7zR0OSzduQ","executionInfo":{"status":"ok","timestamp":1728839143665,"user_tz":-60,"elapsed":242,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"4b46ab7c-ccd8-445e-918e-3708c1bd78f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Entities: ['Barack', 'Obama', 'the former president', 'the United', 'States', 'Honolulu']\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"QsleAwOUy2Ue"}},{"cell_type":"markdown","source":[],"metadata":{"id":"OIi6nUnhy2X2"}}]}