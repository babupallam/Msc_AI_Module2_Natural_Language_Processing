{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSNzth+Lfs4X5zSzmSgQAZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"608c7b83610e4d9a85295b3cd91caa15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a76a3e22795948aca31d70db7dfc12a2","IPY_MODEL_7ed0e5d583394d318dfedab94d85d2b4","IPY_MODEL_b1e3ad302ecf408bae0e0690af2b5b04"],"layout":"IPY_MODEL_16628b280b4c4a59a5be79010b7c2319"}},"a76a3e22795948aca31d70db7dfc12a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_464fb080a3df4b35a57ce05ff3856b8f","placeholder":"​","style":"IPY_MODEL_86cf8a7e5e0a498697c747454aff3754","value":"tokenizer_config.json: 100%"}},"7ed0e5d583394d318dfedab94d85d2b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_752feffa9f20453c8f628e4dacf61a2d","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c095147150e5417696d2f6099fa3c7f8","value":48}},"b1e3ad302ecf408bae0e0690af2b5b04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_849d00cdf6fa4b5080fad0bc34fc4c00","placeholder":"​","style":"IPY_MODEL_dbef52f42ac24d9abf44a9a12854eca9","value":" 48.0/48.0 [00:00&lt;00:00, 1.33kB/s]"}},"16628b280b4c4a59a5be79010b7c2319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"464fb080a3df4b35a57ce05ff3856b8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86cf8a7e5e0a498697c747454aff3754":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"752feffa9f20453c8f628e4dacf61a2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c095147150e5417696d2f6099fa3c7f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"849d00cdf6fa4b5080fad0bc34fc4c00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbef52f42ac24d9abf44a9a12854eca9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38411d40b7274862b25c7d91664e6d80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2278bbe7ecb4d279b9d9612b248c5bf","IPY_MODEL_a84eeb422954454caa8aa554b006926d","IPY_MODEL_b4c7022361084f7e94d18c6cfde3ef15"],"layout":"IPY_MODEL_356e0801679e402ea78cdd964e66744b"}},"a2278bbe7ecb4d279b9d9612b248c5bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f4b4be247b34fbfbff6dc83c9296bcc","placeholder":"​","style":"IPY_MODEL_9ee35c60e5bc4dce920b61d7c319d397","value":"vocab.txt: 100%"}},"a84eeb422954454caa8aa554b006926d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cb71e29b5b949bebf140ebd5152cac7","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68eedf95eafe4c3299a25473fa3735d1","value":231508}},"b4c7022361084f7e94d18c6cfde3ef15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_888a400d121a40d291915b25ba7a21be","placeholder":"​","style":"IPY_MODEL_acd3c4b3434d4d578b037b18841c863e","value":" 232k/232k [00:00&lt;00:00, 3.89MB/s]"}},"356e0801679e402ea78cdd964e66744b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f4b4be247b34fbfbff6dc83c9296bcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ee35c60e5bc4dce920b61d7c319d397":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cb71e29b5b949bebf140ebd5152cac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68eedf95eafe4c3299a25473fa3735d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"888a400d121a40d291915b25ba7a21be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acd3c4b3434d4d578b037b18841c863e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60bef74257dc44e5ad9b9964fd8d8ca5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52f461d751664f6297fa197fa128f4fc","IPY_MODEL_44ba445e246545f0bacb62fa13deceb9","IPY_MODEL_8ed2b04f05e9413fa85a068ca5c0f0f3"],"layout":"IPY_MODEL_ed29b3f5c63b4483a578472b53433dfb"}},"52f461d751664f6297fa197fa128f4fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb0cca7bb9cf436a960ae0310b5a825b","placeholder":"​","style":"IPY_MODEL_15170563156f4f27bc8839f5a0f1d91b","value":"tokenizer.json: 100%"}},"44ba445e246545f0bacb62fa13deceb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95ec59b7ef9e449a8492dc2ed1ecf1b3","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fec8632ce7c846cdac99f53cbeffcbc0","value":466062}},"8ed2b04f05e9413fa85a068ca5c0f0f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c30180e18214a19a666dce9183229ce","placeholder":"​","style":"IPY_MODEL_ee9fb19d6ba34f30b5474c8449b9df22","value":" 466k/466k [00:00&lt;00:00, 10.4MB/s]"}},"ed29b3f5c63b4483a578472b53433dfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb0cca7bb9cf436a960ae0310b5a825b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15170563156f4f27bc8839f5a0f1d91b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ec59b7ef9e449a8492dc2ed1ecf1b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec8632ce7c846cdac99f53cbeffcbc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c30180e18214a19a666dce9183229ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee9fb19d6ba34f30b5474c8449b9df22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3424c26846994fd18d2080fa2947c112":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_088f51bb24b442e0b6dfe6e5be6198b3","IPY_MODEL_045ec34c09434c3598112908e26bdecc","IPY_MODEL_8646e4e9e00e48088dc2378a815fd4d5"],"layout":"IPY_MODEL_67dd03d82c87478b82a682ede50da41d"}},"088f51bb24b442e0b6dfe6e5be6198b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccb9b91680f64bc187cf1480b8c04d46","placeholder":"​","style":"IPY_MODEL_831f0529800946a9a5e407fcc5cd36dd","value":"config.json: 100%"}},"045ec34c09434c3598112908e26bdecc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1d4a5f09c3347a38d93df995ea2ddd9","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2401214c850341598014df97d00a1c75","value":570}},"8646e4e9e00e48088dc2378a815fd4d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5fb49eabdde45b893f457081866103f","placeholder":"​","style":"IPY_MODEL_144b9827cc644e67bb9f6bd50dd7880e","value":" 570/570 [00:00&lt;00:00, 32.9kB/s]"}},"67dd03d82c87478b82a682ede50da41d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccb9b91680f64bc187cf1480b8c04d46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"831f0529800946a9a5e407fcc5cd36dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1d4a5f09c3347a38d93df995ea2ddd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2401214c850341598014df97d00a1c75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5fb49eabdde45b893f457081866103f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"144b9827cc644e67bb9f6bd50dd7880e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be580b201bbf40e39ad76473ea5d8c1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_950a79c1563d426cb5057079940ce368","IPY_MODEL_e9b1a90c6f814e53b5b2d97f8e84131c","IPY_MODEL_ed73c9006b0c4060a60a466d07464a35"],"layout":"IPY_MODEL_e1e512c4d0ab445d8293cbbb7e89f0a7"}},"950a79c1563d426cb5057079940ce368":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a16d108ca7a41f0a2b9265c9bbf97ef","placeholder":"​","style":"IPY_MODEL_954275fc333b42e990df4042c9e823c1","value":"model.safetensors: 100%"}},"e9b1a90c6f814e53b5b2d97f8e84131c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01ebdb381334fbc8e173e118ef20d68","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13fee402413744088c2504a2ea269551","value":440449768}},"ed73c9006b0c4060a60a466d07464a35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_723c65b1062e45aba11ed90891053857","placeholder":"​","style":"IPY_MODEL_c952d69fb5274300a5e3b17b36450834","value":" 440M/440M [00:02&lt;00:00, 215MB/s]"}},"e1e512c4d0ab445d8293cbbb7e89f0a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a16d108ca7a41f0a2b9265c9bbf97ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"954275fc333b42e990df4042c9e823c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d01ebdb381334fbc8e173e118ef20d68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13fee402413744088c2504a2ea269551":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"723c65b1062e45aba11ed90891053857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c952d69fb5274300a5e3b17b36450834":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#### 4.1 **Overview of Chunkers**\n","   - **Definition**: Chunkers are tools that identify and group sequences of words into meaningful units, such as noun phrases (NPs), verb phrases (VPs), and other syntactic structures.\n","   - **Purpose**:\n","     - Provide syntactic analysis of sentences by segmenting and labeling units.\n","     - Useful for named entity recognition (NER), relation extraction, and sentence parsing.\n","   - **Key Techniques**: Rule-based chunking, statistical chunking, and classifier-based chunking.\n","   - **Example Code**:\n"],"metadata":{"id":"TH3JbZ2jhhsd"}},{"cell_type":"code","source":["import nltk\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Sample text to process\n","text = \"The quick brown fox jumps over the lazy dog.\"\n","\n","# Tokenize the text into individual words\n","tokens = nltk.word_tokenize(text)\n","\n","# Assign part-of-speech (POS) tags to each token\n","pos_tags = nltk.pos_tag(tokens)\n","\n","# Define a grammar for noun phrase (NP) chunking using a regular expression\n","# The grammar specifies that an NP can consist of:\n","# - An optional determiner (DT),\n","# - Zero or more adjectives (JJ),\n","# - A noun (NN).\n","grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n","\n","# Create a chunk parser with the defined grammar\n","chunk_parser = nltk.RegexpParser(grammar)\n","\n","# Parse the POS-tagged tokens to create a chunked tree\n","chunked = chunk_parser.parse(pos_tags)\n","\n","# Visualize the chunked structure in a graphical interface\n","#chunked.draw()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojA7XHg8iIL7","executionInfo":{"status":"ok","timestamp":1728834085666,"user_tz":-60,"elapsed":321,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"e47a9ef6-fe3e-4075-e184-69c43e2cd013"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}]},{"cell_type":"markdown","source":["#### 4.2 **Preparing the Data**\n","   - **Chunked Corpora**:\n","     - Chunked corpora are collections of text that have been manually segmented and labeled into syntactic units.\n","     - **Examples**: CoNLL-2000 Corpus, Penn Treebank.\n","     - **Importance**:\n","       - Provides labeled data necessary for training and evaluating chunkers.\n","       - Helps in developing chunkers that generalize across different domains.\n","     - **Example Code**:\n"],"metadata":{"id":"pv8ggUA3hh3P"}},{"cell_type":"code","source":["from nltk.corpus import conll2000\n","\n","# Download the CoNLL-2000 dataset if not already downloaded\n","nltk.download('conll2000')\n","\n","# Load the chunked sentences from the training set of the CoNLL-2000 corpus\n","train_sents = conll2000.chunked_sents('train.txt')\n","\n","# Print the first chunked sentence from the training data\n","print(train_sents[0])\n","# Output: A tree structure with chunked phrases\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9GdZGYbiSCV","executionInfo":{"status":"ok","timestamp":1728834092329,"user_tz":-60,"elapsed":497,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"300edde7-5881-416b-f2c6-3e066979330c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (NP Confidence/NN)\n","  (PP in/IN)\n","  (NP the/DT pound/NN)\n","  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n","  (NP another/DT sharp/JJ dive/NN)\n","  if/IN\n","  (NP trade/NN figures/NNS)\n","  (PP for/IN)\n","  (NP September/NNP)\n","  ,/,\n","  due/JJ\n","  (PP for/IN)\n","  (NP release/NN)\n","  (NP tomorrow/NN)\n","  ,/,\n","  (VP fail/VB to/TO show/VB)\n","  (NP a/DT substantial/JJ improvement/NN)\n","  (PP from/IN)\n","  (NP July/NNP and/CC August/NNP)\n","  (NP 's/POS near-record/JJ deficits/NNS)\n","  ./.)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/conll2000.zip.\n"]}]},{"cell_type":"markdown","source":["   - **IOB Format**:\n","     - **Definition**: IOB (Inside, Outside, Beginning) format is a tagging format used to denote the start, continuation, or absence of a chunk.\n","     - **Structure**:\n","       - **B**: Indicates the beginning of a chunk.\n","       - **I**: Indicates that the token is inside a chunk.\n","       - **O**: Indicates that the token is outside a chunk.\n","     - **Benefits**:\n","       - Standardized format for encoding chunks.\n","       - Facilitates training classifier-based chunkers.\n","     - **Example Code**:\n"],"metadata":{"id":"uq7TLw_TiLd-"}},{"cell_type":"code","source":["from nltk import conlltags2tree, tree2conlltags\n","from nltk.corpus import conll2000\n","\n","# Load the first chunked sentence from the CoNLL-2000 training data\n","sentence = conll2000.chunked_sents('train.txt')[0]\n","\n","# Convert the chunked sentence into IOB format\n","# This function transforms a chunk tree into a list of (word, POS tag, chunk tag) tuples\n","iob_tagged = tree2conlltags(sentence)\n","\n","# Print the first 10 tokens in IOB format\n","# The output will show tuples with the structure (word, POS tag, IOB tag)\n","print(iob_tagged[:10])  # Display the first 10 tokens\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO3wc0zTiMBF","executionInfo":{"status":"ok","timestamp":1728834096032,"user_tz":-60,"elapsed":467,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"47af8c2d-c03e-4e70-a636-4c0d7b1664d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Confidence', 'NN', 'B-NP'), ('in', 'IN', 'B-PP'), ('the', 'DT', 'B-NP'), ('pound', 'NN', 'I-NP'), ('is', 'VBZ', 'B-VP'), ('widely', 'RB', 'I-VP'), ('expected', 'VBN', 'I-VP'), ('to', 'TO', 'I-VP'), ('take', 'VB', 'I-VP'), ('another', 'DT', 'B-NP')]\n"]}]},{"cell_type":"markdown","source":["#### 4.3 **Baseline Chunking Approaches**\n"],"metadata":{"id":"twW4cSzhhh9t"}},{"cell_type":"markdown","source":["   - **4.3.1 Unigram Chunkers**:\n","     - **Definition**: A unigram chunker assigns a chunk tag to each word based solely on the word’s POS tag.\n","     - **Advantages**:\n","       - Simple to implement.\n","       - Useful as a baseline for evaluating more complex models.\n","     - **Disadvantages**:\n","       - Does not consider context, resulting in reduced accuracy for complex structures.\n","     - **Example Code**:\n"],"metadata":{"id":"yx8-e5aQhiDg"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import conll2000\n","\n","# Define a UnigramChunker class that inherits from ChunkParserI\n","class UnigramChunker(nltk.ChunkParserI):\n","    def __init__(self, train_sents):\n","        # Prepare training data in IOB format for the UnigramTagger\n","        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n","        # Initialize the UnigramTagger with the prepared training data\n","        self.tagger = nltk.UnigramTagger(train_data)\n","\n","    def parse(self, sentence):\n","        # Extract POS tags from the sentence\n","        pos_tags = [pos for (word, pos) in sentence]\n","        # Use the trained UnigramTagger to predict chunk tags based on the POS tags\n","        tagged_pos_tags = self.tagger.tag(pos_tags)\n","        # Combine words, POS tags, and chunk predictions into the format expected by conlltags2tree\n","        conlltags = [(word, pos, chunk) for ((word, pos), (pos, chunk)) in zip(sentence, tagged_pos_tags)]\n","        # Convert the tagged sentence into a chunk tree and return it\n","        return nltk.chunk.conlltags2tree(conlltags)\n","\n","# Load training sentences from the CoNLL-2000 chunking corpus\n","train_sents = conll2000.chunked_sents('train.txt')\n","# Initialize the UnigramChunker with the training data\n","unigram_chunker = UnigramChunker(train_sents)\n","\n","# Load test sentences from the CoNLL-2000 chunking corpus\n","test_sents = conll2000.chunked_sents('test.txt')\n","# Evaluate the performance of the Unigram chunker on the test set and print the results\n","print(unigram_chunker.evaluate(test_sents))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fX0QJY1Siu0r","executionInfo":{"status":"ok","timestamp":1728834137308,"user_tz":-60,"elapsed":3092,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"7ebe52eb-1d77-4414-8bc6-b28c40141647"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-ec3e734ff605>:30: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  print(unigram_chunker.evaluate(test_sents))\n"]},{"output_type":"stream","name":"stdout","text":["ChunkParse score:\n","    IOB Accuracy:  86.5%%\n","    Precision:     74.3%%\n","    Recall:        86.4%%\n","    F-Measure:     79.9%%\n"]}]},{"cell_type":"markdown","source":["   - **4.3.2 Bigram Chunkers**:\n","     - **Definition**: A bigram chunker considers the current POS tag and the previous one for assigning chunk tags.\n","     - **Advantages**:\n","       - More accurate than unigram chunkers by accounting for limited context.\n","     - **Disadvantages**:\n","       - Increased complexity compared to unigram.\n","       - Still limited by the narrow context window.\n","     - **Example Code**:\n"],"metadata":{"id":"hqRXi5YqhiGy"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import conll2000\n","\n","# Define a BigramChunker class that inherits from ChunkParserI\n","class BigramChunker(nltk.ChunkParserI):\n","    def __init__(self, train_sents):\n","        # Prepare training data in IOB format for the BigramTagger\n","        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n","        # Initialize the BigramTagger with the prepared training data\n","        self.tagger = nltk.BigramTagger(train_data)\n","\n","    def parse(self, sentence):\n","        # Extract POS tags from the sentence\n","        pos_tags = [pos for (word, pos) in sentence]\n","        # Use the trained BigramTagger to predict chunk tags based on the POS tags\n","        tagged_pos_tags = self.tagger.tag(pos_tags)\n","        # Combine words, POS tags, and chunk predictions into the format expected by conlltags2tree\n","        conlltags = [(word, pos, chunk) for ((word, pos), (pos, chunk)) in zip(sentence, tagged_pos_tags)]\n","        # Convert the tagged sentence into a chunk tree and return it\n","        return nltk.chunk.conlltags2tree(conlltags)\n","\n","# Load training sentences from the CoNLL-2000 chunking corpus\n","train_sents = conll2000.chunked_sents('train.txt')\n","# Initialize the BigramChunker with the training data\n","bigram_chunker = BigramChunker(train_sents)\n","\n","# Load test sentences from the CoNLL-2000 chunking corpus\n","test_sents = conll2000.chunked_sents('test.txt')\n","# Evaluate the performance of the Bigram chunker on the test set and print the results\n","print(bigram_chunker.evaluate(test_sents))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9qTSbJu1iy97","executionInfo":{"status":"ok","timestamp":1728834170993,"user_tz":-60,"elapsed":2959,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"b3a511df-070f-48e5-82cf-426a811433e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-e8f0f54b4cfc>:30: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  print(bigram_chunker.evaluate(test_sents))\n"]},{"output_type":"stream","name":"stdout","text":["ChunkParse score:\n","    IOB Accuracy:  89.3%%\n","    Precision:     81.2%%\n","    Recall:        86.2%%\n","    F-Measure:     83.6%%\n"]}]},{"cell_type":"markdown","source":["#### 4.4 **Classifier-Based Chunking**\n","   - **4.4.1 Concept**:\n","     - Chunking as a classification task involves training a model to assign chunk tags (e.g., IOB tags) based on features.\n","     - **Features**:\n","       - POS tags, word identity, neighboring word tags, position in sentence, prefixes, and suffixes.\n","     - **Classifier Types**:\n","       - Naive Bayes, Maximum Entropy, Decision Trees, Support Vector Machines.\n","     - **Benefits**:\n","       - Greater flexibility in incorporating features.\n","       - Higher accuracy by leveraging richer contextual information.\n","     - **Example Code**:\n"],"metadata":{"id":"iIpj-Ag2hiK2"}},{"cell_type":"code","source":["import nltk\n","from nltk.chunk.util import conlltags2tree, tree2conlltags\n","from sklearn.feature_extraction import DictVectorizer\n","from sklearn.linear_model import LogisticRegression\n","\n","# Feature extraction function for chunking\n","def chunk_features(sentence, index, history):\n","    \"\"\"\n","    Extracts features for the chunking model.\n","\n","    Parameters:\n","    - sentence: A list of (word, POS, chunk_tag) tuples for the sentence.\n","    - index: The index of the current word to extract features for.\n","    - history: The list of previous chunk tags (not used in this implementation).\n","\n","    Returns:\n","    - A dictionary containing features for the word at the given index.\n","    \"\"\"\n","    # Modification: Check the length of the tuple and unpack accordingly\n","    if len(sentence[index]) == 3:\n","        word, pos, _ = sentence[index]\n","    else:  # Assuming 2 values for word and pos\n","        word, pos = sentence[index]\n","\n","    features = {\n","        'pos': pos,  # Part of speech tag of the current word\n","        'word': word,  # Word itself\n","        'prev_pos': '' if index == 0 else sentence[index - 1][1] if len(sentence[index-1])>1 else '',  # POS tag of the previous word, if it exists\n","        'next_pos': '' if index == len(sentence) - 1 else sentence[index + 1][1] if len(sentence[index+1])>1 else '',  # POS tag of the next word, if it exists\n","    }\n","    return features"],"metadata":{"id":"8R9c4L3HjBy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Extract features and labels from the CoNLL-2000 dataset for training\n","train_sents = conll2000.chunked_sents('train.txt')\n","train_data = []  # Feature dictionaries for each word\n","train_labels = []  # Corresponding chunk tags for each word\n","\n","for sent in train_sents:\n","    iob_tags = tree2conlltags(sent)  # Convert chunk tree to IOB tags\n","    for index, (word, pos, chunk_tag) in enumerate(iob_tags):\n","        features = chunk_features(iob_tags, index, history=[]) # Pass iob_tags which contains (word, pos, chunk_tag) tuples\n","        train_data.append(features)\n","        train_labels.append(chunk_tag)\n"],"metadata":{"id":"rg8Jgh0pkCoR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Train a logistic regression classifier on the extracted features\n","clf = LogisticRegression(max_iter=10)  # Increase max_iter for convergence\n","clf.fit(X_train, y_train)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"02WS1YSVkG4A","executionInfo":{"status":"ok","timestamp":1728836313073,"user_tz":-60,"elapsed":186560,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"a59ec5bc-b1f6-417a-c3ee-99ed84a62590"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(max_iter=10)"],"text/html":["<style>#sk-container-id-2 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-2 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-2 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-2 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-2 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-2 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-2 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-2 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-2 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-2 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-2 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-2 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-2 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-2 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-2 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-2 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-2 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10)</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["\n","# Example evaluation on a new test sentence\n","test_sentence = [(\"The\", \"DT\"), (\"cat\", \"NN\"), (\"sat\", \"VB\"), (\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")]\n","test_data = [chunk_features(test_sentence, i, []) for i in range(len(test_sentence))]\n","X_test = vectorizer.transform(test_data)\n","y_pred = clf.predict(X_test)\n","\n","# Print the predicted chunk tags for each word in the test sentence\n","print(list(zip([word for word, _ in test_sentence], y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWwbt_i9k_mt","executionInfo":{"status":"ok","timestamp":1728836313074,"user_tz":-60,"elapsed":11,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"3d318678-1011-49be-d78e-b466390b1d39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('The', 'B-NP'), ('cat', 'I-NP'), ('sat', 'B-VP'), ('on', 'B-PP'), ('the', 'B-NP'), ('mat', 'I-NP')]\n"]}]},{"cell_type":"markdown","source":["#### 4.5 **Evaluation Metrics for Chunkers**\n"],"metadata":{"id":"hY_LGjGuhiP_"}},{"cell_type":"markdown","source":["   - **4.5.1 ChunkParse Score**:\n","     - Measures chunker performance by calculating precision, recall, and F1-score.\n","     - **Precision**: Fraction of predicted chunks that are correct.\n","     - **Recall**: Fraction of actual chunks that are correctly predicted.\n","     - **F1-Score**: Harmonic mean of precision and recall, providing a balanced measure.\n","     - **Example Code**:\n"],"metadata":{"id":"ETRDzkENhiUD"}},{"cell_type":"code","source":["# Evaluating a chunker using NLTK's built-in evaluation\n","from nltk.corpus import conll2000\n","\n","# Load the test sentences from the CoNLL-2000 chunking corpus\n","test_sents = conll2000.chunked_sents('test.txt')\n","\n","# Assuming UnigramChunker class is defined and trained using the train_sents\n","unigram_chunker = UnigramChunker(train_sents)\n","\n","# Evaluate the performance of the Unigram chunker on the test sentences\n","# The evaluation returns Precision, Recall, and F1-score\n","print(\"Precision, Recall, and F1:\", unigram_chunker.evaluate(test_sents))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Ru5wWmzjM_H","executionInfo":{"status":"ok","timestamp":1728836689728,"user_tz":-60,"elapsed":3212,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"0214ea17-81c2-4609-bb27-6731a88b08de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-21-dacb0471259f>:12: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  print(\"Precision, Recall, and F1:\", unigram_chunker.evaluate(test_sents))\n"]},{"output_type":"stream","name":"stdout","text":["Precision, Recall, and F1: ChunkParse score:\n","    IOB Accuracy:  86.5%%\n","    Precision:     74.3%%\n","    Recall:        86.4%%\n","    F-Measure:     79.9%%\n"]}]},{"cell_type":"markdown","source":["   - **4.5.2 Error Analysis**:\n","     - **Analyzing Incorrectly Chunked Tokens**:\n","       - Identify common errors and refine chunking rules or features to improve performance.\n","       - Helps to understand weaknesses in the chunker and guide subsequent iterations.\n","     - **Example Code**:\n"],"metadata":{"id":"xrTlXYPWhiWP"}},{"cell_type":"code","source":["from nltk.chunk import ChunkScore\n","import nltk\n","\n","# Initialize ChunkScore object to evaluate the chunker\n","chunk_score = ChunkScore()\n","\n","# Iterate through each sentence in the test set\n","for sent in test_sents:\n","    # Convert the gold standard chunk tree to IOB format\n","    gold_chunks = nltk.chunk.tree2conlltags(sent)\n","\n","    # Flatten the sentence tree into a list of (word, POS tag) tuples\n","    words_and_pos_tags = [(token, tag) for token, tag in sent.leaves()]\n","\n","    # Use the Unigram chunker to parse the sentence and convert it to IOB format\n","    predicted_chunks = nltk.chunk.tree2conlltags(unigram_chunker.parse(words_and_pos_tags))\n","\n","    # Score the predicted chunks against the gold standard\n","    chunk_score.score(predicted_chunks, gold_chunks)\n","\n","# Print the missed chunks (chunks that the model should have found but did not)\n","print(\"Missed Chunks:\", chunk_score.missed())\n","\n","# Print the incorrect chunks (chunks that were incorrectly identified by the model)\n","print(\"Incorrect Chunks:\", chunk_score.incorrect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOSIoXuzjPBS","executionInfo":{"status":"ok","timestamp":1728836759664,"user_tz":-60,"elapsed":1561,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"d9e4a945-db82-41cb-e692-8ceff73d6018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Missed Chunks: []\n","Incorrect Chunks: []\n"]}]},{"cell_type":"markdown","source":["#### 4.6 **Creative Observations in Developing Chunkers**\n","   - **Importance of Feature Engineering**:\n","     - In classifier-based chunking, effective feature engineering can significantly improve model performance.\n","     - Features like prefixes, suffixes, and word shape (e.g., capitalization, hyphenation) often add value in recognizing chunk boundaries.\n","   \n","   - **Role of Contextual Embeddings**:\n","     - Contextual word embeddings (e.g., BERT) can be used to replace manual features in classifier-based chunkers.\n","     - These embeddings provide richer, context-dependent word representations, often improving chunking accuracy.\n","\n","   - **Chunking Beyond Noun Phrases**:\n","     - Chunkers can be extended beyond noun phrases to identify verb phrases, prepositional phrases, and other types of syntactic structures.\n","     - Enables more detailed parsing of sentences, beneficial for downstream tasks like dependency parsing.\n","\n","   - **Semi-Supervised Chunking**:\n","     - Incorporating unlabeled data along with labeled data can improve chunker performance by leveraging large amounts of unlabeled text.\n","     - Semi-supervised learning approaches like bootstrapping can help label new examples based on confidence scores.\n","\n","   - **Handling Multi-Word and Nested Chunks**:\n","     - Chunking multi-word entities (e.g., named entities with multiple tokens) and handling nested chunks (e.g., NP within a VP) remains a challenge.\n","     - Recursive chunking methods and hierarchical tagging strategies can be employed to manage nested structures.\n","\n","   - **Scalability and Computational Efficiency**:\n","     - When dealing with large datasets, scalability becomes crucial.\n","     - Efficient algorithms and use of parallel processing can help improve chunker performance and reduce processing time.\n","\n"],"metadata":{"id":"DGPrk3xrhiYI"}},{"cell_type":"markdown","source":["#### 4.7 **Demonstration of Creative Observations**\n","   - **Feature Engineering for Classifier-Based Chunkers**:\n"],"metadata":{"id":"f5RddBOthiav"}},{"cell_type":"code","source":["# Adding word shape and suffix features to classifier-based chunker\n","def enhanced_chunk_features(sentence, index, history):\n","    \"\"\"\n","    Extracts enhanced features for chunking, including word shape and suffix.\n","\n","    Parameters:\n","    - sentence: A list of (word, POS) tuples for the sentence.\n","    - index: The index of the current word to extract features for.\n","    - history: The list of previous chunk tags (not used in this implementation).\n","\n","    Returns:\n","    - A dictionary containing enhanced features for the word at the given index.\n","    \"\"\"\n","    word, pos, _ = sentence[index] # Unpack all 3 elements, ignoring the chunk tag with '_'\n","    features = {\n","        'pos': pos,  # Part of speech tag of the current word\n","        'word': word,  # The word itself\n","        'suffix': word[-3:],  # The last three characters of the word, helpful for suffix analysis\n","        'word_shape': 'capitalized' if word[0].isupper() else 'lowercase',  # Indicator if the word is capitalized or not\n","    }\n","    return features\n","\n","# Reuse classifier code and train with enhanced features\n","train_data = []  # List to store training features\n","train_labels = []  # List to store corresponding chunk labels\n","\n","# Extract enhanced features for each word in the training set\n","for sent in train_sents:\n","    # Convert the chunk tree to IOB format\n","    iob_tags = tree2conlltags(sent)\n","\n","    # Iterate over each word in the sentence\n","    for index, (word, pos, chunk_tag) in enumerate(iob_tags):\n","        # Extract features using the enhanced feature function\n","        features = enhanced_chunk_features(iob_tags, index, history=[]) # Pass iob_tags to enhanced_chunk_features\n","        train_data.append(features)  # Append features to training data\n","        train_labels.append(chunk_tag)  # Append the corresponding chunk tag to training labels"],"metadata":{"id":"YfxWTYP8jgd1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["  - **Contextual Embeddings for Chunking**:\n"],"metadata":{"id":"Xbj_Wx3uhic4"}},{"cell_type":"code","source":["# Using pre-trained BERT embeddings for feature extraction\n","from transformers import BertTokenizer, BertModel\n","import torch\n","\n","# Load the pre-trained BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Define a sample sentence to be processed by BERT\n","sentence = \"The quick brown fox jumps over the lazy dog.\"\n","\n","# Tokenize the sentence using the BERT tokenizer\n","# The tokenizer will convert the sentence to input IDs and create attention masks\n","inputs = tokenizer(sentence, return_tensors='pt')  # Return PyTorch tensors\n","\n","# Pass the tokenized input through the pre-trained BERT model\n","outputs = model(**inputs)\n","\n","# Extract the last hidden state (contextual embeddings) for each token in the sentence\n","# 'last_hidden_state' contains the hidden states of the model for each token\n","embeddings = outputs.last_hidden_state\n","\n","# Print the shape of the embeddings tensor\n","print(embeddings.shape)  # [batch_size, sequence_length, hidden_size]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["608c7b83610e4d9a85295b3cd91caa15","a76a3e22795948aca31d70db7dfc12a2","7ed0e5d583394d318dfedab94d85d2b4","b1e3ad302ecf408bae0e0690af2b5b04","16628b280b4c4a59a5be79010b7c2319","464fb080a3df4b35a57ce05ff3856b8f","86cf8a7e5e0a498697c747454aff3754","752feffa9f20453c8f628e4dacf61a2d","c095147150e5417696d2f6099fa3c7f8","849d00cdf6fa4b5080fad0bc34fc4c00","dbef52f42ac24d9abf44a9a12854eca9","38411d40b7274862b25c7d91664e6d80","a2278bbe7ecb4d279b9d9612b248c5bf","a84eeb422954454caa8aa554b006926d","b4c7022361084f7e94d18c6cfde3ef15","356e0801679e402ea78cdd964e66744b","0f4b4be247b34fbfbff6dc83c9296bcc","9ee35c60e5bc4dce920b61d7c319d397","2cb71e29b5b949bebf140ebd5152cac7","68eedf95eafe4c3299a25473fa3735d1","888a400d121a40d291915b25ba7a21be","acd3c4b3434d4d578b037b18841c863e","60bef74257dc44e5ad9b9964fd8d8ca5","52f461d751664f6297fa197fa128f4fc","44ba445e246545f0bacb62fa13deceb9","8ed2b04f05e9413fa85a068ca5c0f0f3","ed29b3f5c63b4483a578472b53433dfb","eb0cca7bb9cf436a960ae0310b5a825b","15170563156f4f27bc8839f5a0f1d91b","95ec59b7ef9e449a8492dc2ed1ecf1b3","fec8632ce7c846cdac99f53cbeffcbc0","2c30180e18214a19a666dce9183229ce","ee9fb19d6ba34f30b5474c8449b9df22","3424c26846994fd18d2080fa2947c112","088f51bb24b442e0b6dfe6e5be6198b3","045ec34c09434c3598112908e26bdecc","8646e4e9e00e48088dc2378a815fd4d5","67dd03d82c87478b82a682ede50da41d","ccb9b91680f64bc187cf1480b8c04d46","831f0529800946a9a5e407fcc5cd36dd","f1d4a5f09c3347a38d93df995ea2ddd9","2401214c850341598014df97d00a1c75","a5fb49eabdde45b893f457081866103f","144b9827cc644e67bb9f6bd50dd7880e","be580b201bbf40e39ad76473ea5d8c1b","950a79c1563d426cb5057079940ce368","e9b1a90c6f814e53b5b2d97f8e84131c","ed73c9006b0c4060a60a466d07464a35","e1e512c4d0ab445d8293cbbb7e89f0a7","6a16d108ca7a41f0a2b9265c9bbf97ef","954275fc333b42e990df4042c9e823c1","d01ebdb381334fbc8e173e118ef20d68","13fee402413744088c2504a2ea269551","723c65b1062e45aba11ed90891053857","c952d69fb5274300a5e3b17b36450834"]},"id":"U5dx_rgljiVI","executionInfo":{"status":"ok","timestamp":1728836940331,"user_tz":-60,"elapsed":11625,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"9e2700f9-b903-4d81-bcbe-4f709a914ab1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"608c7b83610e4d9a85295b3cd91caa15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38411d40b7274862b25c7d91664e6d80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60bef74257dc44e5ad9b9964fd8d8ca5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3424c26846994fd18d2080fa2947c112"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be580b201bbf40e39ad76473ea5d8c1b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["torch.Size([1, 12, 768])\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"V65_43e4hie5"}}]}