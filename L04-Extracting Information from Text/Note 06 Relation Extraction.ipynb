{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgINU+uoihIjFm1VyS8as7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7f8ea5f706a0444f9cfe05e4b4cf734d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9cb2a438ca8b4fdc88cd57d33215deeb","IPY_MODEL_01f8005718fb4210bf70e5ebb07acacd","IPY_MODEL_136d3f62f1fd454e8ae0c12f25eae9ca"],"layout":"IPY_MODEL_da4e8bc476b24b698a704d781a417e79"}},"9cb2a438ca8b4fdc88cd57d33215deeb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7bf1e90218e480fa523bceace928346","placeholder":"​","style":"IPY_MODEL_10aa2d5607e4494db02eecb9d1a4407a","value":"tokenizer_config.json: 100%"}},"01f8005718fb4210bf70e5ebb07acacd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_860795cefe9c4cf8992a5373941cfc35","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cb80baa9d8843209ab011929b9d1964","value":48}},"136d3f62f1fd454e8ae0c12f25eae9ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70a01554ad264306a9a7e578a4935f3b","placeholder":"​","style":"IPY_MODEL_09bb3ba9eae04035a2ccb76b483a44dc","value":" 48.0/48.0 [00:00&lt;00:00, 1.02kB/s]"}},"da4e8bc476b24b698a704d781a417e79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7bf1e90218e480fa523bceace928346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10aa2d5607e4494db02eecb9d1a4407a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"860795cefe9c4cf8992a5373941cfc35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cb80baa9d8843209ab011929b9d1964":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70a01554ad264306a9a7e578a4935f3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09bb3ba9eae04035a2ccb76b483a44dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ef7b3b1de524796a45beaea7e2049f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc00d76fc94143d0bc3eb7abcf4b5af8","IPY_MODEL_dd7c573d8b8f4f82aa7b8932e17abc2c","IPY_MODEL_1d668abab6ed4f84bea6ec8868891f85"],"layout":"IPY_MODEL_960796c3f5014b33b15b2cc19b723f74"}},"bc00d76fc94143d0bc3eb7abcf4b5af8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00be06279e4a4f1f9c700730bfd9c89b","placeholder":"​","style":"IPY_MODEL_bd3e648e0eac4cb699b94eeddd4f4c7a","value":"vocab.txt: 100%"}},"dd7c573d8b8f4f82aa7b8932e17abc2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed89e5cf049041f9a6d1fdbd948d50a7","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edf699c392ac435fbc98d09a821b56fa","value":231508}},"1d668abab6ed4f84bea6ec8868891f85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fffc77193ec546ed96c74e02d4c0c811","placeholder":"​","style":"IPY_MODEL_0490ef0ba7f74efba168e18696d1aa06","value":" 232k/232k [00:00&lt;00:00, 3.75MB/s]"}},"960796c3f5014b33b15b2cc19b723f74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00be06279e4a4f1f9c700730bfd9c89b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd3e648e0eac4cb699b94eeddd4f4c7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed89e5cf049041f9a6d1fdbd948d50a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edf699c392ac435fbc98d09a821b56fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fffc77193ec546ed96c74e02d4c0c811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0490ef0ba7f74efba168e18696d1aa06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4bb9f08d9df421f8fa94eba5e7f9b28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df4b1ffdbd844def8dbbfa4bf523f33d","IPY_MODEL_072aedc27f704fa6b853edd29c9aad7f","IPY_MODEL_6cc384d34e4046c1afc83303c3424f77"],"layout":"IPY_MODEL_6b86fd748638416db48f8d282fa174b6"}},"df4b1ffdbd844def8dbbfa4bf523f33d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a6e97e708da4bc3b066b8bb3e52a85f","placeholder":"​","style":"IPY_MODEL_a6ac8ceee2fc45ea9a61f1da87ae8b5b","value":"tokenizer.json: 100%"}},"072aedc27f704fa6b853edd29c9aad7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df567ec51a314b39a8bec7ba25e7cdc5","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2a1b77367c94b70b44ecdd483063c45","value":466062}},"6cc384d34e4046c1afc83303c3424f77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37d1188e7e2a4f75a5422bbe46d7d955","placeholder":"​","style":"IPY_MODEL_f8c31052ed4e4a588b765e9890463643","value":" 466k/466k [00:00&lt;00:00, 7.90MB/s]"}},"6b86fd748638416db48f8d282fa174b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a6e97e708da4bc3b066b8bb3e52a85f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6ac8ceee2fc45ea9a61f1da87ae8b5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df567ec51a314b39a8bec7ba25e7cdc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2a1b77367c94b70b44ecdd483063c45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37d1188e7e2a4f75a5422bbe46d7d955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8c31052ed4e4a588b765e9890463643":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1c51a8fc4914d8a85f4846b45ac7a94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24dd205be9f547dc96ada84f7e2f8273","IPY_MODEL_113488c8bbca4deeac1e5f6d9420d299","IPY_MODEL_4925106e3337412389605d68d2e6b524"],"layout":"IPY_MODEL_e45b8fa7065349319e9419d45c45b030"}},"24dd205be9f547dc96ada84f7e2f8273":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a40f7bd1e014809850bcdc0b18b4b65","placeholder":"​","style":"IPY_MODEL_c3ece84995004c29b589a3e056729ac7","value":"config.json: 100%"}},"113488c8bbca4deeac1e5f6d9420d299":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26bb3e00f1d54279b90ac41a84de01fc","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4b53163decf461995409de3c701b6f0","value":570}},"4925106e3337412389605d68d2e6b524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50d12dd947bc43c58e1b8cbdc61624c0","placeholder":"​","style":"IPY_MODEL_69a2e377796d4924ae51bd1a0dfee638","value":" 570/570 [00:00&lt;00:00, 7.08kB/s]"}},"e45b8fa7065349319e9419d45c45b030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a40f7bd1e014809850bcdc0b18b4b65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ece84995004c29b589a3e056729ac7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26bb3e00f1d54279b90ac41a84de01fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4b53163decf461995409de3c701b6f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50d12dd947bc43c58e1b8cbdc61624c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69a2e377796d4924ae51bd1a0dfee638":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5075f86e27a34534bc505315d26b244c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67f254fa05ae4d58b1c7e5715fc0eef0","IPY_MODEL_1991b3dbe057433ba7c06a8153d35480","IPY_MODEL_77f8c87e9710433393938d2bcc164d31"],"layout":"IPY_MODEL_a642290332294f7db70ff9fd4f8ab1b1"}},"67f254fa05ae4d58b1c7e5715fc0eef0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_370239fa689f4178a3267cbbe1f869d5","placeholder":"​","style":"IPY_MODEL_bfc89203b4ee4a119bbd82a6c3f82eb6","value":"model.safetensors: 100%"}},"1991b3dbe057433ba7c06a8153d35480":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2da31188ea08488b9fe8ee5ecdc18f04","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a19918df410641839baab012c40acef3","value":440449768}},"77f8c87e9710433393938d2bcc164d31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e1b2cedf11c49a8899dddfd5e84c076","placeholder":"​","style":"IPY_MODEL_16263416491c4445943a214ba40d1647","value":" 440M/440M [00:07&lt;00:00, 58.0MB/s]"}},"a642290332294f7db70ff9fd4f8ab1b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"370239fa689f4178a3267cbbe1f869d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfc89203b4ee4a119bbd82a6c3f82eb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2da31188ea08488b9fe8ee5ecdc18f04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a19918df410641839baab012c40acef3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e1b2cedf11c49a8899dddfd5e84c076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16263416491c4445943a214ba40d1647":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Relation extraction (RE) is the process of identifying semantic relationships between entities in text.\n","\n","This section provides a comprehensive discussion of relation extraction techniques, challenges, tools, and examples.\n","\n","Each point is followed by potential demonstration ideas that use code to illustrate the concept.\n","\n"],"metadata":{"id":"9Wi727wvrOFG"}},{"cell_type":"markdown","source":["### 6.1 Definition and Goals\n","\n","- **Definition**: Relation extraction is the task of detecting and classifying semantic relationships between named entities within a given text. Relations may represent factual associations, such as \"Barack Obama was born in Honolulu.\"\n","  - **Code Demonstration**: You could use a sample sentence and NLTK to split the sentence into entities and identify possible relations.\n"],"metadata":{"id":"X2UWCFP_rOmM"}},{"cell_type":"code","source":["import nltk\n","from nltk import word_tokenize, pos_tag\n","\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Define the sentence to analyze\n","# This sentence contains the name \"Barack Obama\" and the place \"Honolulu\"\n","sentence = \"Barack Obama was born in Honolulu.\"\n","\n","# Tokenize the sentence into individual words\n","# word_tokenize splits the sentence into tokens (words and punctuation)\n","tokens = word_tokenize(sentence)\n","\n","# Perform Part-of-Speech (POS) tagging on the tokens\n","# pos_tag assigns a POS tag to each token, indicating its grammatical role\n","pos_tags = pos_tag(tokens)\n","\n","# Print the tokens and their corresponding POS tags\n","print(pos_tags)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5CIHLJnsPu9","executionInfo":{"status":"ok","timestamp":1728836720492,"user_tz":-60,"elapsed":662,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"5c8843bc-5c8d-49ab-de29-989dad8d44a7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["[('Barack', 'NNP'), ('Obama', 'NNP'), ('was', 'VBD'), ('born', 'VBN'), ('in', 'IN'), ('Honolulu', 'NNP'), ('.', '.')]\n"]}]},{"cell_type":"markdown","source":["- **Goal**: Extract structured relationships between entities (such as \"Person-BornIn-Location\") to enable effective querying of information from unstructured text.\n","  - **Code Demonstration**: A basic rule-based approach could be demonstrated to detect \"Person-BornIn-Location\" relationships.\n"],"metadata":{"id":"cF9Wa-1mrOqF"}},{"cell_type":"code","source":["import nltk\n","from nltk import word_tokenize, pos_tag\n","\n","# Define a function to extract relationships from a given sentence\n","def extract_relation(sentence):\n","    # Check if the phrase \"was born in\" is present in the sentence\n","    if \"was born in\" in sentence:\n","        # Tokenize the sentence into individual words\n","        tokens = word_tokenize(sentence)\n","\n","        # Perform Part-of-Speech (POS) tagging on the tokens\n","        # Filter for proper nouns (NNP), as these likely represent entities (e.g., people, locations)\n","        entities = [token for token, pos in pos_tag(tokens) if pos == 'NNP']\n","\n","        # If there are at least two proper noun entities, return the relationship\n","        # The assumption is that the first entity is the person and the second is the location\n","        if len(entities) >= 2:\n","            return (entities[0], \"born_in\", entities[-1])\n","\n","# Define a sample sentence\n","sentence = \"Barack Obama was born in Honolulu.\"\n","\n","# Extract the relationship from the sentence\n","relation = extract_relation(sentence)\n","\n","# Print the extracted relationship\n","print(relation)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hUbJrsaSsSGM","executionInfo":{"status":"ok","timestamp":1728836750195,"user_tz":-60,"elapsed":270,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"7873b3e8-18f7-47aa-a194-7c0e99883bf9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["('Barack', 'born_in', 'Honolulu')\n"]}]},{"cell_type":"markdown","source":["### 6.2 Types of Relations\n","\n","- **Explicit Relations**: Relationships explicitly stated in the text (e.g., \"CEO of Microsoft\").\n","  - **Code Demonstration**: Extract explicit relations by matching specific patterns in a sentence.\n"],"metadata":{"id":"ZEnyZPSZrOsO"}},{"cell_type":"code","source":["import re\n","\n","# Define the text to analyze\n","# The sentence contains the name of a person, their role, and the organization they work for\n","text = \"Satya Nadella is the CEO of Microsoft.\"\n","\n","# Define a regular expression pattern to extract the person, role, and organization\n","# The pattern uses named groups to capture specific entities\n","pattern = r'(?P<person>\\w+ \\w+) is the (?P<role>CEO) of (?P<org>\\w+)'\n","\n","# Search for the pattern in the text\n","match = re.search(pattern, text)\n","\n","# If a match is found, print the named groups as a dictionary\n","if match:\n","    # The match.groupdict() method returns a dictionary with the names and values of the matched groups\n","    print(match.groupdict())\n","\n","# Output:\n","# {'person': 'Satya Nadella', 'role': 'CEO', 'org': 'Microsoft'}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOcgjm5ZsSlv","executionInfo":{"status":"ok","timestamp":1728836791811,"user_tz":-60,"elapsed":338,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"27480845-f36d-49ac-8b38-2da9188119d5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{'person': 'Satya Nadella', 'role': 'CEO', 'org': 'Microsoft'}\n"]}]},{"cell_type":"markdown","source":["- **Implicit Relations**: Relationships inferred indirectly from the context (e.g., \"Barack Obama was born in Hawaii\" implies a \"BornIn\" relation).\n","  - **Code Demonstration**: A more complex method, such as using dependency parsing, is required to infer these relations.\n"],"metadata":{"id":"0w9Psp84rOun"}},{"cell_type":"code","source":["# Import the spaCy library, which is widely used for NLP tasks like tokenization, parsing, and named entity recognition\n","import spacy\n","\n","# Load the small English language model.\n","# \"en_core_web_sm\" is a pre-trained model provided by spaCy for various NLP tasks, including POS tagging and dependency parsing.\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Process the sentence \"Barack Obama was born in Hawaii.\" with the NLP pipeline.\n","# The `doc` object contains tokens (words), part-of-speech tags, dependencies, etc.\n","doc = nlp(\"Barack Obama was born in Hawaii.\")\n","\n","# Iterate through each token (word) in the processed document `doc`.\n","for token in doc:\n","\n","    # Check if the current token is the ROOT of the sentence.\n","    # In a dependency tree, the ROOT is the main verb (or the central action in the sentence).\n","    if token.dep_ == \"ROOT\":\n","\n","        # Print the action (the root verb) and its subject.\n","        # The subject is generally a noun or pronoun that is related to the ROOT verb.\n","        # The token itself is the action (verb) and the token's head would refer to its subject (in this case it seems mistaken).\n","        # However, instead of 'token.head', we should print out the token and also find the actual subject (typically a noun), which is related to the verb.\n","        print(f\"Action: {token.text}, Subject: {token.head.text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khL6E9vWsS3g","executionInfo":{"status":"ok","timestamp":1728837196054,"user_tz":-60,"elapsed":9781,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"75152373-e86c-453e-fd33-8ee4bda50c0d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Action: born, Subject: born\n"]}]},{"cell_type":"markdown","source":["### 6.3 Approaches to Relation Extraction\n","\n"],"metadata":{"id":"_ZgPH0fUrOxB"}},{"cell_type":"markdown","source":["#### 6.3.1 Pattern-Based Approaches\n","\n","- **Manual Pattern Design**: Creating hand-crafted rules to identify relations based on specific linguistic patterns, such as using part-of-speech (POS) tags or specific keywords.\n","  - **Code Demonstration**: Using regular expressions with predefined patterns to identify relations.\n"],"metadata":{"id":"y89QUihgrOzV"}},{"cell_type":"code","source":["import re  # Importing the 're' module to work with regular expressions.\n","\n","# Defining a regex pattern to match sentences that describe someone being born in a location.\n","# The pattern uses named groups to capture the person's full name (first and last) and the location.\n","# - (?P<person>[A-Z][a-z]+ [A-Z][a-z]+): Captures two capitalized words (a first and last name), stored in the 'person' group.\n","# - (is|was): Matches either 'is' or 'was' (to cover tense variations).\n","# - (?P<location>[A-Z][a-z]+): Captures a single capitalized word as the location (e.g., \"San\" from \"San Francisco\").\n","# The '\\b' ensures that the pattern matches word boundaries so that full words are captured.\n","pattern = re.compile(r'\\b(?P<person>[A-Z][a-z]+ [A-Z][a-z]+)\\b (is|was) born in \\b(?P<location>[A-Z][a-z]+)\\b')\n","\n","# A test sentence to apply the pattern to.\n","sentence = \"Steve Jobs was born in San Francisco.\"\n","\n","# Searches the sentence using the defined regex pattern. It returns a match object if the pattern is found.\n","match = pattern.search(sentence)\n","\n","# If a match is found, the named groups ('person' and 'location') are accessed using match.group(),\n","# and the extracted relation is printed in a formatted way.\n","if match:\n","    print(f\"Extracted Relation: {match.group('person')} born_in {match.group('location')}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qZ-STZWsTip","executionInfo":{"status":"ok","timestamp":1728837311237,"user_tz":-60,"elapsed":239,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"98745d89-18df-4a82-aefc-918b0409f3ca"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Relation: Steve Jobs born_in San\n"]}]},{"cell_type":"markdown","source":["#### 6.3.2 Supervised Learning Methods\n","\n","- **Feature-Based Classification**: Relationships are identified using traditional classifiers such as Support Vector Machines (SVM) by training models on labeled data. Features may include POS tags, dependency relationships, and named entity types.\n","  - **Code Demonstration**: Use scikit-learn to create a simple classifier for detecting relationships.\n"],"metadata":{"id":"GHX0t952rO2R"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.svm import SVC  # Importing the Support Vector Classifier (SVC) from the SVM (Support Vector Machine) module.\n","\n","# A set of sentences (training data), where each sentence describes a relation involving a person (occupation or birthplace).\n","sentences = [\"Satya Nadella is the CEO of Microsoft.\", \"Tim Cook was born in Alabama.\"]\n","\n","# Labels corresponding to the sentences, indicating the type of relation described in each sentence.\n","labels = [\"relation_occupation\", \"relation_birthplace\"]\n","\n","# Creating an instance of CountVectorizer, which converts text data into a matrix of token counts (bag-of-words model).\n","vectorizer = CountVectorizer()\n","\n","# Fitting the vectorizer to the training sentences and transforming them into a sparse matrix of word counts.\n","X = vectorizer.fit_transform(sentences)\n","\n","# Initializing the SVC (Support Vector Classifier) with a linear kernel.\n","# The linear kernel works well with text data when the classes are linearly separable.\n","classifier = SVC(kernel='linear')\n","\n","# Training the classifier using the transformed sentences (X) and their corresponding labels.\n","classifier.fit(X, labels)\n","\n","# Transforming a new sentence (test data) into the same feature space using the fitted vectorizer.\n","test_sentence = vectorizer.transform([\"Sundar Pichai is the CEO of Google.\"])\n","\n","# Using the trained classifier to predict the label for the new test sentence.\n","prediction = classifier.predict(test_sentence)\n","\n","# Printing the predicted label for the test sentence.\n","print(prediction)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ckC6urIsT50","executionInfo":{"status":"ok","timestamp":1728837351454,"user_tz":-60,"elapsed":266,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"41f2a32f-d2b0-42a3-8851-0bcef9f1cd96"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['relation_occupation']\n"]}]},{"cell_type":"markdown","source":["- **Deep Learning-Based Models**: Modern methods use neural networks such as Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks, or transformers for relation extraction.\n","  - **Code Demonstration**: Demonstrate a simple LSTM model using PyTorch to classify relations.\n"],"metadata":{"id":"6jUIgk7LrO7u"}},{"cell_type":"code","source":["import torch  # Importing PyTorch, a deep learning library.\n","import torch.nn as nn  # Importing the neural network module from PyTorch.\n","import torch.optim as optim  # Importing optimization algorithms from PyTorch.\n","\n","# Defining a custom neural network model for relation classification.\n","class RelationClassifier(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n","        super(RelationClassifier, self).__init__()\n","\n","        # Embedding layer: Transforms input word indices into dense vectors of a specified size (embedding_dim).\n","        # - vocab_size: Size of the vocabulary, i.e., how many unique words the model can handle.\n","        # - embedding_dim: Dimension of the embedding vectors (how many features represent each word).\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # LSTM layer: A recurrent layer for sequential data, useful for text since word order matters.\n","        # - embedding_dim: Input size (i.e., the embedding dimension).\n","        # - hidden_dim: Number of hidden units in the LSTM, which determines the model's capacity.\n","        # - batch_first=True: Ensures that input shape is (batch_size, sequence_length, embedding_dim).\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","\n","        # Fully connected layer: Maps the LSTM output to the desired number of output classes.\n","        # - hidden_dim: Input size (coming from LSTM's hidden state).\n","        # - output_dim: Number of output classes (for classification, this would be the number of relations).\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    # The forward method defines the forward pass of the neural network.\n","    def forward(self, x):\n","        # Embedding: Transforms the input indices into dense vectors of size (batch_size, sequence_length, embedding_dim).\n","        embedded = self.embedding(x)\n","\n","        # LSTM: Processes the embedded input through the LSTM layer.\n","        # - The hidden state (hidden) is passed to the fully connected layer for classification.\n","        _, (hidden, _) = self.lstm(embedded)\n","\n","        # Fully connected: The hidden state from the LSTM is used for classification.\n","        # - hidden.squeeze(0): Removes the unnecessary first dimension of the hidden state (as LSTM returns [1, batch_size, hidden_dim]).\n","        output = self.fc(hidden.squeeze(0))\n","\n","        # Returning the output (predictions).\n","        return output\n"],"metadata":{"id":"FX75kx0DsUXt","executionInfo":{"status":"ok","timestamp":1728837465159,"user_tz":-60,"elapsed":254,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["#### 6.3.3 Distant Supervision\n","\n","- **Definition**: Using an external knowledge base (e.g., Freebase, Wikidata) to automatically label training data. Relationships in text are aligned with the facts in the database.\n","  - **Code Demonstration**: Use a set of sample facts to demonstrate distant supervision.\n"],"metadata":{"id":"uNPnhK-CrPAa"}},{"cell_type":"code","source":["# Sample knowledge base (KB), which holds predefined facts about people and their relationships to organizations.\n","# Each fact is represented as a dictionary with 'person', 'relation', and 'organization' keys.\n","knowledge_base = [\n","    {\"person\": \"Elon Musk\", \"relation\": \"CEO_of\", \"organization\": \"Tesla\"}\n","]\n","\n","# Input text from which we want to extract a relationship using distant supervision.\n","text = \"Elon Musk is the CEO of Tesla.\"\n","\n","# Function for distant supervision-based relation extraction.\n","# It tries to find matches between the given text and facts in the knowledge base.\n","def distant_supervision(text, kb):\n","    # Iterating over each fact in the knowledge base.\n","    for fact in kb:\n","        # Checking if both the person's name and the organization's name from the fact appear in the input text.\n","        if fact['person'] in text and fact['organization'] in text:\n","            # If a match is found, print the extracted relation in a human-readable format.\n","            print(f\"Extracted Relation: {fact['person']} is {fact['relation']} {fact['organization']}\")\n","\n","# Calling the distant_supervision function with the input text and knowledge base.\n","distant_supervision(text, knowledge_base)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cfL6g0fdsUxS","executionInfo":{"status":"ok","timestamp":1728837496941,"user_tz":-60,"elapsed":249,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"0c206cf5-33cf-4828-f156-0fe2906d497f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Relation: Elon Musk is CEO_of Tesla\n"]}]},{"cell_type":"markdown","source":["### 6.4 Evaluation of Relation Extraction Models\n","\n","- **Evaluation Metrics**: Precision, recall, and F1-score are typically used to evaluate the performance of relation extraction models.\n","  - **Code Demonstration**: Using scikit-learn to evaluate a classifier's performance.\n"],"metadata":{"id":"b2UcGyqGrPEx"}},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score  # Importing precision, recall, and F1-score metrics.\n","\n","# True labels (ground truth) representing the actual classes for a classification task.\n","y_true = [\"relation_occupation\", \"relation_birthplace\", \"relation_occupation\"]\n","\n","# Predicted labels from a classification model.\n","y_pred = [\"relation_occupation\", \"relation_birthplace\", \"relation_birthplace\"]\n","\n","# Calculating precision using the micro-averaging method.\n","# Precision = True Positives / (True Positives + False Positives)\n","# Micro-averaging computes a global precision by considering all instances across classes,\n","# treating them as a single binary classification task.\n","precision = precision_score(y_true, y_pred, average='micro')\n","\n","# Calculating recall using the micro-averaging method.\n","# Recall = True Positives / (True Positives + False Negatives)\n","# Like precision, micro-averaging for recall aggregates the contribution of all classes to compute a global recall.\n","recall = recall_score(y_true, y_pred, average='micro')\n","\n","# Calculating F1-score using the micro-averaging method.\n","# F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n","# Micro-averaging for F1 is the harmonic mean of the globally computed precision and recall.\n","f1 = f1_score(y_true, y_pred, average='micro')\n","\n","# Printing the calculated precision, recall, and F1-score.\n","print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5WwjhHbcsVF8","executionInfo":{"status":"ok","timestamp":1728837527258,"user_tz":-60,"elapsed":257,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"11e57c91-eae9-4981-b65e-8b277d3dd90d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.6666666666666666, Recall: 0.6666666666666666, F1 Score: 0.6666666666666666\n"]}]},{"cell_type":"markdown","source":["### 6.5 Challenges in Relation Extraction\n","\n","- **Ambiguity in Text**: Ambiguous relations such as a person being associated with multiple organizations can make it challenging to determine the correct relation.\n","  - **Observation**: Techniques like dependency parsing and contextual embeddings can help disambiguate entity relationships.\n","  - **Code Demonstration**: Using SpaCy to illustrate dependency parsing and resolve ambiguity.\n","\n"],"metadata":{"id":"kqRl6znarPHn"}},{"cell_type":"code","source":["# Assuming `nlp` is a pre-trained language model (like from spaCy), which processes text.\n","# 'doc' is the parsed representation of the input text.\n","\n","doc = nlp(\"Steve Jobs was the CEO of Apple and Pixar.\")\n","\n","# Iterating over all noun chunks in the document.\n","# A noun chunk is a noun phrase, which typically includes a noun and its modifiers (e.g., \"the CEO of Apple\").\n","for chunk in doc.noun_chunks:\n","    # Printing the text of the noun chunk and the root (the head noun) of the chunk.\n","    print(f\"Noun Chunk: {chunk.text}, Root: {chunk.root.text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5j9vHX1sVbd","executionInfo":{"status":"ok","timestamp":1728837558729,"user_tz":-60,"elapsed":354,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"18db8125-84df-463b-bf2f-0c2cc006874d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Noun Chunk: Steve Jobs, Root: Jobs\n","Noun Chunk: the CEO, Root: CEO\n","Noun Chunk: Apple, Root: Apple\n","Noun Chunk: Pixar, Root: Pixar\n"]}]},{"cell_type":"markdown","source":["- **Lack of Labeled Data**: Annotating text with relationships can be costly and time-consuming.\n","  - **Observation**: Distant supervision and semi-supervised learning can reduce the dependency on labeled datasets.\n","  - **Code Demonstration**: Automatically generate labeled examples using distant supervision as shown earlier.\n","\n"],"metadata":{"id":"zF0FSWAuv03-"}},{"cell_type":"markdown","source":["### 6.6 Advanced Techniques for Relation Extraction\n","\n"],"metadata":{"id":"UQh9JUpGrPKV"}},{"cell_type":"markdown","source":["#### 6.6.1 Dependency Parsing\n","\n","- **Definition**: Dependency parsing helps determine the grammatical structure of a sentence, making it easier to identify relations between entities.\n","  - **Observation**: Parsing dependencies can uncover relationships that are not linear in word order but are instead hierarchical.\n","  - **Code Demonstration**: Use SpaCy to illustrate dependency parsing and identify relationships.\n","\n","    ```python\n","    for token in doc:\n","        print(f\"Token: {token.text}, Dependency: {token.dep_}, Head: {token.head.text}\")\n","    ```\n","\n"],"metadata":{"id":"uPyTGS2zrPM7"}},{"cell_type":"markdown","source":["#### 6.6.2 Using Transformers for Relation Extraction\n","\n","- **Transformers**: BERT and similar transformer-based models are increasingly used for relation extraction due to their ability to capture contextual embeddings.\n","  - **Observation**: Fine-tuning transformer models like BERT with relation-specific datasets can significantly improve extraction performance.\n","  - **Code Demonstration**: Example using Hugging Face's transformers library.\n"],"metadata":{"id":"hEILTL0grPPx"}},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForSequenceClassification  # Importing BERT tokenizer and sequence classification model.\n","\n","# Loading a pre-trained BERT tokenizer. 'bert-base-uncased' is a version of BERT where the text is lowercased.\n","# The tokenizer converts the input text into a format suitable for the model (tokens and token IDs).\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Loading a pre-trained BERT model for sequence classification.\n","# 'bert-base-uncased' refers to the BERT model trained on lowercased text, and it's designed for classification tasks.\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","\n","# The input text that we want to classify.\n","text = \"Jeff Bezos is the founder of Amazon.\"\n","\n","# Tokenizing the input text. The tokenizer converts the input text into a set of token IDs that the model understands.\n","# - return_tensors=\"pt\": This argument returns the tokenized input as PyTorch tensors (since BERT expects tensors as inputs).\n","inputs = tokenizer(text, return_tensors=\"pt\")\n","\n","# Passing the tokenized inputs into the BERT model. The model processes the input to produce an output.\n","# The double asterisks (**inputs) unpack the dictionary of input tensors (e.g., input_ids, attention_mask).\n","outputs = model(**inputs)\n","\n","# The output contains logits (raw scores) before applying any activation functions like softmax.\n","# Logits are the raw, unnormalized predictions of the model, useful for classification tasks.\n","print(outputs.logits)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388,"referenced_widgets":["7f8ea5f706a0444f9cfe05e4b4cf734d","9cb2a438ca8b4fdc88cd57d33215deeb","01f8005718fb4210bf70e5ebb07acacd","136d3f62f1fd454e8ae0c12f25eae9ca","da4e8bc476b24b698a704d781a417e79","c7bf1e90218e480fa523bceace928346","10aa2d5607e4494db02eecb9d1a4407a","860795cefe9c4cf8992a5373941cfc35","1cb80baa9d8843209ab011929b9d1964","70a01554ad264306a9a7e578a4935f3b","09bb3ba9eae04035a2ccb76b483a44dc","9ef7b3b1de524796a45beaea7e2049f7","bc00d76fc94143d0bc3eb7abcf4b5af8","dd7c573d8b8f4f82aa7b8932e17abc2c","1d668abab6ed4f84bea6ec8868891f85","960796c3f5014b33b15b2cc19b723f74","00be06279e4a4f1f9c700730bfd9c89b","bd3e648e0eac4cb699b94eeddd4f4c7a","ed89e5cf049041f9a6d1fdbd948d50a7","edf699c392ac435fbc98d09a821b56fa","fffc77193ec546ed96c74e02d4c0c811","0490ef0ba7f74efba168e18696d1aa06","f4bb9f08d9df421f8fa94eba5e7f9b28","df4b1ffdbd844def8dbbfa4bf523f33d","072aedc27f704fa6b853edd29c9aad7f","6cc384d34e4046c1afc83303c3424f77","6b86fd748638416db48f8d282fa174b6","1a6e97e708da4bc3b066b8bb3e52a85f","a6ac8ceee2fc45ea9a61f1da87ae8b5b","df567ec51a314b39a8bec7ba25e7cdc5","c2a1b77367c94b70b44ecdd483063c45","37d1188e7e2a4f75a5422bbe46d7d955","f8c31052ed4e4a588b765e9890463643","f1c51a8fc4914d8a85f4846b45ac7a94","24dd205be9f547dc96ada84f7e2f8273","113488c8bbca4deeac1e5f6d9420d299","4925106e3337412389605d68d2e6b524","e45b8fa7065349319e9419d45c45b030","9a40f7bd1e014809850bcdc0b18b4b65","c3ece84995004c29b589a3e056729ac7","26bb3e00f1d54279b90ac41a84de01fc","e4b53163decf461995409de3c701b6f0","50d12dd947bc43c58e1b8cbdc61624c0","69a2e377796d4924ae51bd1a0dfee638","5075f86e27a34534bc505315d26b244c","67f254fa05ae4d58b1c7e5715fc0eef0","1991b3dbe057433ba7c06a8153d35480","77f8c87e9710433393938d2bcc164d31","a642290332294f7db70ff9fd4f8ab1b1","370239fa689f4178a3267cbbe1f869d5","bfc89203b4ee4a119bbd82a6c3f82eb6","2da31188ea08488b9fe8ee5ecdc18f04","a19918df410641839baab012c40acef3","1e1b2cedf11c49a8899dddfd5e84c076","16263416491c4445943a214ba40d1647"]},"id":"ROyYTuwqsW3G","executionInfo":{"status":"ok","timestamp":1728837622011,"user_tz":-60,"elapsed":14625,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"82079134-467a-4e5d-9ca4-efc53e9f3b4b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8ea5f706a0444f9cfe05e4b4cf734d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ef7b3b1de524796a45beaea7e2049f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4bb9f08d9df421f8fa94eba5e7f9b28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1c51a8fc4914d8a85f4846b45ac7a94"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5075f86e27a34534bc505315d26b244c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[0.3521, 0.1801]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["### 6.7 Practical Use Cases of Relation Extraction\n","\n","- **Knowledge Graph Construction**: Extracting entities and relations to populate a knowledge graph.\n","  - **Code Demonstration**: Use RDF triples to construct a basic knowledge graph from extracted relations.\n"],"metadata":{"id":"Ws96r0LarPTA"}},{"cell_type":"code","source":["!pip install rdflib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nWT4-6SpwjGS","executionInfo":{"status":"ok","timestamp":1728837739297,"user_tz":-60,"elapsed":11678,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"72993b8a-df73-4956-f886-0568f4df5163"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rdflib\n","  Downloading rdflib-7.0.0-py3-none-any.whl.metadata (11 kB)\n","Collecting isodate<0.7.0,>=0.6.0 (from rdflib)\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.1.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n","Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: isodate, rdflib\n","Successfully installed isodate-0.6.1 rdflib-7.0.0\n"]}]},{"cell_type":"code","source":["from rdflib import Graph, URIRef, Literal  # Importing necessary classes from the RDFLib library.\n","\n","# Creating a new RDF graph. An RDF graph is a set of triples, where each triple consists of a subject, predicate, and object.\n","g = Graph()\n","\n","# Adding a triple to the graph.\n","# - The subject is a URI (Unique Resource Identifier) representing \"Jeff Bezos\".\n","# - The predicate is a URI representing the relationship \"founder_of\".\n","# - The object is a literal, which in this case is the string \"Amazon\".\n","g.add((URIRef(\"http://example.org/Jeff_Bezos\"), URIRef(\"http://example.org/founder_of\"), Literal(\"Amazon\")))\n","\n","# Iterating over all triples (statements) in the graph.\n","# RDFLib stores triples as a set of (subject, predicate, object) tuples.\n","for stmt in g:\n","    # Printing each triple in the graph.\n","    print(stmt)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QF5xsNjLwLd4","executionInfo":{"status":"ok","timestamp":1728837742463,"user_tz":-60,"elapsed":526,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"691d0942-b633-4ac3-b840-fdc3ad09746b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(rdflib.term.URIRef('http://example.org/Jeff_Bezos'), rdflib.term.URIRef('http://example.org/founder_of'), rdflib.term.Literal('Amazon'))\n"]}]},{"cell_type":"markdown","source":["- **Question Answering**: Relation extraction is a critical step in understanding relationships between entities to answer complex questions.\n","  - **Observation**: Question-answering systems use extracted relations to search and return structured answers.\n","  - **Code Demonstration**: Extracting relations to provide simple QA answers.\n","\n"],"metadata":{"id":"y-FNnzKvrwuo"}},{"cell_type":"code","source":["# Defining a question about the CEO of Tesla.\n","question = \"Who is the CEO of Tesla?\"\n","\n","# A simple knowledge base (KB) that maps organizations (keys) to their CEO or related information (values).\n","knowledge_base = {\"Tesla\": \"Elon Musk\"}\n","\n","# Function to answer a question by checking the text and retrieving information from the knowledge base.\n","def answer_question(q, kb):\n","    # If the specific phrase \"CEO of Tesla\" is found in the question, the function attempts to answer.\n","    if \"CEO of Tesla\" in q:\n","        # The function retrieves the value associated with the key \"Tesla\" from the knowledge base.\n","        return kb.get(\"Tesla\")\n","\n","# Calling the function with the provided question and knowledge base.\n","answer = answer_question(question, knowledge_base)\n","\n","# Printing the retrieved answer.\n","print(f\"Answer: {answer}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRM8nIkvsXsk","executionInfo":{"status":"ok","timestamp":1728837748350,"user_tz":-60,"elapsed":3,"user":{"displayName":"Babu Pallam","userId":"10131957121692699069"}},"outputId":"a8a96662-9a91-421f-f28a-e764d7b0883b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Answer: Elon Musk\n"]}]}]}